[
  {
    "title": "【イベント開催告知】企業の生成 AI 活用を加速する Dify Enterprise on AWS 〜セキュアなデータの活用とパートナー導入事例〜 (2025/11/21)",
    "date": "2025-10-20T08:58:25.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/dify-enterprise-on-aws-event-20251121/",
    "content": "<p>こんにちは！ アマゾン ウェブ サービス ジャパンのソリューションアーキテクト馬渕です。</p> \n<p>2025 年 11 月 21 日 (金) 15:30-17:00 、AWS Japan の目黒オフィスにて、Dify と AWS に関するイベント「<strong><a href=\"https://d2e7mz4alxgx8z.cloudfront.net/?TrafficSource=awsblog\">企業の生成 AI 活用を加速する Dify Enterprise on AWS 〜セキュアなデータの活用とパートナー導入事例〜</a></strong>」の開催が決定しました。社内の生成 AI 活用を加速するために Dify を利用したいお客様、すでに Dify を利用していてさらにセキュアなデータも扱いたいお客様、Dify Enterprise を利用したいものの導入・運用に不安をお持ちのお客様に、今後のさらなる活用のためのヒントをご提供します。</p> \n<p><span id=\"more-166796\"></span></p> \n<h2>Dify のご紹介と、 AWS とのシナジーのご紹介</h2> \n<p><a href=\"https://dify.ai/jp\">Dify</a> は、生成 AI アプリをノーコードで開発できるプラットフォームです。技術者以外でも AI アプリが作れる使いやすさから多くのお客様の注目を集めており、社内の生成 AI 基盤として PoC ・本番導入しているお客様が増えてきています。Dify には SaaS 利用するか自社の環境にセルフホストするかの 2 つの利用方法があり、後者のセルフホスト方式では多くのお客様が AWS 上で Dify をデプロイし、セキュアに社内の生成 AI 推進を実現しています。なお、前者の <a href=\"https://docs.dify.ai/en/getting-started/cloud#faqs\">Dify Cloud も AWS 上で稼働しており</a>、AWS 上での Dify の稼働実績を十分に裏付けるものになっています。</p> \n<p>また、AWS では、AWS 上に Dify をスケーラブルかつマネージドな環境でセルフホストするための <a href=\"https://github.com/aws-samples/dify-self-hosted-on-aws\">AWS CDK サンプル</a>や、それをワンクリックでデプロイするための <a href=\"https://aws-samples.github.io/sample-one-click-generative-ai-solutions/solutions/dify/\">AWS Generative AI Solution Box</a> を公開しています。また、<a href=\"https://catalog.us-east-1.prod.workshops.aws/workshops/95a3c231-2064-4a33-9a3d-624b7c11aaa6/ja-JP\">AWS 上に簡易な構成で Dify 環境を構築し、その上で AI アプリケーションを構築する方法を学ぶワークショップ</a>も公開しており、Dify を通じたお客様の生成 AI 活用をご支援しています。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/14/image-5-6.png\"><img loading=\"lazy\" class=\"aligncenter size-full wp-image-166798\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/14/image-5-6.png\" alt=\"\" width=\"926\" height=\"590\"></a></p> \n<p style=\"text-align: center\">GitHub 上で公開している <a href=\"https://github.com/aws-samples/dify-self-hosted-on-aws\">Dify on AWS with CDK</a> サンプルのアーキテクチャ</p> \n<h2>Dify Enterprise のメリットとユースケース</h2> \n<p>そして、 Dify をエンタープライズ規模でセキュアに社内利用するのに役立つのが <a href=\"https://dify.ai/jp/enterprise\">Dify Enterprise</a> です。OSS 版 Dify の機能に加えて、自社 IdP とのシングルサインイン機能や、マルチワークスペースによるアプリケーション利用の細かい権限管理など、社内利用に役立つガバナンス向上のための機能を備えています。<a href=\"https://aws.amazon.com/marketplace/pp/prodview-vhluia2quhiuu\">Dify Enterprise のライセンスは AWS Marketplace 上でも購入可能</a>になっており、これを用いて AWS 上にデプロイすればセルフホスト時の基盤の費用とライセンス費用を効率的に管理することが可能です。</p> \n<p>Dify Enterprise を利用することで特にメリットのあるユースケースの 1 つが、セキュアなデータソースとの連携です。Dify には様々な SaaS やアプリケーションと連携できるプラグインのエコシステムがあり、例えば企業のデータウェアハウスと連携して社内データを活用した生成 AI アプリケーションを構築できます。Dify Enterprise の権限管理機能では、アプリケーションやプラグインへの細やかなアクセス可否を制御できるため、公開範囲が厳密なデータソースを連携するアプリケーションであっても安心して組み込むことが可能になります。</p> \n<h2>11/21(金) のイベントの詳細</h2> \n<p>今回のイベントでは、企業で社内の生成 AI 活用を推進する方を対象に、Dify Enterprise をご活用いただくための情報をご提供いたします。Dify の最新情報アップデートや、 Dify Enterprise ならではのセキュアなデータを扱うユースケースのご紹介に加えて、Dify の Eliter Partner でもあり AWS パートナーでもある株式会社リコー様にもご登壇いただき、Dify Enterprise の構築・運用のナレッジについてご共有いただきます。</p> \n<h3>開催概要</h3> \n<ul> \n <li>タイトル : <a href=\"https://d2e7mz4alxgx8z.cloudfront.net/?TrafficSource=awsblog\"><strong>企業の生成 AI 活用を加速する Dify Enterprise on AWS 〜セキュアなデータの活用とパートナー導入事例〜</strong></a></li> \n <li>日時 : 2025年11月21日（金）15:30-17:00 (15:00 開場) \n  <ul> \n   <li>終了後、懇親会あり</li> \n  </ul> </li> \n <li>参加費 : 無料</li> \n <li>お申し込み方法 : イベントの<a href=\"https://d2e7mz4alxgx8z.cloudfront.net/?TrafficSource=awsblog\">ランディングページ</a>よりフォームにアクセスしてお申し込みください</li> \n <li>開催場所 : 〒153-0064 東京都目黒区下目黒1-8-1 ARCO TOWER 19 F \n  <ul> \n   <li>JR線・東急目黒線・東京メトロ南北線・都営地下鉄三田線 目黒駅より徒歩約5分</li> \n   <li>[<a href=\"https://maps.app.goo.gl/uQK4JpGpmbs48Vhy6\">google map</a>] [<a href=\"https://pages.awscloud.com/rs/112-TZM-766/images/Japanese_AccessMAP_ArcoTower.pdf\">ARCO TOWERへのアクセス方法</a>]</li> \n  </ul> </li> \n</ul> \n<h3>アジェンダ</h3> \n<table border=\"1\" cellspacing=\"1\" cellpadding=\"10\"> \n <tbody> \n  <tr> \n   <td>開始</td> \n   <td>終了</td> \n   <td>コンテンツ</td> \n   <td>プレゼンター</td> \n  </tr> \n  <tr> \n   <td>15:30</td> \n   <td>15:35</td> \n   <td>オープニング</td> \n   <td>アマゾン ウェブ サービス ジャパン 合同会社</td> \n  </tr> \n  <tr> \n   <td>15:35</td> \n   <td>15:55</td> \n   <td>Dify Updates : RAG 2.0, MCP</td> \n   <td>株式会社 LangGenius</td> \n  </tr> \n  <tr> \n   <td>15:55</td> \n   <td>16:15</td> \n   <td>Dify Enterprise でセキュアなデータを扱おう<br> 〜Snowflake と連携してインサイトを生む〜</td> \n   <td>株式会社 LangGenius<br> アマゾン ウェブ サービス ジャパン 合同会社</td> \n  </tr> \n  <tr> \n   <td>16:15</td> \n   <td>16:30</td> \n   <td>Dify on AWS の選択肢と、AWS で Dify を使う理由</td> \n   <td>アマゾン ウェブ サービス ジャパン 合同会社</td> \n  </tr> \n  <tr> \n   <td>16:30</td> \n   <td>16:50</td> \n   <td>パートナーと進める Dify 活用</td> \n   <td>株式会社リコー</td> \n  </tr> \n  <tr> \n   <td>16:50</td> \n   <td>17:00</td> \n   <td>Q&amp;A / クロージング</td> \n   <td>アマゾン ウェブ サービス ジャパン 合同会社</td> \n  </tr> \n  <tr> \n   <td>17:00</td> \n   <td>18:00</td> \n   <td>懇親会</td> \n   <td>–</td> \n  </tr> \n </tbody> \n</table> \n<p>※ アジェンダやスピーカーは変更となる可能性がございます。</p> \n<h3>こんな課題をお持ちのお客様に</h3> \n<ul> \n <li>機密性の高いシステムと生成 AI の安全な連携方法を模索している</li> \n <li>部門やプロジェクトごとに異なるセキュリティレベルでの AI 活用を検討している</li> \n <li>コンプライアンスを確保しながら生成 AI の全社展開を進めたい</li> \n <li>Dify を活用したいが、その導入・運用のナレッジやリソースに不安がある</li> \n</ul> \n<h3>お申し込み方法</h3> \n<p>イベントの<a href=\"https://d2e7mz4alxgx8z.cloudfront.net/?TrafficSource=awsblog\">ランディングページ</a>よりフォームにアクセスしてお申し込みください。会場の定員の都合上、抽選とさせていただく場合がございますのでご了承ください。ご不安・ご不明点がある場合は、 AWS の担当営業にお声がけください。</p>"
  },
  {
    "title": "Amazon Q Developer で Audible のユニットテスト自動化を強化",
    "date": "2025-10-20T05:44:48.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/boosting-unit-test-automation-at-audible-with-amazon-q-developer/",
    "content": "<p>本記事は 2025 年 10 月 10 日に公開された “<a href=\"https://aws.amazon.com/jp/blogs/devops/boosting-unit-test-automation-at-audible-with-amazon-q-developer/\" target=\"_blank\" rel=\"noopener\">Boosting Unit Test Automation at Audible with Amazon Q Developer</a>” を翻訳したものです。</p> \n<p>Amazon の子会社である <a href=\"https://www.audible.co.jp/?ref=Adbl_ip_rdr_from_US&amp;source_code=ADBANON002061821003I&amp;ipRedirectFrom=US&amp;ipRedirectOriginalURL=\" target=\"_blank\" rel=\"noopener\">Audible</a> は、オーディオストーリーテリングの大手プロデューサーかつプロバイダーです。オーディオブック、ポッドキャスト、特別にキュレーションされた Audible Originals を含む 100 万タイトル以上の膨大なライブラリを持っています。Audible は没入感のあるオーディオ体験で、日常を学習や想像力、エンターテイメントの機会に変えています。数百万のエンドユーザーがデバイス間でシームレスな体験を楽しめるよう、堅牢なテストが重要です。</p> \n<p>テストカバレッジが不十分なコードベースを引き継いだ経験はありませんか？あるいは、締切に間に合わせるために急いでコードを書き、「後で」テストを追加すると約束したことは？私たちは皆そのような経験があります。テストは重要ですが、締切が迫ると優先度が下がりがちです。そこで <a href=\"https://aws.amazon.com/jp/q/developer/build/\" target=\"_blank\" rel=\"noopener\">Amazon Q Developer</a> のエージェント機能が登場し、開発者のテスト生成アプローチを変革しています。このブログでは、Audible が Amazon Q Developer を活用してユニットテストカバレッジを向上させた方法を紹介します。</p> \n<h2>ソフトウェアテストのビジネスユースケース</h2> \n<p>ベロシティの高い開発環境では、厳しい締切の下でテストサイクルが圧縮されることが多く、品質に問題が生じやすくなります。Amazon Q Developer は包括的な基準を維持しながらテストを加速し、この状況を変えます。自動テスト生成、エッジケースの特定、修正提案により、チームは短い時間で徹底的なテストを実行できます。これにより迅速なリリース、QA リソースの最適化、本番環境への準備強化を実現します。</p> \n<p>適切なテストが実装されていない各関数は、作り直し、バグ、メンテナンスの課題につながる可能性があります。さらに、引き継いだコードベースは特別な課題を提示します。開発者は既存機能のテストを書くのに数週間を費やすか、テストなしでの開発を続けるかという難しい選択を迫られます。</p> \n<p>Amazon Q Developer は適切なテストカバレッジに必要な時間と労力を削減し、これらの課題に対処します。テストを面倒な作業から効率的なプロセスに変え、チームがコード品質を確保しながら新機能の提供に集中できるようにします。</p> \n<h2>Amazon Q Developer：コードベースのテストカバレッジ拡張</h2> \n<p>Amazon Q Developer のエージェント機能は、ソフトウェアテスト生成に高度なアプローチを提供します。汎用的なテストを生成する従来ツールとは異なり、Amazon Q Developer はコードの意図、ビジネスロジック、エッジケースを分析します。単にテストを生成するだけでなく、コードの動作を包括的に検証する意味のあるテストスイートを作成します。</p> \n<p>今回紹介する専用のテスト生成機能以外にも、Amazon Q Developer はテストを支援するさまざまな方法を提供します。テスト計画生成のための会話型プロンプトの使用、既存コードのテスト改善要求、テスト作成時の Amazon Q Developer とのペアプログラミングなどが可能です。テスト開発プロセス全体に AI アシスタンスを統合する柔軟性により、Amazon Q Developer は開発者にとって多用途なパートナーとなります。</p> \n<h3>Amazon Q Developer のワークフローアーキテクチャ</h3> \n<p>以下のアーキテクチャ図は、Audible がテスト生成とコード変換の両方で Amazon Q Developer を活用した方法を示しています。</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/Q-developer-workflow.png\"></p> \n<p>Amazon Q Developer の開発プロセスは、2つの主要な機能を実証します。</p> \n<ul> \n <li><span style=\"text-decoration: underline\"><strong>テスト生成：</strong></span>Amazon Q Developer は Java クラスを分析し、ユニットテスト、エッジケーステスト、例外処理テストを含む包括的なテストスイートを作成します。</li> \n <li><span style=\"text-decoration: underline\"><strong>コード変換：</strong></span>Amazon Q Developer は自動移行タスクを実行します。これには <code>JDK 8</code> から <code>JDK 17/21</code> へのアップグレード、言語バージョン互換性の処理、<code>JUnit 4</code> から <code>JUnit 5</code> への変換、テストフレームワークの構文とアノテーションのモダナイゼーション、非推奨 API とコードパターンの更新が含まれます。</li> \n</ul> \n<p>この開発プロセスがとくに強力なのは、AI 機能と人間の専門知識を組み合わせる点です。エキスパート開発者が日常の開発プロセスで AI を活用できるようにします。Amazon Q Developer はコードベースを分析してコンテキストとして使用し、エッジケースを特定し、自動変換を実行します。一方で開発者はドメイン知識を適用し、出力がビジネス要件と期待される動作に合致することを確保します。</p> \n<h2>Amazon Q Developer の可能性を活用する Audible のアプローチ</h2> \n<p>Audible チームは、Amazon Q Developer を活用してテストカバレッジを向上させるために以下のステップに従いました。</p> \n<p><span style=\"text-decoration: underline\"><strong>コード生成：</strong></span>Audible チームは Amazon Q Developer を活用し、Java クラスの追加ユニットテストを生成してテストカバレッジを強化しました。対象には静的メソッドや既存のテストケースを持つメソッドも含まれます。このアプローチは彼らの堅牢なテスト戦略を補完しました。Amazon Q Developer はクラス、メソッド、パラメータ、戻り値の型、例外を調べる能力を持っています。null 入力チェックや空文字列チェックなど、見落としやすいエッジケースをカバーするユニットテストを自動的に特定します。</p> \n<p><span style=\"text-decoration: underline\"><strong>対象を絞った要求：</strong></span>Audible チームは Amazon Q Developer に以下を提供するよう具体的に依頼しました。</p> \n<ul> \n <li>Java クラス内の指定されたメソッドをカバーするユニットテストの提案</li> \n <li>テストされていないエッジケースを対象とするユニットテストの推奨事項</li> \n <li>エラー処理と例外シナリオに対処するテストケースの推奨事項</li> \n</ul> \n<p>Audible チームはテスト生成とコード変換の両方で Amazon Q Developer を使用し、大幅な改善を達成しました。成功の鍵は体系的な開発プロセスで、対象を絞ったプロンプトとともに豊富なコンテキストを提供することでした。</p> \n<h3>開発者の作業の流れ</h3> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/developer-workflow.png\"></p> \n<p>Audible は自動化ツールからの出力をレビューするため、人間参加型のアプローチを採用しています。上記の開発プロセスは完全なプロセスを示しています。：（1）IDE でクラスファイルを開く、（2）特定のメソッドを選択してプロンプトを追加する、（3）この組み合わされたコンテキストを Amazon Q Developer に送信する、（4）生成されたテストを受け取る、（5）テストをレビューしてコードベースに統合する。</p> \n<h2>効果的なプロンプトとアプローチ</h2> \n<p>Audible チームは Amazon Q Developer が対応できる対象を絞った要求を使用し、構造化されたアプローチに従いました。</p> \n<p><span style=\"text-decoration: underline\"><strong>コード生成：</strong></span>チームは Java クラスを Amazon Q Developer に提供し、個々のメソッドのテストを生成しました。対象には静的メソッドや、既にいくつかのテストがあるが完全なカバレッジが不足しているメソッドも含まれます。Amazon Q Developer はクラス、メソッド、パラメータ、戻り値の型、例外を調べ、null 入力チェックや空文字列チェックなどのエッジケースをカバーするユニットテストを自動的に特定しました。</p> \n<h3>特定のリクエストのための汎用サンプルプロンプト</h3> \n<p><em>基本的なテスト生成：</em></p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-text\">以下の Java メソッドのユニットテストを生成してください。すべての可能な入力シナリオとエッジケースをカバーすることに焦点を当ててください：\n\n[メソッドコードをここに]\n\n以下のテストを含めてください：\n- 有効な入力シナリオ\n- Null 入力チェック\n- 空文字列検証\n- 例外処理</code></pre> \n</div> \n<p><em>エッジケースフォーカス：</em></p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-text\">ユーザー入力を処理するこのメソッドがあります。見落としている可能性のあるエッジケースをカバーするユニットテストを提案してもらえますか？境界条件とエラーシナリオにとくに注意してください：\n\n[メソッドコードをここに]</code></pre> \n</div> \n<p><em>手動フレームワーク移行（Q Developer Chat 経由）：</em></p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-text\">この JUnit 4 テストを JUnit 5 形式に変換してください。アノテーションを更新し、適切な場合は最新の JUnit 5 機能を使用するようにしてください：\n\n[JUnit 4 テストコードをここに]</code></pre> \n</div> \n<blockquote>\n <p>注意：Amazon Q Developer のコード変換機能は、コードベース全体で JUnit4 から JUnit5 への移行を自動的に処理できますが、Audible は上記のように手動でターゲット化された変換のために会話型インターフェイスも使用しました。両方のアプローチが利用可能です。自動変換の詳細については<a href=\"https://docs.aws.amazon.com/ja_jp/amazonq/latest/qdeveloper-ug/transform-in-IDE.html\" target=\"_blank\" rel=\"noopener\">ドキュメント</a>を参照してください。</p>\n</blockquote> \n<p><span style=\"text-decoration: underline\"><strong>テスト生成：</strong></span>チームのリクエストに基づいて、Amazon Q Developer は適切なアサーションとテストメソッドでこれらの領域に対処する特定のテスト提案を生成しました。</p> \n<p><span style=\"text-decoration: underline\"><strong>実装：</strong></span>開発チームは、レビュー後に提案されたテストを実装しました。</p> \n<p><span style=\"text-decoration: underline\"><strong>ドキュメント：</strong></span>Amazon Q Developer は、テストの目的、テストがカバーしている機能の領域を説明するコメントを追加する能力を持っています。さらに、Amazon Q Developer は、readme ファイルやプロジェクトドキュメントなど、他の側面に関連するドキュメントを生成する能力も持っています。</p> \n<h2>定量化可能な結果</h2> \n<p>Amazon Q Developer を活用することで、Audible チームは以下を達成しました。</p> \n<ul> \n <li><span style=\"text-decoration: underline\"><strong>10 以上の主要パッケージ</strong></span>が包括的なユニットテストカバレッジを受けました</li> \n <li><strong><span style=\"text-decoration: underline\">テストクラスあたり約 1 時間</span></strong>の節約（通常 8-10 の個別テストを含む）</li> \n <li><span style=\"text-decoration: underline\"><strong>5,000 以上のテストケース</strong></span>が Amazon Q Developer のコード変換と手動での会話支援の両方を使用して<code>JUnit4</code> から <code>JUnit5</code> に正常に移行されました</li> \n <li>Amazon Q Developer のコード変換を使用し、<code>JDK8</code> から <code>JDK17</code> への移行にて&nbsp;<span style=\"text-decoration: underline\"><strong>50 時間以上の手作業を節約</strong></span></li> \n <li>AI 支援変換による人的エラーの削減</li> \n</ul> \n<h2>主要機能の実証結果</h2> \n<p>Amazon Q Developer は、手動テストで見落とされがちないくつかの領域で優れていました。</p> \n<p><strong><span style=\"text-decoration: underline\">包括的な例外テスト：</span></strong>標準的な null 入力チェックと空文字列検証を超えて、<code>IllegalArgumentException</code>、<code>NullPointerException</code>、カスタムビジネス例外のテストを自動的に提案しました。例外の投げ方と特定のエラーメッセージの両方の検証を含みます。この体系的なアプローチによりテストカバレッジがより完全になり、エラー処理がより堅牢になりました。</p> \n<p><span style=\"text-decoration: underline\"><strong>自動エッジケース検出：</strong></span>Amazon Q Developer はプロンプトなしで null ポインタ例外処理のインライン提案を行い、プロセスをよりスムーズで高速にしました。</p> \n<p><span style=\"text-decoration: underline\"><strong>AI 支援による手動フレームワーク移行：</strong></span>Amazon Q Developer のパターン認識は会話支援を通じて移行プロセスを加速しました。チームはチャットを通じて Amazon Q Developer に <code>JUnit4</code> から <code>JUnit5</code> へのテスト構文を手動で変換するよう依頼できました。たとえば、以前のセットアップには <code>@UseDataProvider</code> と <code>@DataProvider</code>アノテーションを持つ <code>JUnit4</code> 構文がありました。必要な作業はコードブロックをハイライトし、Send to Prompt して、Amazon Q Developer にテストを <code>JUnit5</code> 互換にするよう依頼することだけでした。数秒以内に ParameterizedTest アノテーションと Stream of Arguments を持つ信頼性の高い JUnit5 テストを生成し、手動で実装できました。</p> \n<p><span style=\"text-decoration: underline\"><strong>コンテキスト分析：</strong></span>Amazon Q Developer は既存のコードベースを分析してパターンを認識し、チームのコーディングスタイルとテスト規約に一致するテストを生成しました。</p> \n<h2>まとめ</h2> \n<p>Amazon Q Developer はテスト生成プロセスを時間のかかる作業から効率的な開発プロセスに変換し、チームが最小限の労力で包括的なテストカバレッジを達成できるようにします。これにより開発者はコード品質と信頼性を向上させながら、より価値の高い活動に集中できます。</p> \n<p>ビジネスへの影響は大きく、テストが負担でなくなるとチームは自然により良いテスト手法を採用します。全体的なコード品質が向上し、より高速な開発サイクルとメンテナンス時間の削減という好循環を作り出します。</p> \n<p>Amazon Q Developer の機能と価格の詳細については、<a href=\"https://aws.amazon.com/jp/q/developer/\" target=\"_blank\" rel=\"noopener\">Amazon Q Developer 製品ページ</a>をご覧ください。</p> \n<p>翻訳はApp Dev Consultantの宇賀神が担当しました。</p> \n<h2>著者について</h2> \n<p><img loading=\"lazy\" class=\"wp-image-1533 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/10/08/kirankumar.jpeg\" alt=\"kirankumar.jpeg\" width=\"218\" height=\"294\"></p> \n<p>Kirankumar Chandrashekar は AWS の Generative AI Specialist Solutions Architect で、Q Developer、Kiro、AI を使用した Developer Productivity などの次世代開発者体験ツールに焦点を当てています。AWS クラウドサービス、DevOps、モダナイゼーション、Infrastructure as Code の深い専門知識を持ち、革新的な AI 駆動ソリューションを通じて顧客の開発サイクルを加速し、開発者の生産性を向上させることを支援しています。Amazon Q Developer を活用することで、チームがアプリケーションをより高速に構築し、日常的なタスクを自動化し、開発作業の流れを合理化できるようにしています。Kirankumar は、複雑な顧客の課題を解決しながら開発者の効率を向上させることに専念しており、音楽、料理、旅行を楽しんでいます。</p> \n<p>&nbsp;</p> \n<p><img loading=\"lazy\" class=\"wp-image-1533 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/alex-torres-1.jpg\" alt=\"alex-torres.jpeg\" width=\"218\" height=\"294\" data-wp-editing=\"1\"></p> \n<p>Alex Torres は AWS の Senior Solutions Architect で、AWS 上でのアプリケーションのアーキテクチャ設計、設計、構築において <a href=\"https://amazon.com\" target=\"_blank\" rel=\"noopener\">Amazon.com</a> をサポートしています。セキュリティ、ガバナンス、開発者向けエージェント AI の深い専門知識を持ち、顧客が最先端のクラウド技術を活用して人々の生活を形作る製品を作成することを支援しています。革新的な AWS ソリューションを通じて複雑な課題を解決するチームの支援に情熱を注ぎ、Alex は最高水準のセキュリティとガバナンスを維持しながら顧客の成功を推進することに専念しています。仕事以外では、料理とハイキングを楽しんでいます。</p> \n<p>&nbsp;</p> \n<p><img loading=\"lazy\" class=\"wp-image-1533 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/GK_Profile_Picture-1.jpg\" width=\"218\" height=\"294\" data-wp-editing=\"1\"></p> \n<p>GK は Senior Customer Solutions Manager で、AWS の顧客としての Amazon をサポートする戦略的顧客アドバイザーです。AWS での 4 年間で、開発者の生産性向上と AWS サービス全体での Amazon のニーズの擁護に焦点を当て、ユーザー体験を向上させ、2つの組織間のより深い連携を推進してきました。高度な Amazon チームとの彼女の仕事は、最終的に内部と外部の両方の AWS 顧客に利益をもたらすソリューションの提供を支援しています。GK は、GenAI が開発者と非開発者の間のギャップをどのように埋めているかにとくに関心があり、GenAI とセキュリティの課題解決に多くの時間を費やしています。彼女はサンフランシスコベイエリアを拠点とし、ハイキングとキャンプを楽しんでいます。</p> \n<p>&nbsp;</p> \n<p><img loading=\"lazy\" class=\"wp-image-1533 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/aditi-linkedin.jpeg\" width=\"218\" height=\"294\" data-wp-editing=\"1\"></p> \n<p>Aditi Joshi は Audible のソフトウェアエンジニアで、Amazon プラットフォーム全体での Audible の存在拡大に取り組んでいます。フルスタック開発者として、主に Web 技術、クラウドサービス、JavaScript と Java などのプログラミング言語を使用して、Amazon iOS アプリでの Audible 購入機能の導入などの最近のプロジェクトを含む、クロスプラットフォーム統合機能を構築・強化しています。ユーザーインターフェイス開発、レスポンシブデザイン、Web 技術の専門知識を持ち、Audible オファーの紹介と Amazon エコシステム全体での Audible の可視性向上に焦点を当てています。Aditi は、クリーンで効率的なコードでスケーラブルなシステムを構築することに焦点を当てたソフトウェアアーキテクチャとユーザー体験に情熱を注いでいます。コーディング以外では、旅行、ヨガ、音楽鑑賞を楽しんでいます。</p> \n<p>&nbsp;</p> \n<p><img loading=\"lazy\" class=\"wp-image-1533 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/SP-headshot.jpeg\" width=\"218\" height=\"294\" data-wp-editing=\"1\"></p> \n<p>Sam Park は Audible のソフトウェア開発エンジニアで、Amazon プラットフォーム全体での Audible 機能の構築に焦点を当てています。Amazon Cart を通じた Audible 購入の有効化、および Amazon iOS と Android アプリ内での Audible の可視性拡大において重要な役割を果たしてきました。彼の仕事は、検索、商品ページ、チェックアウト、カート体験を含む Amazon エコシステム内の複数のタッチポイントにわたっています。Sam は、直感的な顧客体験を創出するソリューションの開発と、開発効率と生産性を向上させるための GenAI の活用に情熱を注いでいます。仕事以外では、旅行、バスケットボール、クリーブランド・キャバリアーズの応援を楽しんでいます。</p>"
  },
  {
    "title": "vitejs/vite – v5.4.21",
    "date": "2025-10-20T05:30:37.000Z",
    "source": "GitHub",
    "url": "https://github.com/vitejs/vite/releases/tag/v5.4.21",
    "content": "Please refer to [CHANGELOG.md](https://github.com/vitejs/vite/blob/v5.4.21/packages/vite/CHANGELOG.md) for details."
  },
  {
    "title": "vitejs/vite – v6.4.1",
    "date": "2025-10-20T05:25:55.000Z",
    "source": "GitHub",
    "url": "https://github.com/vitejs/vite/releases/tag/v6.4.1",
    "content": "Please refer to [CHANGELOG.md](https://github.com/vitejs/vite/blob/v6.4.1/packages/vite/CHANGELOG.md) for details."
  },
  {
    "title": "vitejs/vite – v7.0.8",
    "date": "2025-10-20T05:20:29.000Z",
    "source": "GitHub",
    "url": "https://github.com/vitejs/vite/releases/tag/v7.0.8",
    "content": "Please refer to [CHANGELOG.md](https://github.com/vitejs/vite/blob/v7.0.8/packages/vite/CHANGELOG.md) for details."
  },
  {
    "title": "Cortex Analyst と Streamlit を用いた Text2SQL アプリ作成",
    "date": "2025-10-20T05:13:15.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/chihilong/articles/text2sql-app-cortex-analyst-streamlit",
    "content": "\n 記事の概要\nこんにちは。シンプルフォーム株式会社でインターンをしています、長井です。\nこの記事では、Cortex Analyst [1] を用いたチャットアプリケーションを Streamlit [2] で構築した事例を紹介します。具体的には本アプリケーションで実装した以下の機能を説明します。\n\nチャット機能\n\nチャット\nリクエスト数のカウント\nSemantic View の選択\n直前までの質問を参考にした回答の生成\n\n\n補助機能\n\nフィードバックフォーム\nチャット履歴ページ\nSemantic View の定義確認ページ\n\n\n\n\n 背景・課題\n当社では社内向けのデータ分析基盤として S..."
  },
  {
    "title": "vitejs/vite – v7.1.11",
    "date": "2025-10-20T05:09:01.000Z",
    "source": "GitHub",
    "url": "https://github.com/vitejs/vite/releases/tag/v7.1.11",
    "content": "Please refer to [CHANGELOG.md](https://github.com/vitejs/vite/blob/v7.1.11/packages/vite/CHANGELOG.md) for details."
  },
  {
    "title": "LLMの責務を最小化する設計 — Claude Codeの中身は50代のベテランエンジニアかもしれない件",
    "date": "2025-10-20T02:59:31.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/sogab3/articles/fbf0230234ffe1",
    "content": "\n TL;DR\n本記事は、著者自身の振り返りとClaude Codeの分析を通して得た気づきを共有するものです。要点は下記です：\n\nDeep Learning時代のEnd-to-End学習の成功体験が、汎用LLM時代では逆に足かせになっているのではないか\n汎用性が高すぎるLLMには、むしろ古典的な設計原則（SOLID、関心の分離）が必要\n\nClaude Codeの成功には、LLMの責務を最小化し従来の設計原則を忠実に適用していることが寄与している\n\nLLMの責務を減らすことで開発者の責務は増えるが、これは「本来あるべき姿」への回帰\nパラダイムは変わっても、ソフトウェアエンジニアリングの基..."
  },
  {
    "title": "[資料公開 & 開催報告] Amazon Q Developer Meetup #3 を開催しました",
    "date": "2025-10-20T02:57:22.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/amazon-q-developer-meetup-3-report/",
    "content": "<p>2025 年 9 月 30 日に AWS Startup Loft Tokyo (目黒) で開催された「<a href=\"https://aws-experience.com/apj/smb/event/a9fb2855-8aae-43ed-b8bd-3e5cb537682c\">Amazon Q Developer Meetup #3 生成AIの利用を中心としたソフトウェア開発の新しいアプローチであるAI-DLCおよびその活用実績のご紹介</a>」のイベントの様子をレポートします。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167073\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-1024x573.png\" alt=\"\" width=\"1024\" height=\"573\"></a></p> \n<p>このイベントは、生成 AI を中心としたソフトウェア開発に対する新たなアプローチである、<strong>AI 駆動開発ライフサイクル (AI-DLC)</strong> をテーマに実施しました。まず Developer Specialist SA の金森から AI-DLC が必要とされる背景と、AI-DLC の概要、進め方をご紹介しました。続いて、すでに AI-DLC を体験していただいた LINE ヤフー株式会社様、株式会社サイバーエージェント様、東京海上日動システムズ株式会社様に、実際の進め方や学び、今後の展望などについて発表していただきました。</p> \n<p>現地参加・オンライン参加合わせて 200 名以上の方にご登録いただきました。参加者の方からは「実際に AI-DLC を実施した結果としての良い点、課題点が聞けたことが良かったです。」とのご感想をいただきました。AI-DLC を始めて知った方、これから AI-DLC の実施を検討されている方、すでに AI-DLC を体験されて改善に取り組まれている方、それぞれの皆様にご参考いただける情報をお届けしました。</p> \n<p>現地参加の方のみ、ケータリングをご用意し、ネットワーキングのための懇親会を実施しました。<br> 登壇者の方への質問や、参加者同士の意見交換、AWS メンバーへの相談が活発におこなわれていました。</p> \n<h2>イベント概要</h2> \n<ul> \n <li>開催日時: 2025年9月30日</li> \n <li>会場: AWS Startup Loft Tokyo (目黒)、オンライン配信</li> \n <li>スピーカー \n  <ul> \n   <li>LINE ヤフー株式会社様「AI-DLC を活用した、 負荷試験環境の構築」</li> \n   <li>株式会社サイバーエージェント様「CA 流、現場と伴走する AI 駆動開発 (AI-DLC)」</li> \n   <li>東京海上日動システムズ株式会社様「AI-DLC 体験記」</li> \n   <li>Developer Specialist SA 金森政雄, Amazon Web Services Japan G.K. 「AI 駆動開発ライフサイクル (AI-DLC) ソフトウェアエンジニアリングの再構築」</li> \n  </ul> </li> \n <li>登壇資料: <a href=\"https://pages.awscloud.com/rs/112-TZM-766/images/qdev-meetup3.zip\">こちらからダウンロード (zip)</a></li> \n</ul> \n<h2>AI 駆動開発ライフサイクル(AI-DLC)ソフトウェアエンジニアリングの再構築</h2> \n<p>スピーカー: Developer Specialist SA 金森政雄, Amazon Web Services Japan G.K.</p> \n<p>はじめに、Developer スペシャリストソリューションアーキテクトの金森より、AI-DLC をご紹介しました。<br> まず、ソフトウェア開発における生成 AI 利用に対する既存のアプローチの課題を挙げ、AI-DLC が必要とされる背景について述べました。続いて、開発プロセスを生成 AI が制御し、開発者が最終的な責任を保持するという AI-DLC のコンセプトを示し、AI-DLC を構成する各ステップの詳細についてご説明しました。そして AI-DLC を実践するためのアプローチであり、ご登壇いただいた各社様にご体験いただいた、AI-DLC Unicorn Gym についてケーススタディに基づいて仕組みや期待される成果についてご説明しました。<br> AI-DLC についてさらに詳しく知りたい方は、添付資料と併せてブログ「<a href=\"https://aws.amazon.com/jp/blogs/news/ai-driven-development-life-cycle/\">AI 駆動開発ライフサイクル:ソフトウェアエンジニアリングの再構築</a>」をご覧ください。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-1.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167074\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-1-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a><img loading=\"lazy\" class=\"alignnone size-large wp-image-167075\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-2-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-3.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167076\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-3-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-4.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167077\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-4-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a></p> \n<h2>LINEヤフー株式会社 様「AI-DLC を活用した、 負荷試験環境の構築」</h2> \n<p>LINE ヤフー株式会社様からは「AI-DLC を活用した、 負荷試験環境の構築」と題して、負荷試験環境の構築に AI-DLC を実践した事例についてご紹介いただきました。負荷試験ツールである Locust の設定や API、DB 初期化スクリプト等を AI-DLC を応用して作成した際の留意事項や実際の手順、工夫や今後の展望についてご説明いただきました。<br> 一次情報は社員が普段から利用しているツールから MCP Server 経由で取得していることや、AI-DLC のアウトプットを新規担当者のキャッチアップ資料などに活用していること、AI-DLC を軽量にカスタマイズして取り入れていることをご紹介いただきました。AI エージェントとの対話内容の例や実際のアウトプットについてもご共有いただきました。これからの展望として、アウトプットであるドキュメントの更新・メンテナンスの仕組みについても検討されていることをご紹介いただきました。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-1.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167079\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-1-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-2.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167080\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-2-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-3.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167081\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-3-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-4.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167082\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-4-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a></p> \n<h2>株式会社サイバーエージェント様 「CA 流、現場と伴走する AI 駆動開発 (AI-DLC)」</h2> \n<p>株式会社サイバーエージェント様からは「CA 流、現場と伴走する AI 駆動開発」と題して、AI 駆動開発の全社展開を目指す背景とその実践についてお話しいただきました。AI 駆動開発の浸透・普及により AI 活用を強化し、競争力のあるプロダクトを作ることの重要性や、AI を前提とした開発文化の定着には全社への浸透、行動様式や意思決定プロセスの変革も必要である、と言う方針についてご紹介いただきました。既存プロジェクトへの AI-DLC の適用においてはドメイン知識に関するコンテキストの不足や、伝達の難しさについてお話しいただいたのち、Code を Single source of truth とすることや、ドメインごとに独立したコンテキストを与えるという AI へのドメイン知識の伝達方法をご説明いただきました。最後に、AI 活用の普及には継続的に開発チームとコミュニケーションし、二人三脚で進めていくことが重要であるとも述べていただきました。</p> \n<p>AI-DLC Unicorn Gym 実施内容の詳細はブログ「<a href=\"https://note.com/ca_ai_ope/n/n23e13ccf2c8d\">既存開発フローに AI-DLCを適用する</a> 」と「<a href=\"https://note.com/ca_ai_ope/n/n14ba20754a53\">AWS 発「AI-DLC」ワークショップレポート！現場に適用するには？ </a>」も併せてご覧ください。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-1.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167083\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-1-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-2.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167084\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-2-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-3.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167085\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-3-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-4.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167086\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-4-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a></p> \n<h2>東京海上日動システムズ株式会社様 「AI-DLC 体験記」</h2> \n<p>東京海上日動システムズ株式会社様からは「AI-DLC 体験記」というタイトルで、AI-DLC ワークショップにご参加いただいた背景や準備、当日の様子や今後の展望についてご紹介いただきました。要件定義から実装フェーズの効率化の検証のため、既存システム改修と新規システム構築を対象とし、さまざまな部門・役割のメンバーが参加されたという背景をお話しいただきました。ワークショップ当日の成果物の例や完成したアプリケーションもご紹介いただきました。最後に各参加者からのフィードバックや、今後の AI-DLC を広く導入するための取り組みについてご説明いただきました。</p> \n<p>AI-DLC Unicorn Gym 実施内容の詳細はブログ「<a href=\"https://aws.amazon.com/jp/blogs/news/tokio-marine-ai-dlc/\">東京海上日動システムズ株式会社様の AWS 生成 AI 事例：金融業界初 AI-DLC Unicorn Gym による開発変革への挑戦</a>」も併せてご覧ください。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.30.14.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-166133\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.30.14-1024x577.png\" alt=\"\" width=\"1024\" height=\"577\"></a><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.30.38.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-166132\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.30.38-1024x578.png\" alt=\"\" width=\"1024\" height=\"578\"></a><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.31.06.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-166131\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.31.06-1024x578.png\" alt=\"\" width=\"1024\" height=\"578\"></a><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.31.20.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-166130\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.31.20-1024x578.png\" alt=\"\" width=\"1024\" height=\"578\"></a></p> \n<h2>おわりに</h2> \n<p>今回の Amazon Q Developer Meetup #3 では、AI 駆動開発ライフサイクル (AI-DLC) をテーマとしてその概要と実際に体験されたお客様からの事例をご紹介いただきました。LINE ヤフー株式会社様、株式会社サイバーエージェント様、東京海上日動システムズ株式会社様にご登壇いただき、実施の背景や体験していただいた内容、学びや今後の展望についてお話しいただきました。今後も、開発者の皆様が生成 AI をより有効に活用していただくための AI-DLC をはじめとしたプラクティスや Amazon Q Developer や Kiro といったツールについて発信・アップデートをお届けします。</p> \n<h2>次回予告: Amazon Q Developer &amp; Kiro Meetup #4 AWS サポートが語るよくある問い合わせ紹介とKiroのユースケース紹介</h2> \n<p>次回から Amazon Q Developer &amp; Kiro Meetup にシリーズ名をアップデートします！</p> \n<p>Amazon Q Developer &amp; Kiro Meetup #4 では AWS サポートエンジニアから Amazon Q Developer に関するよくあるお問い合わせとその回答を、株式会社アド・ダイセン様から Kiro のユースケースをご紹介いただきます。皆様のご登録をお待ちしています。</p> \n<ul> \n <li>参加登録: <a href=\"https://aws-experience.com/apj/smb/event/fd28de00-3189-49c4-909f-eb4c57a1ec3c\">Amazon Q Developer Meetup &amp; Kiro #4 AWS サポートが語るよくある問い合わせ紹介とKiroのユースケース紹介</a></li> \n <li>開催日時: 2025年10月31日 (金) 19:00-21:00</li> \n <li>会場: AWS Startup Loft Tokyo (目黒)、オンライン配信</li> \n <li>お客様登壇 \n  <ul> \n   <li>株式会社アド・ダイセン ソリューション部 部長 吉田 和弘 様「非エンジニアが生成AIでチームのイノベーション文化を創った実践事例」</li> \n  </ul> </li> \n</ul> \n<div></div> \n<footer> \n <div class=\"blog-author-box\"> \n  <div class=\"blog-author-image\"> \n   <div id=\"attachment_164799\" style=\"width: 310px\" class=\"wp-caption alignnone\">\n    <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/09/08/profile-20250806.jpg\"><img aria-describedby=\"caption-attachment-164799\" loading=\"lazy\" class=\"size-medium wp-image-164799\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/09/08/profile-20250806-300x296.jpg\" alt=\"\" width=\"300\" height=\"296\"></a>\n    <p id=\"caption-attachment-164799\" class=\"wp-caption-text\">yamazaki hiroki profile-20250806</p>\n   </div> \n  </div> \n  <h4 class=\"lb-h4\"><a href=\"https://x.com/yh1roki\" target=\"_blank\" rel=\"noopener\">山崎 宏紀 (Hiroki Yamazaki)</a></h4> \n  <p>山崎宏紀 は Amazon Web Services Japan G.K. のソリューションアーキテクトとして、ISV/SaaS 業界のお客様を中心にアーキテクチャ設計や構築、生成 AI の活用をご支援しています。Amazon Q Developer や AWS CDK を好みます。(より良いご支援のために) AI エージェントに代わりに働いてもらおうと画策しています。</p> \n </div> \n</footer>"
  },
  {
    "title": "2025/10/20時点で最良のAIコーディングプロセス",
    "date": "2025-10-20T02:09:26.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/erukiti/articles/2510-ai-coding",
    "content": "2025年10月20日の僕が考えるAIコーディング（バイブコーディング）プロセスです。\n個人的な結論としては、1ミリでも気に食わないコードを生成してきたら、そのタスクは最終的には破棄すべきというものです。「このコード気に食わない」「この設計気に食わない」の直感がAIコーディングで品質を維持する生命線です。\n\n\nバイブコーディング時代ではコードレビューのお局ビリティが鍵です。\nレビューに全時間を割こう。レビューに時間がかかりすぎるというより、レビューに時間をもっとかけるくらい\n1ミリでも知らないことをなくそう\n\n断片的なAIコーディングでいえば1年弱、本格的なコーディングエージェントを使い..."
  },
  {
    "title": "なぜResult型ライブラリを再発明したのか",
    "date": "2025-10-20T02:00:19.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/praha/articles/9d24390b869499",
    "content": "\n はじめに\nTypeScriptでエラーハンドリングを型安全に行いたいと考えたとき、皆さんはどのようなアプローチを取るでしょうか。\nJavaScript/TypeScriptの標準的なエラーハンドリング手法であるtry/catchは、型安全性に欠け、エラーが発生する可能性のあるコードを追跡するのが難しいという問題があります。\nそんな課題を解決するために、よく用いられるのがResult型を用いたエラーハンドリングです。\nResult型とは、成功時の値と失敗時のエラーを明示的に表現する型です。\nTypeScriptにおけるResult型ライブラリといえば、neverthrowが最も有名で広..."
  },
  {
    "title": "週刊AWS – 2025/10/13週",
    "date": "2025-10-20T01:56:19.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/aws-weekly-20251013/",
    "content": "<p>みなさん、こんにちは。ソリューションアーキテクトの戸塚です。今週も <a href=\"https://aws.amazon.com/jp/blogs/news/tag/%E9%80%B1%E5%88%8Aaws/\" target=\"_blank\" rel=\"noopener\">週刊AWS</a> をお届けします。</p> \n<p>AWS Bedrock AgentCore の一般提供開始を受け、私たちリテールチームは、店舗への導入ですぐに価値を発揮できるソリューションとして、マルチ AI エージェントによる販売支援を提案しています。実際に実機のデジタルサイネージを用いたデモをイベントなどで展示し、その内容をブログにまとめました。ぜひこちらもご覧ください。<br> <a href=\"https://aws.amazon.com/jp/blogs/news/multi-aiagents-sales-support-with-bedrock-agentcore/\">マルチ AI エージェントが創る新しい店舗体験 〜Amazon Bedrock AgentCoreによる販売支援〜</a></p> \n<p>こちらのデモは、10/28(火)-30(木)で開催される <a href=\"https://www.gartner.com/jp/conferences/apac/symposium-japan?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=EVT_JP_2025_JXP25_CPC_SEM1_BRAND&amp;utm_adgroup=181036754158&amp;utm_term=gartner%20it%20symposium&amp;ad=761661092565&amp;matchtype=e&amp;gad_source=1&amp;gad_campaignid=22604767100&amp;gbraid=0AAAAADFC_-Ui4vrFt6CCE9EqdOPnS9roe&amp;gclid=CjwKCAjwmNLHBhA4EiwA3ts3mei2Q0B2kNNPDRLdl5tlSwkTl01DDlT3Nx7wiTQwtsvga7aY-4Up5RoCZagQAvD_BwE\">Gartner IT Symposium</a> での展示予定となっております。</p> \n<p>それでは、先週の主なアップデートについて振り返っていきましょう。</p> \n<p><span id=\"more-167149\"></span></p> \n<h4>2025年10月13日週の主要なアップデート</h4> \n<ul> \n <li>10/13(月) \n  <ul> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/generative-ai-observability-amazon-cloudwatch/\" target=\"_blank\" rel=\"noopener\">Amazon CloudWatch で生成 AI オブザーバビリティが一般提供開始</a><br> Amazon CloudWatch で生成 AI オブザーバビリティ機能が一般提供開始となりました。AI アプリケーション全体の監視が可能になり、レイテンシーやトークン使用量、エラーをリアルタイムで把握できます。LangChain や LangGraph などのフレームワークにも対応し、問題の迅速な特定が可能です。追加料金なしで利用できます。詳細は<a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/GenAI-observability.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-bedrock-agentcore-available/\" target=\"_blank\" rel=\"noopener\">Amazon Bedrock AgentCore が一般提供開始</a><br> Amazon Bedrock AgentCore が一般提供開始されました。このサービスは AI エージェントを簡単に構築・運用できるプラットフォームです。従来は複雑だったエージェント開発が、インフラ管理不要で実現できるようになりました。最大 8 時間の長時間実行や VPC サポートによる安全なプライベート環境での運用が可能です。CrewAI や LangGraph などの人気フレームワークに対応し、CloudWatch で運用状況を監視できます。東京リージョンを含む 9 リージョンで利用でき、従量課金制で初期費用は不要です。詳細は<a href=\"https://aws.amazon.com/jp/blogs/news/amazon-bedrock-agentcore-is-now-generally-available/\" target=\"_blank\" rel=\"noopener\">こちらの Blog 記事をご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-sagemaker-ai-projects-custom-template-s3-provisioning\" target=\"_blank\" rel=\"noopener\">Amazon SageMaker AI Projects がカスタムテンプレートの S3 プロビジョニングをサポート</a><br> Amazon SageMaker AI Projects で、Amazon S3 からカスタム ML プロジェクトテンプレートをプロビジョニングできるようになりました。これまで管理者は標準的な ML プロジェクトテンプレートの管理が困難でしたが、今回のアップデートにより S3 上でテンプレートを管理し、データサイエンティストが SageMaker AI Studio から直接アクセスできます。組織の要件に合った標準化された ML 開発ワークフローを簡単に構築でき、全社的な ML プロジェクトの品質向上とガバナンス強化が実現します。詳細は<a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-templates-custom.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n  </ul> </li> \n <li>10/14(火) \n  <ul> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-msk-connect-ten-additional-regions/\" target=\"_blank\" rel=\"noopener\">Amazon MSK Connect が 10 の追加 AWS リージョンで利用可能に</a><br> Amazon MSK Connect が 10 の新しいリージョン (ジャカルタ、香港、大阪、メルボルンなど) で利用可能になりました。MSK Connect は Apache Kafka のデータ連携を完全マネージドで実現するサービスです。データベースやファイルシステムなどの外部システムと Kafka 間でデータを移動するコネクターを、インフラ管理不要で簡単にデプロイできます。従来は自分でサーバーを管理する必要がありましたが、これで使った分だけの課金で自動スケールが可能になります。詳細は<a href=\"https://docs.aws.amazon.com/msk/latest/developerguide/msk-connect.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-route-53-profiles-supports-aws-privatelink\" target=\"_blank\" rel=\"noopener\">Amazon Route 53 Profiles が AWS PrivateLink をサポート開始</a><br> Amazon Route 53 Profiles が AWS PrivateLink をサポート開始しました。従来はパブリックインターネット経由でのアクセスが必要でしたが、今回のアップデートでプライベートネットワーク経由での安全なアクセスが可能になりました。Route 53 Profiles は複数の VPC に統一された DNS 設定を適用できるサービスで、今回セキュリティが大幅に向上しました。詳細は<a href=\"https://docs.aws.amazon.com/Route53/latest/APIReference/API_Operations_Route_53_Profiles.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-appstream-license-included-apps\" target=\"_blank\" rel=\"noopener\">Amazon AppStream 2.0 がライセンス込み Microsoft アプリケーションの提供を発表</a><br> Amazon AppStream 2.0 で Microsoft Office や Visio、Project 2021/2024 がライセンス込みで利用できるようになりました。これまでは別途ライセンスの準備が必要でしたが、今回のアップデートにより AWS が提供するライセンス込みバージョンを直接利用可能です。リモートワークや在宅勤務で Microsoft アプリケーションを安全にクラウド経由で提供したい企業にとって、ライセンス管理の手間が大幅に削減されます。詳細は<a href=\"https://docs.aws.amazon.com/appstream2/latest/developerguide/tutorial-image-builder.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n  </ul> </li> \n <li>10/15(水) \n  <ul> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-aurora-postgresql-zero-etl-integration-sagemaker\" target=\"_blank\" rel=\"noopener\">Amazon Aurora PostgreSQL と Amazon SageMaker のゼロ ETL 統合が利用可能に</a><br> Amazon Aurora PostgreSQL が SageMaker Lakehouseとの zero-ETL 統合をサポート開始しました。これまで複雑な ETL プロセスが必要だったデータ分析が、リアルタイムに近い形で可能になります。PostgreSQL のデータを自動的にデータレイクハウスに同期し、Apache Iceberg 互換形式で SQL や Spark、機械学習ツールから直接利用できます。ノーコードで設定でき、本番環境への影響もありません。詳細は<a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/zero-etl.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-bedrock-automatic-enablement-serverless-foundation-models\" target=\"_blank\" rel=\"noopener\">Amazon Bedrock がサーバーレス基盤モデルの自動有効化によりアクセスを簡素化</a><br> Amazon Bedrock で、サーバーレス基盤モデルへのアクセスが自動で有効化されるようになりました。従来は手動でモデルアクセスを有効化する必要がありましたが、今回のアップデートで全商用リージョンにおいて即座に AI モデルを利用開始できます。Amazon Bedrock コンソールや AWS SDK から直ちにアクセス可能で、開発効率が大幅に向上します。ただし Anthropic モデルのみ初回利用時に一度だけ使用フォームの提出が必要です。詳細は<a href=\"https://aws.amazon.com/blogs/security/simplified-amazon-bedrock-model-access/\" target=\"_blank\" rel=\"noopener\">こちらの Blog 記事をご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock\" target=\"_blank\" rel=\"noopener\">Anthropic の Claude 4.5 Haiku が Amazon Bedrock で利用可能に</a><br> Amazon Bedrock で Claude Haiku 4.5 が利用可能になりました。Claude Sonnet 4 並みの高性能でありながら、大幅にコストを抑えて高速処理を実現しています。リアルタイムのカスタマーサポートやチャットボットなど、レスポンス速度が重要なアプリケーションに最適です。従来は性能とコストのどちらかを諦める必要がありましたが、両方を兼ね備えた AI モデルが使えるようになりました。</li> \n  </ul> </li> \n <li>10/16(木) \n  <ul> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/aws-security-hub-cspm-cis-foundations-benchmark-v5/\" target=\"_blank\" rel=\"noopener\">AWS Security Hub CSPM が CIS AWS Foundations Benchmark v5.0 をサポート開始</a><br> AWS Security Hub CSPM で CIS AWS Foundations Benchmark v5.0 がサポート開始されました。この業界標準のベンチマークには 40 のコントロールが含まれ、AWS リソースのセキュリティ設定を自動チェックできます。従来版から最新のセキュリティ要件に対応し、組織全体のアカウントで一括有効化も可能です。セキュリティ設定の見落としを防ぎ、コンプライアンス対応が効率化されます。詳細は<a href=\"https://docs.aws.amazon.com/securityhub/latest/userguide/cis-aws-foundations-benchmark.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-ec2-cpu-options-optimization-license-included-instances\" target=\"_blank\" rel=\"noopener\">Amazon EC2 がライセンス込みインスタンスの CPU オプション最適化をサポート</a><br> Amazon EC2 でライセンス込み Windows インスタンスの CPU オプション最適化が可能になりました。これまで固定だった vCPU 数やハイパースレッディングを調整できるようになり、Microsoft SQL Server などの vCPU ベースライセンス費用を大幅削減できます。例えば r7i.8xlarge インスタンスでハイパースレッディングを無効にすることで、32 vCPU を 16 vCPU に削減し、ライセンス費用を 50% 節約しながら、メモリ 256 GiB と IOPS 40,000 の性能は維持可能です。詳細は<a href=\"https://aws.amazon.com/blogs/modernizing-with-aws/optimize-cpus-best-practices-for-sql-server-workloads-continued/\" target=\"_blank\" rel=\"noopener\">こちらの Blog 記事をご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/aws-location-services-new-map-styling-enchanced-customization\" target=\"_blank\" rel=\"noopener\">Amazon Location Service が強化されたカスタマイゼーションのための新しいマップスタイリング機能を導入</a><br> Amazon Location Service で新しい地図スタイリング機能が利用可能になりました。地形の可視化、等高線表示、リアルタイム交通情報、交通手段別ルーティングなどが追加され、用途に応じたカスタマイズが可能です。物流アプリではトラック専用ルートの制限情報を表示したり、アウトドアアプリでは標高や地形の詳細を可視化できます。従来の基本的な地図表示から、より実用的で詳細な地図アプリケーションの開発が実現できるようになりました。詳細は<a href=\"https://docs.aws.amazon.com/location/latest/developerguide/what-is.html\" target=\"_blank\" rel=\"noopener\">こちらの Developer Guide をご参照ください。</a></li> \n  </ul> </li> \n <li>10/17(金) \n  <ul> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/aws-systems-manager-patch-manager-windows/\" target=\"_blank\" rel=\"noopener\">AWS Systems Manager Patch Manager が Windows 向けセキュリティ更新通知を開始</a><br> AWS Systems Manager Patch Manager で Windows 向けセキュリティ更新通知機能がリリースされました。この機能により、パッチベースラインで承認されていないセキュリティ更新を AvailableSecurityUpdate 状態として識別できます。これまで ApprovalDelay などを使用する際に、意図せずインスタンスがパッチ未適用のままになるリスクがありましたが、デフォルトで Non-Compliant として明確に表示されるため、セキュリティパッチの見落としを防げます。詳細は<a href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/patch-manager-compliance-states.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-ec2-capacity-manager\" target=\"_blank\" rel=\"noopener\">Amazon EC2 Capacity Manager の発表</a><br> Amazon EC2 Capacity Manager が一般提供開始されました。これまで複数のアカウントやリージョンにまたがる EC2 容量の管理は煩雑でしたが、単一のインターフェースで一元管理できるようになりました。On-Demand、Spot、Capacity Reservation の使用状況をダッシュボードで可視化し、履歴トレンドや最適化の機会も確認できます。全商用リージョンで追加コストなしで利用可能です。詳細は<a href=\"https://aws.amazon.com/jp/blogs/news/monitor-analyze-and-manage-capacity-usage-from-a-single-interface-with-amazon-ec2-capacity-manager/\" target=\"_blank\" rel=\"noopener\">こちらの Blog 記事をご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/database-insights-tag-based-access-control\" target=\"_blank\" rel=\"noopener\">CloudWatch Database Insights でタグベースアクセス制御をサポート開始</a><br> Amazon CloudWatch Database Insights で、タグベースアクセス制御がサポート開始されました。これまで RDS や Aurora インスタンスに設定したタグが Performance Insights のメトリクスに適用されず、データベースリソースごとに個別で権限設定する必要がありましたが、今回のアップデートでインスタンスのタグが自動評価されるようになりました。IAM ポリシーでタグベースアクセス条件を定義でき、複数のデータベースを論理的にグループ化した権限管理が可能です。詳細は<a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.access-control.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n  </ul> </li> \n</ul> \n<p>もうすぐ 今年もラスベガスにて、<a href=\"https://reinvent.awsevents.com/\" target=\"_blank\" rel=\"noopener\">AWS re:Invent</a> が開催されます。私は、BuildersFair のコーナーにて、LLM を活用したロボットのデモ展示対応をしております。ぜひ遊びにきてください。<br> それでは、また来週お会いしましょう！</p> \n<h1>著者について</h1> \n<footer> \n <div class=\"blog-author-box\"> \n  <div class=\"blog-author-image\">\n   <img src=\"https://d1.awsstatic.com/Developer%20Marketing/jp/magazine/profile/photo_totsuka-tomoya.7a8175c15da4a36f9232592a389c5f5c18663193.jpg\" alt=\"Tomoya Tozuka\" width=\"150\">\n  </div> \n  <h3 class=\"lb-h4\"><a href=\"https://x.com/tottu22\" target=\"_blank\" rel=\"noopener\">戸塚 智哉(Tomoya Tozuka) / @tottu22</a></h3> \n  <p>飲料やフィットネス、ホテル業界全般のお客様をご支援しているソリューション アーキテクトで、AI/ML、IoT を得意としています。最近では AWS を活用したサステナビリティについてお客様に訴求することが多いです。<br> 趣味は、パデルというスペイン発祥のスポーツで、休日は仲間とよく大会に出ています。</p> \n </div> \n</footer>"
  },
  {
    "title": "2025年版 スタートアップエンジニアが考えるWebアプリの技術選定",
    "date": "2025-10-20T01:30:00.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/m_noto/articles/5e4c9f705f500b",
    "content": "はじめまして、_minoです！\nこの記事では、最近公開されたムーザルちゃんねるさんの動画「2025年版「Webアプリ作るなら技術どれにする？」」を見て、私も今年を振り返り採用してよかった技術や、トレンドから見た来年以降流行りそうな技術についてまとめました。\n「その技術いいよね！」「この技術よかった!」などのご意見がありましたら、コメントで教えていただけると嬉しいです!\n!\n筆者がフロントエンドメインということもあり、フロントエンド目線での技術構成になっています。\n\n\n 🧩 言語・フレームワーク\n\n TypeScript\nJavaScriptに静的型付けを追加し、開発時の型安全性とツールサ..."
  },
  {
    "title": "Amazon MWAA における Apache Airflow 2.x から Apache Airflow 3.x への移行のベストプラクティス",
    "date": "2025-10-20T00:50:12.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/best-practices-for-migrating-from-apache-airflow-2-x-to-apache-airflow-3-x-on-amazon-mwaa/",
    "content": "<p>本記事は、2025 年 10 月 7 日に公開された <a href=\"https://aws.amazon.com/jp/blogs/big-data/best-practices-for-migrating-from-apache-airflow-2-x-to-apache-airflow-3-x-on-amazon-mwaa/\" target=\"_blank\" rel=\"noopener\">Best practices for migrating from Apache Airflow 2.x to Apache Airflow 3.x on Amazon MWAA</a> を翻訳したものです。翻訳はクラウドサポートエンジニアの山本が担当しました。</p> \n<p>Amazon MWAA の Apache Airflow 3.x では、セキュリティと分離性を強化する API ベースのタスク実行など、アーキテクチャの改善が導入されています。その他の主要なアップデートには、ユーザーエクスペリエンスを向上させた UI の再設計、パフォーマンスを改善したスケジューラーベースのバックフィル、<a href=\"https://www.python.org/downloads/release/python-3120/\" target=\"_blank\" rel=\"noopener\">Python 3.12</a> のサポートが含まれています。Amazon MWAA における Airflow のマイナーバージョンのインプレースアップグレードとは異なり、Airflow 2 から Airflow 3 へのアップグレードには根本的な破壊的変更があるため、慎重な計画と移行アプローチによる実行が必要です。</p> \n<p>この移行は、ビジネス継続性を確保しながら、次世代のワークフローオーケストレーション機能を導入する機会となります。しかし、これは単なるアップグレードではありません。Amazon MWAA で Airflow 3.x に移行する組織は、ワーカーからのメタデータデータベースへの直接アクセスの削除、SubDAG の廃止、デフォルトのスケジューリング動作の変更、ライブラリ依存関係の更新など、破壊的変更を理解する必要があります。この記事では、ミッションクリティカルなデータパイプラインへの影響を最小限に抑えながら、Airflow 3 の強化された機能を最大限に活用するための、ベストプラクティスとして合理的なアプローチを提供します。</p> \n<h2>移行プロセスの理解</h2> \n<p>Amazon MWAA における Airflow 2.x から 3.x への移行には、組織が移行を開始する前に理解しておくべき、いくつかの基本的な変更が含まれています。これらの変更は主要なワークフローの操作に影響を与えるため、スムーズな移行を実現するには慎重な計画が必要です。</p> \n<p>以下の破壊的な変更に注意してください：</p> \n<ul> \n <li><strong>直接的なデータベースアクセスの削除</strong> – Airflow 3 における破壊的変更は、ワーカーノードからのメタデータデータベースへの直接アクセスができなくなったことです。タスクとカスタムオペレーターは、直接的なデータベースアクセスではなく REST API を介して通信する必要があります。この設計変更は、以前 SQLAlchemy 接続を通じてメタデータデータベースに直接アクセスしていたコードに影響を与え、既存の DAG とカスタムオペレーターのリファクタリングが必要になります。</li> \n <li><strong>SubDAG の廃止</strong> – Airflow 3 では、TaskGroups、Assets、Data Aware Scheduling を優先し、SubDAG 構造を削除します。組織は既存の SubDAG を前述のいずれかの構造にリファクタリングする必要があります。</li> \n <li><strong>スケジューリング動作の変更</strong> – デフォルトのスケジューリングオプションに関する 2 つの注目すべき変更により、影響分析が必要です： \n  <ul> \n   <li>catchup_by_default と create_cron_data_intervals のデフォルト値が False に変更されました。この変更は、これらのオプションを明示的に設定していない DAG に影響を与えます。</li> \n   <li>Airflow 3 では、execution_date、tomorrow_ds、yesterday_ds、prev_ds、next_ds などのいくつかのコンテキスト変数が削除されます。これらの変数を、現在サポートされているコンテキスト変数に置き換える必要があります。</li> \n  </ul> </li> \n <li><strong>ライブラリと依存関係の変更</strong> – Airflow 3.x では多数のライブラリが変更され、DAG コードのリファクタリングが必要になります。以前に含まれていた多くのプロバイダーパッケージは、<code>requirements.txt</code> ファイルに明示的に追加する必要が場合があります。</li> \n <li><strong>REST API の変更</strong> – REST API のパスが /api/v1 から /api/v2 に変更され、外部統合に影響を与えます。Airflow REST API の使用に関する詳細については、<a href=\"https://docs.aws.amazon.com/ja_jp/mwaa/latest/userguide/access-mwaa-apache-airflow-rest-api.html#create-web-server-session-token\" target=\"_blank\" rel=\"noopener\">ウェブサーバーセッショントークンを作成し、Apache Airflow REST API を呼び出す</a>をご参照ください。</li> \n <li><strong>認証システム</strong> – Airflow 3.0.1 以降のバージョンでは Flask-AppBuilder の代わりに SimpleAuthManager がデフォルトになりますが、Amazon MWAA は Airflow 3.x でも引き続き Flask-AppBuilder を使用します。これは、Amazon MWAA のお客様には認証の変更が発生しないことを意味します。</li> \n</ul> \n<p>この移行では、インプレースアップグレードではなく、新しい環境を作成する必要があります。このアプローチはより多くの計画とリソースを必要としますが、移行プロセス中にフォールバックオプションとして既存の環境を維持できるという利点があり、ビジネスの継続性を確保できます。</p> \n<h2>移行前の計画と評価</h2> \n<p>移行を成功させるには、現在の環境を徹底的に計画し評価することが重要です。この段階では、依存関係、構成、潜在的な互換性の問題を特定することで、スムーズな移行の基盤を確立します。前述の互換性に影響する変更点に照らして環境とコードを評価し、移行を成功に導きましょう。</p> \n<h3>環境評価</h3> \n<p>まず、現在の Amazon MWAA 環境の完全なインベントリを作成します。すべての DAG、カスタムオペレーター、プラグイン、依存関係について、それぞれの特定のバージョンと構成を含め文書化します。Airflow 3.x を搭載した Amazon MWAA へのアップグレードに最適な互換性パスを提供するため、現在の環境がバージョン 2.10.x であることを確認してください。</p> \n<p>DAG コード、requirements ファイル、起動スクリプト、プラグインが含まれている <a href=\"https://aws.amazon.com/jp/s3/\" target=\"_blank\" rel=\"noopener\">Amazon Simple Storage Service</a> (Amazon S3) バケットの構造を確認します。この構造を新しい環境用の新しいバケットに複製します。環境ごとに個別のバケットを作成することで、競合を回避し、現在のパイプラインに影響を与えることなく開発を継続できます。</p> \n<h3>設定ドキュメント</h3> \n<p>すべてのカスタム Amazon MWAA 環境変数、Airflow 接続、環境設定を文書化してください。新しい環境の実行ロールには同一のポリシーが必要となるため、<a href=\"https://aws.amazon.com/jp/iam/\" target=\"_blank\" rel=\"noopener\">AWS Identity and Access Management (IAM)</a> の<a href=\"https://docs.aws.amazon.com/ja_jp/mwaa/latest/userguide/access-policies.html\" target=\"_blank\" rel=\"noopener\">リソース</a>を確認してください。Airflow UI にアクセスする IAM ユーザーまたはロールには、新しい環境に対する CreateWebLoginToken 権限が必要です。</p> \n<h3>パイプラインの依存関係</h3> \n<p>パイプラインの依存関係を理解することは、段階的な移行を成功させるために重要です。Datasets (現在は <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/assets.html\" target=\"_blank\" rel=\"noopener\">Assets</a>)、SubDAG、TriggerDagRun オペレーター、または外部 API との連携を通じて相互依存関係を特定してください。これらの依存関係に基づいて移行計画を立て、関連する DAG を同時に移行できるようにします。</p> \n<p>移行ウェーブを計画する際は、DAG のスケジューリング頻度を考慮してください。実行間隔が長い DAG は、頻繁に実行される DAG と比較して、より長い移行期間を確保でき、重複実行のリスクも低くなります。</p> \n<h3>テスト戦略</h3> \n<p>互換性の問題を特定するための体系的なアプローチを定義して、テスト戦略を作成します。<a href=\"https://github.com/astral-sh/ruff\" target=\"_blank\" rel=\"noopener\">ruff linter</a> を AIR30 ルールセットと共に使用して、更新が必要なコードを自動的に特定します。</p> \n<pre><code class=\"lang-code\">ruff check --preview --select AIR30 &lt;path_to_your_dag_code&gt;</code></pre> \n<p>次に、環境の <code>requirements.txt</code> ファイルを確認し、パッケージのバージョンが更新された制約ファイルに準拠するように更新してください。また、以前は airflow-core パッケージに含まれていた一般的に使用されるオペレーターは、現在は別のパッケージに移動されているため、requirements ファイルに追加する必要があります。</p> \n<p>Airflow 3.x 用の <a href=\"https://github.com/aws/amazon-mwaa-docker-images\" target=\"_blank\" rel=\"noopener\">Amazon MWAA Docker イメージ</a>を使用して DAG をテストします。これらのイメージを使用することで、requirements ファイルの作成とテスト、そしてスケジューラーが DAG を正常にパースすることを確認できます。</p> \n<h2>移行戦略とベストプラクティス</h2> \n<p>体系的な移行アプローチにより、明確な検証チェックポイントを提供しながら、リスクを最小限に抑えることができます。推奨される戦略は、信頼性の高い移行と即時のロールバック機能を提供する段階的ブルー/グリーンデプロイメントモデルを採用しています。</p> \n<h3>段階的な移行のアプローチ</h3> \n<p>以下の移行フェーズは、移行計画の定義に役立ちます。</p> \n<ul> \n <li><strong>フェーズ 1: 発見、評価、計画</strong> – このフェーズでは、環境のインベントリ、依存関係のマッピング、変更による影響の分析を完了します。収集した情報を基に、詳細な移行計画を策定します。この計画には、コードの更新、requirements ファイルの更新、テスト環境の作成、テスト、ブルー/グリーン環境の作成 (この記事の後半で説明)、および移行手順が含まれます。また、計画には、トレーニング、モニタリング戦略、ロールバック条件、ロールバック計画も含める必要があります。</li> \n <li><strong>フェーズ 2: パイロット移行</strong> – パイロット移行フェーズでは、影響範囲が限定された管理環境で詳細な移行計画の検証を行います。異なるスケジュールや依存関係など、多様な特性を持つ 2 ～ 3 個の重要度の低い DAG にフォーカスします。前のフェーズで定義した移行計画を使用して、選択した DAG を移行します。このフェーズを活用して計画とモニタリングツールを検証し、実際の結果に基づいて両者を調整します。パイロット中に、完全な移行のパフォーマンスを予測するのに役立つ基準となる移行メトリクスを確立します。</li> \n <li><strong>フェーズ 3: 段階的な本番移行</strong> – パイロットが成功したら、残りの DAG の段階的な完全移行を開始する準備が整います。残りの DAG を、ビジネスの重要度 (重要度の低いものから開始)、技術的な複雑さ、相互依存関係 (依存関係のある DAG をまとめて移行)、スケジュールの頻度 (実行頻度の低い DAG は移行に時間を確保できる) に基づいて論理的なウェーブにグループ化します。ウェーブを定義したら、ステークホルダーと協力してウェーブスケジュールを作成します。次のウェーブを開始する前に、ウェーブが成功したことを確認するための十分な検証期間を設けます。この時間は、移行の問題が発生した場合の影響範囲を抑え、ロールバックを実行するための十分な時間も確保します。</li> \n <li><strong>フェーズ 4: 移行後のレビューと廃止</strong> – すべてのウェーブが完了したら、得られた知見、最適化の機会、その他の未解決の項目を特定するために移行後のレビューを実施します。これはシステムの安定性を承認するのにも適した時期です。最後のステップは、元の Airflow 2.x 環境の廃止です。ビジネス要件と意見に基づいて安定性が確認されたら、元の (ブルー) 環境を廃止します。</li> \n</ul> \n<p><img loading=\"lazy\" class=\"alignnone wp-image-83993 size-full\" src=\"https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2025/09/30/MWAA-5280-Blue-Green-Migration-Timeline-.png\" alt=\"\" width=\"1400\" height=\"800\"></p> \n<h3>ブルー/グリーンデプロイメント戦略</h3> \n<p>安全で元に戻せる移行のために、ブルー/グリーンデプロイメント戦略を実装します。この戦略では、移行中に 2 つの Amazon MWAA 環境が稼働し、どの DAG をどの環境で実行するかを管理します。</p> \n<p>ブルー環境 (現行の Airflow 2.x) は、移行中に本番ワークロードを維持します。移行前に DAG の変更に対する停止期間を設定することで、直前のコードの競合を回避できます。この環境は、新しい (グリーン) 環境で問題が特定された場合の即時ロールバック環境として機能します。</p> \n<p>グリーン環境 (新しい Airflow 3.x) は、制御された段階で移行された DAG を受け取ります。ブルー環境からネットワーク、IAM ロール、セキュリティ設定をミラーリングします。この環境はブルー環境と同じオプションで構成し、同一の監視メカニズムを作成して、両環境を同時に監視できるようにします。DAG の重複実行を避けるため、DAG が単一の環境でのみ実行されるようにしてください。これには、グリーン環境で DAG をアクティブ化する前に、ブルー環境で DAG を一時停止することが含まれます。移行全体を通じて、ブルー環境をウォームスタンバイモードで維持します。各移行段階での具体的なロールバック手順を文書化し、少なくとも 1 つの重要度の低い DAG でロールバック手順をテストしてください。さらに、ロールバックのトリガー基準（特定の失敗率や SLA 違反など）を明確に定義してください。</p> \n<h2>段階的な移行プロセス</h2> \n<p>このセクションでは、移行を実施するための詳細な手順を説明します。</p> \n<h3>移行前の評価と準備</h3> \n<p>移行プロセスを開始する前に、現在の環境を徹底的に評価し、移行計画を策定してください。</p> \n<ul> \n <li>現在の Amazon MWAA 環境がバージョン 2.10.x であることを確認してください</li> \n <li>DAG、カスタムオペレーター、プラグインについて、それらの依存関係とバージョンを含む詳細なインベントリを作成してください</li> \n <li>現在の <code>requirements.txt</code> ファイルを確認し、パッケージの要件を理解してください</li> \n <li>すべての環境変数、接続、設定を文書化してください</li> \n <li><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/installation/upgrading_to_airflow3.html#breaking-changes\" target=\"_blank\" rel=\"noopener\">Apache Airflow 3.x リリース</a>ノートを確認し、破壊的変更を理解してください</li> \n <li>移行の成功基準、ロールバック条件、ロールバック計画を決定してください</li> \n <li>パイロット移行に適した少数の DAG を特定してください</li> \n <li>Amazon MWAA ユーザーに対する Airflow 3 のトレーニングまたは習熟計画を策定してください</li> \n</ul> \n<h3>互換性のチェック</h3> \n<p>互換性の問題を特定することは、移行を成功させる上で重要です。このステップにより、開発者は Airflow 3 と互換性のない特定のコードに焦点を当てることができます。 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/installation/upgrading_to_airflow3.html#step-3-dag-authors-check-your-airflow-dags-for-compatibility\" target=\"_blank\" rel=\"noopener\">ruff linter</a>を AIR30 ルールセットと共に使用して、更新が必要なコードを自動的に特定します。</p> \n<pre><code class=\"lang-code\">ruff check --preview --select AIR30 &lt;path_to_your_dag_code&gt;</code></pre> \n<p>さらに、<a href=\"https://airflow.apache.org/docs/apache-airflow/stable/installation/upgrading_to_airflow3.html#step-5-review-custom-operators-for-direct-db-access\" target=\"_blank\" rel=\"noopener\">メタデータベースへの直接アクセス</a>がコードに含まれていないか確認してください。</p> \n<h3>DAG コードの更新</h3> \n<p>互換性テストの結果に基づいて、Airflow 3.x に影響を受ける DAG コードを更新してください。ruff DAG チェックユーティリティを使用すると、一般的な変更を自動的に修正できます。以下のコマンドを使用して、更新モードでユーティリティを実行してください：</p> \n<pre><code class=\"lang-code\">ruff check dag/ --select AIR301 --fix ––preview</code></pre> \n<p>一般的な変更点は以下の通りです:</p> \n<ul> \n <li>メタデータベースへの直接アクセスを API 呼び出しに置き換える： \n  <div class=\"hide-language\"> \n   <pre><code class=\"lang-python\"># Before (Airflow 2.x) - Direct DB access\n\nfrom airflow.settings import Session\nfrom airflow.models.taskInstance import TaskInstance\nsession=Session()\nresult=session.query(TaskInstance)\n\nFor Apache Airflow v3.x, utilize in the Amazon MWAA SDK.\nUpdate core construct imports with the new Airflow SDK namespace:\n# Before (Airflow 2.x)\nfrom airflow.decorators import dag, task\n\n# After (Airflow 3.x)\nfrom airflow.sdk import dag, task</code></pre> \n  </div> </li> \n <li>非推奨のコンテキスト変数を最新の同等のものに置き換える： \n  <div class=\"hide-language\"> \n   <pre><code class=\"lang-python\"># Before (Airflow 2.x)\ndef my_task(execution_date, **context):\n    # Using execution_date\n\n# After (Airflow 3.x)\ndef my_task(logical_date, **context):\n    # Using logical_date</code></pre> \n  </div> </li> \n</ul> \n<p>次に、2 つのスケジューリング関連のデフォルト変更の使用状況を評価します。<code>catchup_by_default</code> が <code>False</code> になったため、欠落した DAG の実行は自動的にバックフィルされなくなりました。バックフィルが必要な場合は、DAG の定義を <code>catchup=True</code> に更新してください。DAG にバックフィルが必要な場合は、この移行とバックフィルの影響を考慮する必要があります。履歴のないクリーンな環境に DAG を移行するため、バックフィルを有効にすると、指定された start_date から始まるすべての実行に対して DAG 実行が作成されます。不要な実行を避けるため、start_date の更新を検討してください。</p> \n<p><code>create_cron_data_intervals</code> も <code>False</code> になりました。この変更により、cron 式は <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/timetable.html#crontriggertimetable\" target=\"_blank\" rel=\"noopener\">CronTriggerTimetable</a> コンストラクトとして評価されます。</p> \n<p>最後に、手動および Asset トリガーの DAG に対する<a href=\"https://airflow.apache.org/docs/apache-airflow/3.0.0/release_notes.html#context-behavior-for-asset-and-manually-triggered-dags\" target=\"_blank\" rel=\"noopener\">非推奨のコンテキスト変数</a>の使用状況を評価し、適切な代替コードに更新してください。</p> \n<h3>requirements の更新とテスト</h3> \n<p>パッケージバージョンの変更に加えて、airflow-core パッケージに含まれていた複数の Airflow コアオペレーターが apache-airflow-providers-standard パッケージに移行されました。これらの変更は、<code>requirements.txt</code> ファイルに反映する必要があります。requirements ファイルでパッケージバージョンを指定 (固定) することはベストプラクティスであり、この移行でも推奨されています。requirements ファイルを更新するには、以下の手順を実行します：</p> \n<ol> \n <li>Amazon MWAA Docker イメージをダウンロードして設定します。詳細については、<a href=\"https://github.com/aws/amazon-mwaa-docker-images\" target=\"_blank\" rel=\"noopener\">GitHub リポジトリ</a>を参照してください。</li> \n <li>現在の環境の <code>requirements.txt</code> ファイルを新しいファイルにコピーします。</li> \n <li>必要に応じて、新しい requirements ファイルに apache-airflow-providers-standard パッケージを追加します。</li> \n <li>対象の Airflow バージョンに適した Airflow constraints ファイルを作業ディレクトリにダウンロードします。constraints ファイルは、Airflow バージョンと Python バージョンの組み合わせごとに用意されています。URL は以下の形式になります：<code>https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt</code></li> \n <li>バージョン指定のない requirements ファイルと constraints ファイルを使用して、バージョン指定された requirements ファイルを作成します。requirements ファイルの作成ガイダンスについては、<a href=\"https://docs.aws.amazon.com/ja_jp/mwaa/latest/userguide/working-dags-dependencies.html#working-dags-dependencies-test-create\" target=\"_blank\" rel=\"noopener\"><code>requirements.txt</code> ファイルの作成</a>を参照してください。次のステップに進む前に、依存関係の競合がないことを確認してください。</li> \n <li>Docker イメージを使用して requirements ファイルを検証します。実行中のコンテナ内で以下のコマンドを実行します： \n  <div class=\"hide-language\"> \n   <pre><code class=\"lang-code\">./run.sh test-requirements</code></pre> \n  </div> <p>インストールエラーが発生した場合は、パッケージのバージョンを更新して対処します。</p></li> \n</ol> \n<p>ベストプラクティスとして、Amazon MWAA へのデプロイ用にパッケージを ZIP ファイルにパッケージ化することをお勧めします。これにより、すべての Airflow ノードに同じパッケージが確実にインストールされます。依存関係のパッケージ化に関する詳細については、<a href=\"https://docs.aws.amazon.com/ja_jp/mwaa/latest/userguide/best-practices-dependencies.html#best-practices-dependencies-different-ways\" target=\"_blank\" rel=\"noopener\">PyPI.org 要件ファイルフォーマットを使用した Python 依存関係のインストール</a>を参照してください。</p> \n<h3>新しい Amazon MWAA 3.x 環境の作成</h3> \n<p>Amazon MWAA はメジャーバージョンアップグレードに移行アプローチを必要とするため、ブルー/グリーンデプロイメント用に新しい環境を作成する必要があります。この記事では例として <a href=\"https://aws.amazon.com/jp/cli/\" target=\"_blank\" rel=\"noopener\">AWS Command Line Interface</a> (AWS CLI) を使用しますが、Infrastructure as Code (IaC) を使用することもできます。</p> \n<ol> \n <li>現在の S3 バケットと同じ構造で新しい S3 バケットを作成します。</li> \n <li>更新された requirements ファイルとプラグインパッケージを新しい S3 バケットにアップロードします。</li> \n <li>新しい環境設定のテンプレートを生成します： \n  <div class=\"hide-language\"> \n   <pre class=\"unlimited-height-code\"><code class=\"lang-bash\">aws mwaa create-environment --generate-cli-skeleton &gt; new-mwaa3-env.json</code></pre> \n  </div> </li> \n <li>生成された JSON ファイルを変更します： \n  <ol type=\"a\"> \n   <li>既存の環境から設定をコピーします。</li> \n   <li>環境名を更新します。</li> \n   <li>AirflowVersion パラメータをターゲットの 3.x バージョンに設定します。</li> \n   <li>S3 バケットのプロパティを新しい S3 バケット名で更新します。</li> \n   <li>必要に応じて他の設定パラメータを確認し更新します。</li> \n  </ol> <p>既存の環境と同じネットワーク設定、セキュリティグループ、IAM ロールで新しい環境を設定します。これらの設定については、<a href=\"https://docs.aws.amazon.com/ja_jp/mwaa/latest/userguide/what-is-mwaa.html\" target=\"_blank\" rel=\"noopener\">Amazon MWAA ユーザーガイド</a>を参照してください。</p></li> \n <li>新しい環境を作成します： \n  <div class=\"hide-language\"> \n   <pre class=\"unlimited-height-code\"><code class=\"lang-bash\">aws mwaa create-environment --cli-input-json file://new-mwaa3-env.json</code></pre> \n  </div> </li> \n</ol> \n<h3>メタデータの移行</h3> \n<p>新しい環境には、同じ変数、接続、ロール、プールの設定が必要です。このセクションを、これらの情報の移行ガイドとして使用してください。<a href=\"https://aws.amazon.com/jp/secrets-manager/\" target=\"_blank\" rel=\"noopener\">AWS Secrets Manager</a> をシークレットのバックエンドとして使用している場合は、接続を移行する必要はありません。環境サイズに応じて、Airflow UI または <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html\" target=\"_blank\" rel=\"noopener\">Apache Airflow REST API</a> を使用してこのメタデータを移行できます。</p> \n<ol> \n <li>Airflow UI を使用して、新しい環境でカスタムプールの情報を更新します。</li> \n <li>メタデータベースをシークレットバックエンドとして使用する環境の場合、すべての接続を新しい環境に移行します。</li> \n <li>すべての変数を新しい環境に移行します。</li> \n <li>カスタム Airflow ロールを新しい環境に移行します。</li> \n</ol> \n<h3>移行の実行と検証</h3> \n<p>古い環境から新しい環境への移行を計画し、実行します。</p> \n<ol> \n <li>ワークフローの影響を最小限に抑えるため、アクティビティの少ない期間に移行をスケジュールしてください。</li> \n <li>移行前および移行中で DAG の変更の停止期間を設定してください。</li> \n <li>移行を以下のフェーズで実行してください： \n  <ol type=\"a\"> \n   <li>古い環境で DAG を一時停止します。少数の DAG の場合は Airflow UI を使用できます。大規模なグループの場合は、REST API の使用を検討してください。</li> \n   <li>Airflow UI で実行中のすべてのタスクが完了したことを確認します。</li> \n   <li>DAG トリガーと外部統合を新しい環境にリダイレクトします。</li> \n   <li>更新された DAG を新しい環境の S3 バケットにコピーします。</li> \n   <li>新しい環境で DAG を有効化します。少数の DAG の場合は Airflow UI を使用できます。大規模なグループの場合は、REST API の使用を検討してください。</li> \n  </ol> </li> \n <li>初期運用期間中は新しい環境を注意深く監視してください： \n  <ol type=\"a\"> \n   <li>失敗したタスクやスケジューリングの問題がないか監視します。</li> \n   <li>変数や接続の欠落がないか確認します。</li> \n   <li>外部システムとの統合が正しく機能しているか確認します。</li> \n   <li><a href=\"https://aws.amazon.com/jp/cloudwatch/\" target=\"_blank\" rel=\"noopener\">Amazon CloudWatch</a> メトリクスをモニタリングして、環境が期待通りに動作していることを確認します。</li> \n  </ol> </li> \n</ol> \n<h3>移行後の検証</h3> \n<p>移行後、新しい環境を徹底的に検証します:</p> \n<ul> \n <li>すべての DAG が定義されたスケジュールに従って正しくスケジュールされていることを確認します。</li> \n <li>タスク履歴とログにアクセス可能で完全であることを確認します。</li> \n <li>重要なワークフローのエンドツーエンドテストを実施し、正常に実行されることを確認します。</li> \n <li>外部システムへの接続が適切に機能していることを検証します。</li> \n <li>パフォーマンスの検証のために CloudWatch メトリクスを監視します。</li> \n</ul> \n<h3>クリーンアップと文書化</h3> \n<p>移行が完了し、新しい環境が安定したら、以下の手順を実行してください。</p> \n<ol> \n <li>移行プロセス中に行った変更を文書化します。</li> \n <li>新しい環境を反映するように、運用手順書とオペレーション手順を更新します。</li> \n <li>ステークホルダーが定めた十分な安定期間の後、古い環境を廃止します： \n  <div class=\"hide-language\"> \n   <pre><code class=\"lang-code\">aws mwaa delete-environment --name old-mwaa2-env</code></pre> \n  </div> </li> \n <li>組織のデータ保持ポリシーに従ってバックアップデータをアーカイブします。</li> \n</ol> \n<h2>まとめ</h2> \n<p>Amazon MWAA における Airflow 2.x から 3.x への移行は、ワークフロー運用の信頼性を維持しながら、次世代のワークフロー オーケストレーション機能を活用する機会となります。これらのベストプラクティスに従い、体系的なアプローチを維持することで、ビジネス運用へのリスクと混乱を最小限に抑えながら、この移行を成功させることができます。</p> \n<p>移行を成功させるには、入念な準備、体系的なテスト、そしてプロセス全体を通じた明確なドキュメントの維持が必要です。この移行アプローチは初期の労力は大きくなりますが、このような重要なアップグレードに必要な安全性と制御を提供します。</p> \n<hr> \n<h3>著者について</h3> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/Anurag-Srivastava-badge-100x133-1-1.jpg\"><img loading=\"lazy\" class=\"size-full wp-image-167293 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/Anurag-Srivastava-badge-100x133-1-1.jpg\" alt=\"\" width=\"100\" height=\"133\"></a>Anurag Srivastava</strong> は、AWS のシニアテクニカルアカウントマネージャーとして、Amazon MWAA を専門に担当しています。お客様のスケーラブルなデータパイプラインとワークフロー自動化ソリューションの構築支援に情熱を注いでいます。</p> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/BDB-3847-awskamen-100x100-1-1.png\"><img loading=\"lazy\" class=\"size-full wp-image-167295 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/BDB-3847-awskamen-100x100-1-1.png\" alt=\"\" width=\"100\" height=\"100\"></a>Kamen Sharlandjiev</strong> は、ビッグデータおよび ETL ソリューションアーキテクトのシニアで、Amazon MWAA と AWS Glue ETL のエキスパートです。複雑なデータ統合とオーケストレーションの課題に直面するお客様の負担を軽減することをミッションとしています。最小限の労力で成果を出せるフルマネージド型 AWS サービスが彼の秘密兵器です。Amazon MWAA と AWS Glue の最新機能やニュースについては、LinkedIn で Kamen をフォローしてください！</p> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/Ankit-1-100x100-1.png\"><img loading=\"lazy\" class=\"size-full wp-image-167296 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/Ankit-1-100x100-1.png\" alt=\"\" width=\"100\" height=\"100\"></a>Ankit Sahu</strong> は、革新的なデジタル製品やサービスの構築において 18 年以上の実績があります。製品戦略、市場投入の実行、デジタルトランスフォーメーションイニシアチブにわたる幅広い経験を持ちます。現在は Amazon Web Services (AWS)のシニアプロダクトマネージャーとして、Amazon MWAA サービスを主導しています。</p> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/jeeten.png\"><img loading=\"lazy\" class=\"size-full wp-image-167297 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/jeeten.png\" alt=\"\" width=\"100\" height=\"119\"></a>Jeetendra Vaidya</strong> は、AWS のシニアソリューションアーキテクトとして、AI/ML、サーバーレス、データ分析の分野で専門性を発揮しています。お客様の安全で、スケーラブルで、信頼性が高く、コスト効率の良いソリューションの設計を支援することに情熱を注いでいます。</p> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/ellisms-resize.jpeg\"><img loading=\"lazy\" class=\"size-full wp-image-167298 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/ellisms-resize.jpeg\" alt=\"\" width=\"100\" height=\"133\"></a>Mike Ellis</strong> は、AWS のシニアテクニカルアカウントマネージャーで、Amazon MWAA のスペシャリストです。お客様の Amazon MWAA 支援に加えて、Airflow オープンソースプロジェクトにも貢献しています。</p> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/venu.jpeg\"><img loading=\"lazy\" class=\"size-full wp-image-167299 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/venu.jpeg\" alt=\"\" width=\"100\" height=\"133\"></a>Venu Thangalapally</strong> は、シカゴを拠点とする AWS のシニアソリューションアーキテクトで、クラウドアーキテクチャ、データ分析、コンテナ、アプリケーションモダナイゼーションに関する深い専門知識を持っています。金融サービス業界のお客様と協力して、ビジネス目標を安全で、スケーラブルで、コンプライアンスに準拠したクラウドソリューションに転換し、測定可能な価値を提供しています。技術を活用してイノベーションと業務効率の向上を推進することに情熱を注いでいます。仕事以外では、家族との時間を大切にし、読書や散歩を楽しんでいます。</p>"
  },
  {
    "title": "NTT西日本の AWS 事例：Amazon Bedrock Knowledge Bases を活用した営業支援 AI ボットの開発",
    "date": "2025-10-20T00:46:07.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/aws-genai-usecases-nttwest-elgana-rag/",
    "content": "<p><em>本ブログは、NTT西日本グループ 吉田 健哉氏、同 中井 智絵氏、アマゾン ウェブ サービス ジャパン合同会社 ソリューションアーキテクト 川岸 が共同で執筆しました。</em></p> \n<h2>はじめに</h2> \n<p><a href=\"https://www.ntt-west.co.jp/\">NTT西日本株式会社</a>（以下、NTT西日本）では、<a href=\"https://business.ntt-west.co.jp/service/assist/elgana/\">ビジネスチャット『elgana』（エルガナ）</a>をサービス提供しています。<a href=\"https://aws.amazon.com/jp/solutions/case-studies/ntt-west/\">2022 年 7 月にアマゾン ウェブ サービス (AWS) へプラットフォーム</a>を移行し、生成 AI による新機能開発も加速しています。</p> \n<p>elgana Project 「AI Lab.チーム」では、生成 AI を実際の業務にどう活かせるかをテーマにトライアル開発を進めています。本記事では、営業担当者支援を目的として <a href=\"https://docs.aws.amazon.com/ja_jp/bedrock/latest/userguide/knowledge-base.html\">Amazon Bedrock Knowledge Bases</a> を活用した RAG を構築し、そのトライアルを実施した取り組みについて紹介します。</p> \n<h2>取り組み背景</h2> \n<p>elgana は一般の企業様を中心にご利用いただいているサービスですが、生成 AI による新機能開発は社内向けに検証を開始しました。NTT西日本グループにおいて営業担当者は日々多様な商材を扱い、膨大なマニュアルや資料を参照しています。しかし実際には、情報が複数のシステムに散在しており、必要な情報を探し出すのに時間がかかる・属人化してしまうといった課題がありました。加えて、商材の問い合わせ窓口である社内ヘルプデスクは限られた対応時間の中で運用されており、すべての問い合わせに即時対応することは難しい状況でした。そこで、生成 AI に社内ナレッジを組み合わせる RAG を活用し、効率的に「聞ける・探せる・使える」仕組みを提供できないか検証することにしました。AWS サービスとの親和性、日本語対応、セキュリティ設計の容易さから、Amazon Bedrock Knowledge Bases を採用しました。</p> \n<h2>営業支援 AI ボット</h2> \n<p>営業支援 AI ボットは elgana 上に構築しました。トークルーム上で営業支援 AI ボットに対して商材に関する質問を入力すると、AI ボットが即時に回答を提示する仕組みです。また、AI ボットからの回答には、補足情報として関連するマニュアルページへのリンクを設けることで、裏付けとなる情報を容易に確認できる設計としました。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_chat_image1.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-167117\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_chat_image1.png\" alt=\"\" width=\"904\" height=\"446\"></a></p> \n<p>さらに、回答後には「解決した／解決していない」の簡易アンケートを設け、解決率を収集するとともに、未解決のユーザーをヘルプデスクに誘導する流れを設けています。これにより、AI の強みと有人対応を組み合わせた実用的なサポート体験を実現しています。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_chat_image2.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-167118\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_chat_image2.png\" alt=\"\" width=\"904\" height=\"450\"></a></p> \n<h2>アーキテクチャ</h2> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_architecture.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-167120\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_architecture.png\" alt=\"\" width=\"2220\" height=\"1232\"></a></p> \n<p>本システムでは、AWS のマネージドサービスをフル活用して構成し、最新技術の活用、インフラ運用の負担軽減とアプリレイヤの改善への集中を実現しています。elgana 上で営業支援 AI ボットに質問すると、Amazon API Gateway と AWS Lambda で実装したアプリケーションがメッセージを受信し、Amazon Bedrock Knowledge Bases を呼び出して質問に回答します。ナレッジのドキュメントの保存先のベクトルストアとして Amazon OpenSearch Serverless を利用しています。</p> \n<p>営業支援 AI ボットでは、利用者体験を向上させるため、回答生成に利用したマニュアルのページ番号まで案内すること、関連するサービスマニュアルのナレッジだけを参照するよう<a href=\"https://aws.amazon.com/jp/blogs/news/knowledge-bases-for-amazon-bedrock-now-supports-metadata-filtering-to-improve-retrieval-accuracy/\">メタデータフィルタリング</a>を活用して検索対象を絞り込むことで回答精度を向上させる工夫をしています。</p> \n<p>具体的な処理内容としては、運用者が Amazon S3 にアップロードしたマニュアルの pdf ファイルは AWS Lambda (pre-processing) を通じて、(A) ページ分割した上で、Markdown 形式に変換、(B) マニュアルに付与するメタデータを作成、の 2 つの処理が行われた後、Amazon S3 に格納されます。(A) の処理では、ページ分割することで RAG 回答で参照したマニュアルのページ番号をファイル名から特定できるようにしています。また、マニュアルに含まれる表データの抽出精度向上のため、pdf 文書をテキスト化するための python ライブラリである pdfminer を用いて HTML 化し、その後 Claude 3.5 Sonnet で Markdown 形式に変換しています。なお、Claude 3.5 Sonnet はマルチモーダル対応 LLM であるため、画像認識による情報抽出も可能ですが、検証時点では pdfminer を介す方法の方が優れていると判断しました。(B) の処理では、S3 のオブジェクトキー情報からカテゴリ情報等を抽出して、<code>.metadata.json</code> メタデータファイルを作成しています。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_architecture2.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-167121\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_architecture2.png\" alt=\"\" width=\"2060\" height=\"720\"></a><br> 以下はメタデータファイルの中身の例です。</p> \n<pre><code class=\"lang-json\">{\n    \"metadataAttributes\": {\n        \"original-s3-key\": \"docs/商材A/pdf/manualA.pdf\",\n        \"file-type\": \"pdf\",\n        \"category\": \"商材A\"\n    }\n}</code></pre> \n<p>このメタデータは、ベクトルストアからドキュメント検索する際に、メタデータに基づき事前にフィルタリングした上で、関連するドキュメントを検索できます。上記の例では、単一の Knowledge Base に複数の商材のマニュアルを格納していた場合にも、<code>category = 商材A</code> でフィルタリングすることで関連する情報を取得できるため、検索精度向上に寄与します。</p> \n<h2>トライアル結果</h2> \n<p>今回の取り組みでは、実際の営業担当者に数週間トライアル利用していただき、その後、ユーザーアンケートを実施し様々な評価を得ました。利用者からは「知りたい情報に素早くアクセスできる」「マニュアルを探す時間が減った」といった声が多く寄せられ、業務効率化につながる手応えを実感していただいており、現場での実用性を確認する結果となりました。一方で、「回答速度を上げてほしい」や「回答の幅（サービスの種類）を広げてほしい」などの改善意見もポイントも挙げられました。こうした声を踏まえ、今後も更なる機能改善を繰り返し利用者がさらに安心して業務に取り入れられるよう、進化させていく予定です。</p> \n<h2>今後の展望</h2> \n<p>今回のトライアルで得られた成果をもとに機能改善を重ねて実運用を目指していく予定です。<br> また、開発した RAG 基盤は Amazon S3 にナレッジドキュメントを格納するだけで対象商材に特化した検索基盤を自動的に構築できる仕組みであり、幅広い業務で活用できる柔軟な基盤へ発展させることも視野に入れています。将来的には Amazon Bedrock AgentCore 等を活用することで、単なる検索や回答にとどまらずタスク実行まで支援できる「Agentic RAG」へ時代に即した価値創出を目指します。</p> \n<h2>まとめ</h2> \n<p>本ブログでは、NTT西日本グループによる、 Amazon Bedrock Knowledge Bases を活用した営業支援 AI ボットによる情報検索効率化の取り組み事例をご紹介しました。生成 AI の業務利用にあたっては、ハルシネーションのような不確実性を課題視されるお客様もいらっしゃると思います。本事例では、関連マニュアルのページ番号まで明示することで情報の正確性を迅速に確認できる仕組みを構築するとともに未解決の場合にはヘルプデスクに誘導する仕組みを設け、AI の強みと有人対応を組み合わせた実用的なサポート体験を実現しています。皆様の生成 AI 活用の参考になれば幸いです。</p> \n<h3>著者</h3> \n<p>吉田 健哉<br> NTTビジネスソリューションズ株式会社 バリューデザイン部 システム開発部門</p> \n<p>中井 智絵<br> NTT西日本株式会社 ビジネス営業本部 バリューデザイン部 DXプラットフォーム部門</p> \n<p>川岸 基成<br> アマゾン ウェブ サービス ジャパン合同会社 技術統括本部 ストラテジックインダストリー技術本部 通信グループ<br> ソリューションアーキテクト</p>"
  },
  {
    "title": "Amazon MWAA における Apache Airflow 3 の紹介：新機能と機能拡張",
    "date": "2025-10-20T00:10:37.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/introducing-apache-airflow-3-on-amazon-mwaa-new-features-and-capabilities/",
    "content": "<p>本記事は、2025/10/1 に公開された <a href=\"https://aws.amazon.com/jp/blogs/big-data/introducing-apache-airflow-3-on-amazon-mwaa-new-features-and-capabilities/\" target=\"_blank\" rel=\"noopener\">Introducing Apache Airflow 3 on Amazon MWAA: New features and capabilities</a> を翻訳したものです。翻訳はプロフェッショナルサービスの佐藤が担当しました。</p> \n<p>本日、Amazon Web Services (AWS) は、<a href=\"https://aws.amazon.com/managed-workflows-for-apache-airflow/\" target=\"_blank\" rel=\"noopener\">Amazon Managed Workflows for Apache Airflow (Amazon MWAA)</a> における <a href=\"https://airflow.apache.org/blog/airflow-three-point-oh-is-here/\" target=\"_blank\" rel=\"noopener\">Apache Airflow 3</a> の一般提供開始を発表しました。このリリースにより、組織がクラウド上でデータパイプラインやビジネスプロセスをオーケストレーションするために Apache Airflow を使用する方法が変革され、強化されたセキュリティ、改善されたパフォーマンス、そして最新のワークフローオーケストレーション機能がもたらされます。</p> \n<p>Amazon MWAA は、AWS のお客様向けにワークフロー管理を最新化する Airflow 3 の機能を導入します。Apache コミュニティによる 2025 年 4 月の Airflow 3 リリースに続き、AWS はこれらの機能を Amazon MWAA に組み込みました。Airflow は現在、再設計された直感的な UI を備えており、あらゆるレベルのユーザーにとってワークフローオーケストレーションを簡素化します。Task Execution Interface (Task API) により、タスクは Airflow 内とスタンドアロンの Python スクリプトの両方として実行でき、コードの移植性とテストが向上します。スケジューラー管理のバックフィルは、操作を CLI からスケジューラーに移行し、Airflow UI を通じて一元的な制御と可視性を提供します。CLI のセキュリティ改善により、データベースへの直接アクセスが API 呼び出しに置き換えられ、インターフェース全体で一貫したセキュリティが維持されます。Airflow は現在、event-driven ワークフローをサポートしており、AWS サービスや外部ソースからのトリガーが可能になります。Amazon MWAA は Python 3.12 のサポートも追加し、ワークフロー開発に最新の言語機能をもたらします。</p> \n<p>この記事では、Amazon MWAA における Airflow 3 の機能を探求し、ワークフローオーケストレーション機能を向上させる拡張機能の概要を説明します。このサービスは、前払いのコミットメントなしで Amazon MWAA の従量課金制の料金モデルを維持します。<a href=\"https://console.aws.amazon.com/mwaa/home\" target=\"_blank\" rel=\"noopener\">Amazon MWAA コンソール</a>にアクセスし、<a href=\"https://console.aws.amazon.com/\" target=\"_blank\" rel=\"noopener\">AWS マネジメントコンソール</a>、<a href=\"https://aws.amazon.com/cli/\" target=\"_blank\" rel=\"noopener\">AWS コマンドラインインターフェイス</a> (AWS CLI)、<a href=\"https://aws.amazon.com/cloudformation/\" target=\"_blank\" rel=\"noopener\">AWS CloudFormation</a>、または <a href=\"https://aws.amazon.com/developer/tools/\" target=\"_blank\" rel=\"noopener\">AWS SDK</a> を通じて Apache Airflow 環境を起動することで、数分以内に開始できます。</p> \n<h2>Amazon MWAA における Airflow 3 のアーキテクチャの進歩</h2> \n<p>Amazon MWAA における Airflow 3 は、セキュリティ、パフォーマンス、柔軟性を向上させる重要なアーキテクチャの改善を導入します。これらの進歩により、既存のワークフローとの下位互換性を維持しながら、ワークフローオーケストレーションのためのより堅牢な基盤が構築されます。</p> \n<h3>セキュリティの強化</h3> \n<p>Airflow 3 を搭載した Amazon MWAA は、コンポーネントの分離をオプションではなく標準とすることで、セキュリティモデルを変更します。Airflow 2 では、DAG プロセッサー (DAG ファイルを解析および処理するコンポーネント) はデフォルトでスケジューラープロセス内で実行されますが、スケーラビリティとセキュリティの分離を向上させるために、オプションで独自のプロセスに分離できました。Airflow 3 では、この分離を標準とし、デプロイメント全体で一貫したセキュリティプラクティスを維持します。</p> \n<h3>API サーバーと Task API</h3> \n<p>このセキュリティモデルの上に、Airflow 3 を搭載した Amazon MWAA では新しい API サーバーコンポーネントが導入され、タスクインスタンスと Airflow メタデータデータベース間の仲介役として機能します。この変更により、タスクから Airflow メタデータデータベースへの直接アクセスを最小限に抑えることができ、ワークフローのセキュリティ態勢が向上します。タスクは現在、最小権限のデータベースアクセスで動作し、あるタスクが他のタスクに影響を与えるリスクを軽減し、データベースへの直接アクセスを減らすことで全体的なシステムの安定性を向上させます。</p> \n<p>明確に定義された API エンドポイントを通じた標準化された通信により、より安全で、スケーラブル、柔軟なワークフローオーケストレーションの基盤が構築されます。Task API により、タスクは Airflow 内とスタンドアロンの Python スクリプトの両方として実行でき、コードの移植性とテスト機能が向上します。</p> \n<h3>data-aware スケジューリングから event-driven スケジューリングへ</h3> \n<p>Airflow の event-driven スケジューリングへの進化は、Airflow 2.4 での data-aware スケジューリングの導入から始まり、時刻だけでなくデータの変更や更新を検知して DAG をトリガーできるようになりました。Airflow 3 を搭載した Amazon MWAA は、Dataset から Asset への名称変更を含む移行を通じてこの基盤の上に構築され、Asset パーティション、外部イベント統合、Asset 中心のワークフロー設計などの高度な機能を導入します。</p> \n<p>Dataset から Asset への移行は、単純な名称変更以上のものを表しています。 Asset は、データベーステーブル、永続化された ML モデル、埋め込みダッシュボード、ファイルを含むディレクトリなど、多様なデータ製品を表すことができる、論理的に関連するデータのコレクションです。</p> \n<p>Airflow 3 を搭載した Amazon MWAA は、ワークフローの設計方法における重要な変化を表す新しい Asset 中心の構文を導入します。@asset デコレーターにより、開発者は Asset をワークフロー設計の中心に置くことができ、より直感的な asset-driven パイプラインを作成できます。</p> \n<p>以下は、asset-aware DAG スケジューリングの例です:</p> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-python\">from airflow.sdk import DAG, Asset\nfrom airflow.providers.standard.operators.python import PythonOperator\n\n# Define the asset\ncustomer_data_asset = Asset(name=\"customer_data\", uri=\"s3://my-bucket/customer-data.csv\")\n\ndef process_customer_data():\n    \"\"\"Process customer data...\"\"\"\n    # Implementation here\n\n# Create the DAG and task\nwith DAG(dag_id=\"process_customer_data\", schedule=\"@daily\"):\n    PythonOperator(\n        task_id=\"process_data\", \n        outlets=[customer_data_asset], \n        python_callable=process_customer_data\n    )</code></pre> \n</div> \n<p>以下は、@asset デコレーターを使用した Asset 中心のアプローチを示しています:</p> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-python\">from airflow.sdk import asset\n\n@asset(uri=\"s3://my-bucket/customer-data.csv\", schedule=\"@daily\")\ndef customer_data():\n    \"\"\"Process customer data...\"\"\"\n    # Implementation here</code></pre> \n</div> \n<p>@asset デコレーターは、関数名を持つ Asset、同じ識別子を持つ DAG、および Asset を生成するタスクを自動的に作成します。これにより、コードの複雑さが軽減され、各 Asset が自己完結型のワークフローユニットになる自動 DAG 作成が容易になります。</p> \n<h3>Asset Watchers による external event-driven スケジューリング</h3> \n<p>Airflow 3 を搭載した Amazon MWAA における重要な進歩は、Asset Watchers の導入です。これにより、Airflow は Airflow システム自体の外部で発生するイベントに反応できるようになります。以前のバージョンでは内部のクロス DAG 依存関係をサポートしていましたが、Asset Watchers は AssetWatcher クラスを通じて、この機能を外部データシステムやメッセージキューに拡張します。</p> \n<p>Airflow 3 を搭載した Amazon MWAA には、Asset Watchers を通じた <a href=\"https://aws.amazon.com/sqs/\" target=\"_blank\" rel=\"noopener\">Amazon Simple Queue Service (Amazon SQS)</a> のサポートが含まれています。これにより、ワークフローを外部メッセージによってトリガーでき、より event-driven なスケジューリングが促進されます。Airflow は現在、event-driven ワークフローをサポートしており、AWS サービスや外部ソースからのトリガーが可能になります。Asset Watchers は外部システムを非同期的に監視し、特定のイベントが発生したときにワークフローの実行をトリガーします。これにより、従来のセンサーベースのポーリングメカニズムのオーバーヘッドなしに、ビジネスイベント、データ更新、またはシステム通知に応答できるようになります。</p> \n<h3>最新の React ベース UI</h3> \n<p>Airflow 3 を搭載した Amazon MWAA は、React と FastAPI で構築された完全に再設計された直感的な UI を備えており、あらゆるレベルのユーザーにとってワークフローオーケストレーションを簡素化します。新しいインターフェースは、より直感的なナビゲーションとワークフローの可視化を提供し、タスクのステータスと履歴をより良く可視化する強化されたグリッドビューを備えています。ユーザーは、長時間の使用中の疲労を軽減するダークモードのサポートの追加と、特に大規模な DAG を扱う際に顕著な全体的に高速なパフォーマンスを高く評価するでしょう。</p> \n<p>新しい UI は、DAG 管理と監視のためのより最新で効率的なエクスペリエンスを提供しながら、使い慣れたワークフローを維持し、開発者と運用者の両方にとって日常業務をより生産的にします。レガシー UI は完全に削除され、システム全体でよりクリーンで一貫したエクスペリエンスを提供します。新しい UI の基盤は、REST API と UI 操作用の内部 API のセットに基づいて構築されており、両方とも FastAPI に基づいているため、プログラムアクセスと UI 操作の両方に対して、より統合的で安全なアーキテクチャが構築されます。</p> \n<h3>スケジューラーの最適化</h3> \n<p>Airflow 3 を搭載した Amazon MWAA の強化されたスケジューラーは、タスク実行とワークフロー管理のパフォーマンス向上を実現します。再設計されたスケジューリングエンジンは、タスクをより効率的に処理し、タスクの送信と実行の間の時間を短縮します。この最適化は、迅速なタスク処理とタイムリーなワークフロー完了を必要とするデータパイプライン操作に利益をもたらします。</p> \n<p>スケジューラーは現在、コンピューティングリソースをより効果的に管理し、ワークロードがスケールしても安定したパフォーマンスを実現します。複数の DAG を同時に実行する場合、改善されたリソース割り当てシステムは、ボトルネックを防ぎ、一貫した実行速度を維持するのに役立ちます。この進歩は、さまざまなリソース要件を持つ複雑なワークフローを実行する組織にとって特に有用です。新しいスケジューラーは、同時操作をより高い精度で処理するため、チームはシステムの安定性と予測可能なパフォーマンスを維持しながら、複数の DAG インスタンスを同時に実行できます。</p> \n<h3>強化されたスケジューラーバックフィル操作</h3> \n<p>スケジューラー管理のバックフィル (過去の日付に対して DAG を実行するプロセス) は、操作を CLI からスケジューラーに移行し、Airflow UI を通じて一元的な制御と可視性を提供します。Airflow 3 を搭載した Amazon MWAA は、スケジューラーのバックフィル機能に重要なアップグレードを提供し、データチームが過去のデータをより効率的に処理できるようにします。バックフィルプロセスは、パフォーマンスの向上のために最適化されており、これらの操作中のデータベース負荷を軽減し、バックフィルをより迅速に完了できるようにし、ニアリアルタイムのワークフロー実行への影響を最小限に抑えます。</p> \n<p>Airflow 3 を搭載した Amazon MWAA は、バックフィル操作の管理も改善し、スケジューラーはバックフィルジョブ間のより良い分離を提供し、過去の Dataset より効率的な処理をサポートします。運用者は現在、バックフィルジョブの進行状況とステータスを追跡するためのより良い監視ツールを持っており、これらの重要なデータ処理タスクのより効果的な管理が可能になります。</p> \n<h2>開発者向けの改善</h2> \n<p>Amazon MWAA における Airflow 3 は、簡素化されたタスク定義からより良いワークフロー管理機能まで、開発者エクスペリエンスを向上させるために設計されたいくつかの拡張機能を提供します。</p> \n<h3>Task SDK</h3> \n<p><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html\" target=\"_blank\" rel=\"noopener\">Task SDK</a> は、タスクと DAG を定義するためのより直感的な方法を提供します:</p> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-python\"># Example using the Task SDK\nfrom airflow.sdk import dag, task\nfrom datetime import datetime\n\n@dag(\n    start_date=datetime(2023, 1, 1),\n    schedule=\"@daily\",\n    catchup=False\n)\ndef modern_etl_workflow():\n    \n    @task\n    def extract():\n        # Extract data from source\n        return {\"data\": [1, 2, 3, 4, 5]}\n    \n    @task\n    def transform(input_data):\n        # Transform the data\n        return [x * 10 for x in input_data]\n    \n    @task\n    def load(transformed_data):\n        # Load data to destination\n        print(f\"Loading data: {transformed_data}\")\n    \n    # Define the workflow\n    extracted_data = extract()\n    transformed_data = transform(extracted_data[\"data\"])\n    load(transformed_data)\n\n# Instantiate the DAG\netl_dag = modern_etl_workflow()</code></pre> \n</div> \n<p>このアプローチは、タスク間のより直感的なデータフロー、改善された型ヒントによるより良い統合開発環境 (IDE) サポート、およびタスクロジックのより簡単な単体テストを提供します。その結果、パイプラインの実際のデータフローをより良く表現する、よりクリーンで保守しやすいコードが得られます。このパターンを採用するチームは、特にワークフローが複雑さを増すにつれて、DAG がより読みやすく、保守が簡単になることがよくあります。</p> \n<h3>DAG バージョニング</h3> \n<p>Airflow 3 を搭載した Amazon MWAA には、Airflow 3 にデフォルトで付属する基本的な DAG バージョニング機能が含まれています。DAG が変更されてデプロイされるたびに、Airflow は DAG 定義をシリアル化して保存し、履歴を保持します。この自動バージョン追跡により、手動での記録管理の必要性が最小限に抑えられ、すべての変更が記録されます。</p> \n<p>Airflow UI を通じて、チームは DAG の履歴にアクセスして確認できます。この視覚的表現は、バージョン番号 (v1、v2、v3 など) を示し、チームがワークフローが時間とともにどのように進化したかを理解するのに役立ちます。</p> \n<p>Amazon MWAA でサポートされている DAG バージョニングは、Airflow UI で実行されたさまざまな DAG バージョンを確認する機能を提供し、複雑で進化するデータパイプラインを管理するデータエンジニアリングチームに、改善されたワークフローの可視性と強化されたコラボレーションを提供します。</p> \n<h3>Python 3.12 サポート</h3> \n<p>Amazon MWAA は <a href=\"https://www.python.org/downloads/release/python-3120/\" target=\"_blank\" rel=\"noopener\">Python 3.12</a> のサポートを追加し、ワークフロー開発に最新の言語機能をもたらします。このアップグレードにより、最新の Python 言語の改善、パフォーマンスの強化、ライブラリの更新にアクセスでき、データパイプラインを最新かつ効率的に保ちます。</p> \n<h2>Amazon MWAA で現在サポートされていない機能</h2> \n<p>このリリースで Amazon MWAA に Airflow 3 の機能のほとんどを導入していますが、現時点ではサポートされていない機能がいくつかあります:</p> \n<p>Flask AppBuilder の置き換え (<a href=\"https://cwiki.apache.org/confluence/display/AIRFLOW/AIP-79%3A+Remove+Flask+AppBuilder+as+Core+dependency\" target=\"_blank\" rel=\"noopener\">AIP-79</a>) – 完全な置き換え機能<br> Edge Executor とタスクの分離 (<a href=\"https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=301795932\" target=\"_blank\" rel=\"noopener\">AIP-69</a>) – リモート実行機能<br> 多言語サポート (<a href=\"https://cwiki.apache.org/confluence/display/AIRFLOW/Test+cases+AIP-72+Task+Execution+Interface+aka+Task+SDK\" target=\"_blank\" rel=\"noopener\">AIP-72</a>) – Python 以外の言語のサポート<br> これらの機能は、Amazon MWAA における Airflow の今後のバージョンでサポートする予定です。</p> \n<h2>まとめ</h2> \n<p>Amazon MWAA における Airflow 3 は、強化されたワークフロー自動化機能を提供します。アーキテクチャの改善、強化されたセキュリティモデル、開発者フレンドリーな機能により、より信頼性が高く保守しやすいデータパイプラインを構築するための堅固な基盤が提供されます。Asset Watchers の導入により、ワークフローが外部イベントに応答する方法が変わり、真のevent-driven スケジューリングが可能になります。この機能は、新しい Asset 中心のワークフロー設計と組み合わせることで、Airflow 3 をより強力で柔軟なオーケストレーションサービスにします。</p> \n<p>スケジューラーの最適化により、タスク実行とワークフロー管理のパフォーマンスが向上し、強化されたバックフィル機能により、過去のデータ処理がより効率的になります。DAG バージョニングシステムは、ワークフローの安定性とコラボレーションを向上させ、Python 3.12 サポートにより、データパイプラインを最新かつ効率的に保ちます。</p> \n<p>組織は現在、Amazon MWAA における Airflow 3 のこれらの新機能と改善を活用して、ワークフローオーケストレーション機能を強化できます。開始するには、<a href=\"https://aws.amazon.com/managed-workflows-for-apache-airflow/\" target=\"_blank\" rel=\"noopener\">Amazon MWAA 製品ページ</a>をご覧ください。</p> \n<hr> \n<h3>著者について</h3> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167222 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/Anurag-Srivastava-badge-100x133-1.jpg\" alt=\"\" width=\"100\" height=\"133\"><strong>Anurag Srivastava</strong> は、Amazon Web Services (AWS) のシニアビッグデータクラウドエンジニアとして、Amazon MWAA を専門としています。彼は、お客様が AWS 上でスケーラブルなデータパイプラインとワークフロー自動化ソリューションを構築するのを支援することに情熱を注いでいます。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167221 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/BDB-3847-awskamen-100x100-1.png\" alt=\"\" width=\"100\" height=\"100\"><strong>Kamen Sharlandjiev</strong> は、シニアビッグデータおよび ETL ソリューションアーキテクトであり、Amazon MWAA と AWS Glue ETL のエキスパートです。彼は、複雑なデータ統合とオーケストレーションの課題に直面しているお客様の生活を楽にすることを使命としています。彼の秘密兵器?は、最小限の労力で仕事を完了できる完全マネージド型 AWS サービスです。最新の Amazon MWAA と AWS Glue の機能とニュースを最新の状態に保つために、LinkedIn で Kamen をフォローしてください!</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167220 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/Ankit-1-100x100-1.png\" alt=\"\" width=\"100\" height=\"100\"><strong>Ankit Sahu</strong> は、革新的なデジタル製品とサービスの構築において 18 年以上の専門知識を持っています。彼の多様な経験は、製品戦略、市場投入の実行、デジタルトランスフォーメーションイニシアチブにまたがっています。現在、Ankit は Amazon Web Services (AWS) のシニアプロダクトマネージャーとして、Amazon MWAA サービスをリードしています。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167219 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/sabeel.jpg\" alt=\"\" width=\"100\" height=\"133\"><strong>Mohammad Sabeel</strong> は、Amazon Web Services (AWS) のシニアクラウドサポートエンジニアとして、AWS Glue、Amazon MWAA、Amazon Athena を含む AWS Analytics サービスを専門としています。14 年以上の IT 経験を持つ彼は、お客様がスケーラブルなデータ処理パイプラインを構築し、AWS 上の分析ソリューションを最適化するのを支援することに情熱を注いでいます。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167218 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/SatyaChikkala-1-100x150-1.jpg\" alt=\"\" width=\"100\" height=\"150\"><strong>Satya Chikkala</strong> は、Amazon Web Services のソリューションアーキテクトです。オーストラリアのメルボルンを拠点とし、エンタープライズのお客様と緊密に協力してクラウドジャーニーを加速しています。仕事以外では、自然と写真撮影に非常に情熱を注いでいます。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167217 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/saadari-1-100x133-1.jpg\" alt=\"\" width=\"100\" height=\"133\"><strong>Sriharsh Adari</strong> は、Amazon Web Services (AWS) のシニアソリューションアーキテクトであり、お客様がビジネス成果から逆算して AWS 上で革新的なソリューションを開発するのを支援しています。長年にわたり、彼は業界の垂直市場全体でデータシステムの変革において複数のお客様を支援してきました。彼の中核的な専門分野には、テクノロジー戦略、データ分析、データサイエンスが含まれます。余暇には、スポーツをしたり、テレビ番組を一気見したり、タブラを演奏したりすることを楽しんでいます。</p>"
  },
  {
    "title": "Amazon Bedrock 搭載の Treasure Data AI エージェントによってマーケティングキャンペーンプランニングを 3 倍に加速",
    "date": "2025-10-19T23:47:19.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/accelerate-marketing-campaign-planning-by-3x-with-treasure-data-ai-agents-powered-by-amazon-bedrock/",
    "content": "<p><em>この記事は <a href=\"https://aws.amazon.com/blogs/industries/accelerate-marketing-campaign-planning-by-3x-with-treasure-data-ai-agents-powered-by-amazon-bedrock/\" target=\"_blank\" rel=\"noopener\">Accelerate Marketing campaign planning by 3x with Treasure Data AI Agents powered by Amazon Bedrock</a> の翻訳記事です。</em></p> \n<p>マルチチャネル・キャンペーンの企画・実行において、マーケティングチームは大きな課題に直面しています。従来のキャンペーン企画​では、仮説設定、オーディエンス分析、ジャーニーマッピング、コンテンツ開発、アクティベーション、そして効果測定など、システムとチーム間の調整だけで数ヶ月を必要とします。この長いプロセスの間に、顧客がエンゲージメントを必要とする重要な瞬間を逃してしまうことがあるのです。<span id=\"more-166247\"></span></p> \n<p>Treasure Dataの<a href=\"https://www.treasuredata.co.jp/product/intelligent-cdp/\" target=\"_blank\" rel=\"noopener\">顧客データプラットフォーム（CDP）</a>は、世界中の大手ブランドにサービスを提供しており、インターネット接続人口の大部分の顧客プロファイルを管理しています。Amazon Web Services（AWS）と連携し、Amazon Bedrock を利用したマーケティングチーム向けの AI 活用ソリューションを開発しました。<a href=\"https://aws.amazon.com/jp/bedrock/\" target=\"_blank\" rel=\"noopener\">Amazon Bedrock</a> は、生成 AI アプリケーションを構築するための高性能な<a href=\"https://docs.aws.amazon.com/ja_jp/bedrock/latest/userguide/models-supported.html\" target=\"_blank\" rel=\"noopener\">基盤モデル</a>へのフルマネージドアクセスを提供し、自然言語の指示を理解し、様々なシステムと自律的に対話する AI エージェントの導入を可能にするサービスです。</p> \n<p>このブログでは、Amazon Bedrock を使って構築された Treasure Data の AI を活用したサービスによって、どのようにしてキャンペーン作成を数か月かかるプロセスから数時間または、数日へと変革することができるのか解説します。これらのソリューションにより、マーケティングチームと CX チームは、エンタープライズ企業が求めるセキュリティとガバナンスの基準を有しつつ、市場機会に迅速に対応し、パーソナライズされた体験を大規模に提供できるようになります。</p> \n<h3>信頼できるデータを基にした AI エージェント構築</h3> \n<p>AI の真の力は、高度な基盤モデルと高品質な顧客データを組み合わせることにこそあります。Treasure Data のプラットフォームと Amazon Bedrock の統合により、マーケティング担当者が顧客データを迅速に分析し、ターゲットオーディエンスセグメントを生成し、詳細なペルソナを定義し、技術的な専門知識がなくてもデータに基づく意思決定を行うことができるようになります。この組み合わせにより、キャンペーン作成時間が大幅に短縮され、ターゲティングの精度とキャンペーンのパフォーマンスが向上します。</p> \n<h3>AWS との共同開発</h3> \n<p>Treasure Data は AWS と緊密に連携し、従来のキャンペーン計画・実行プロセスにおける主要なボトルネックを特定しました。既存のツールにチャットインターフェースを単に追加するのではなく、AI の効果を最大限に高めるための基本的なワークフローを再設計することに重点を置きました。</p> \n<p>このパートナーシップでは、人間の持つ専門知識と AI の能力の適切なバランスを見つけることを重視しました。マーケティング担当者は戦略的な全体監督としての役割を維持し、AI エージェントが時間のかかる分析タスクを処理します。このアプローチでは、複雑なデータの相関性を処理し、実際の顧客の行動に基づいた実用的なインサイトを提供できるエージェントを構築する必要がありました。</p> \n<p>このコラボレーションにより、Amazon Bedrock 上に構築されたマルチエージェント・フレームワークが実現し、エンタープライズ企業が求めるセキュリティとコンプライアンスの標準を維持しながら、特定のマーケティング課題に対処できるようになりました。</p> \n<h3>Amazon Bedrock の価値</h3> \n<p>Treasure Data が AI エージェント基盤として Amazon Bedrock を選択したのは、制御性やセキュリティを犠牲にすることなく迅速な導入を可能にするためです。Amazon Bedrock はモデル選択を簡素化し、チームにデータサイエンスの専門知識がなくても高度な基盤モデルにアクセスできるようになります。</p> \n<p>このフルマネージドプラットフォームにより、カスタムインフラストラクチャをゼロから構築することなく、本番環境への迅速な導入が可能になります。顧客データは AWS とお客様による責任共有モデルの範囲内でプライバシーとセキュリティが確保されます。AWS が基盤となるインフラストラクチャを保護し、お客様はコンテンツとアクセス権限を管理できます。</p> \n<p>Treasure Data の顧客データに関する専門知識と Amazon Bedrock が提供する AI 基盤モデルを組み合わせることにより、組織がセキュリティとガバナンスの標準を維持しつつ AI イニシアチブを拡張することができます。</p> \n<h3>Treasure Data の目的別 AI エージェント</h3> \n<p>Treasure Data は、Amazon Bedrock を基盤として、特定のマーケティング課題に対応するための目的別 AI エージェントをいくつか開発しました。各エージェントは、キャンペーンの計画・実行プロセスにおける重要な課題を専門に扱います。</p> \n<p><a href=\"https://www.treasuredata.co.jp/product/ai-agents/\" target=\"_blank\" rel=\"noopener\">Audience Agent</a> を利用すれば、マーケティング担当者が SQL や高度なデータ操作スキルを持たなくても、行動シグナルから高価値のオーディエンスセグメントを素早く発見・作成できます。エージェントが顧客行動のパターンを自動的に識別してくれるため、データ分析とオーディエンスセグメンテーションの速度と精度が向上します。図 1 はクエリに基づいて顧客データを取得する Audience Agent の例です。例えば「最もロイヤルティの高い顧客について知りたい」という要求に対して、Audience Agent が関連する属性を識別し、結果を提示しています。</p> \n<p><img loading=\"lazy\" class=\"aligncenter size-full wp-image-166474\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/07/Figure-1-Audience-Agent-Console.png\" alt=\"\" width=\"624\" height=\"387\"></p> \n<p style=\"text-align: center\">図 1: Audience Agent コンソール</p> \n<p><a href=\"https://www.treasuredata.com/blog/deep-research-analysis-agent/\" target=\"_blank\" rel=\"noopener\">Deep Research &amp; Analysis Agent</a> は、仮説構築プロセスを数ヶ月から 1 週間未満にまで短縮します。手作業による分析やマーケティングに膨大な時間を費やす代わりに、顧客チームは行動シグナルに基づいた高品質な仮説を構築し、戦略、テスト、実行の意思決定に役立てることができます。Treasure Data の Deep Insight Platform は「質問管理」機能を提供しており、ユーザーは図 2 に示すように、解約率の傾向やメールのパフォーマンス分析など、いろいろな分析のための質問を作成できます。</p> \n<p><img loading=\"lazy\" class=\"aligncenter size-full wp-image-166475\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/07/Figure-2-Treasure-Data-Deep-Insight-Platform.png\" alt=\"\" width=\"624\" height=\"192\"></p> \n<p style=\"text-align: center\">図 2: Treasure Data Deep Insight Platform</p> \n<p>Treasure Data の <a href=\"https://www.treasuredata.co.jp/marketing-tool-trade-up-2025/\" target=\"_blank\" rel=\"noopener\">CDP トレードアッププログラム</a>の一部として提供される <a href=\"https://www.treasuredata.com/blog/meet-the-migration-agent/\" target=\"_blank\" rel=\"noopener\">Migration Agent</a> は、既存の顧客データプラットフォームからの移行を最大 60% 加速します。現在のシステムからクエリ、セグメント、変換ロジックを抽出し、SQL、パイプライン、オーケストレーション・ワークフローを自動生成します。このエージェントにより、既存のセグメント、ワークフロー、ビジネスロジックを維持したままデータを移行できるため、ゼロから構築する必要がなくなります。</p> \n<p>これらのエージェントは、データ処理機能と Amazon Bedrock の推論機能を組み合わせた Retrieval Augumented Generation (RAG) を利用しており、正確でデータに基づいた応答を提供します。これにより、AI による提案が一般的な推奨事項ではなく、実際の顧客行動を反映したものになります。</p> \n<h3>Treasure Data AI Agent Foundryのご紹介</h3> \n<p>予め提供されるエージェントは一般的なマーケティング課題に対応していますが、Treasure Data のお客様からは、独自のビジネス要件や業界固有のユースケースに合わせてカスタマイズされたエージェントを作成する必要性も指摘されていました。<a href=\"https://www.treasuredata.co.jp/product/ai-agent-foundry/\" target=\"_blank\" rel=\"noopener\">AI Agent Foundry</a> はこのニーズに応えるソリューションとして登場しました。</p> \n<p>AI Agent Foundry は、特定のビジネスニーズに合わせてカスタマイズされた AI エージェントを構築するための基盤です。マーケティングチーム、カスタマーエクスペリエンスチーム、データチームは、深い専門知識を持たなくても、エージェントを作成、改良、導入することができます。効果の高いユースケースとしては、ジャーニーオーケストレーション、データヘルスモニタリング、組織固有のキャンペーン最適化などが挙げられます。</p> \n<p>AI Agent Foundry には、エンタープライズガバナンス要件を満たすセキュリティ機能、権限管理、監査機能、アクセス管理が組み込まれています。チームは、データセキュリティ、プライバシー、規制コンプライアンスを維持しつつ、AI 機能を試し、エージェントを導入できます。このアプローチにより、お客様は特定の市場動向やビジネスプロセスに対応するエージェントを構築できます。</p> \n<h3>成果に直結する実用的なアプリケーション</h3> \n<p>これら専用エージェントは、Amazon Bedrock との統合で、複数の重要なマーケティングユースケースにも対応します。意思決定支援機能は、マーケティング担当者がキャンペーンのターゲティング、メッセージング、チャネル選択を決定する際に、複数の要素を同時に評価するのに役立ちます。AI が、単なる直感ではなく、包括的なデータ分析に基づいた推奨事項を提供してくれます。</p> \n<p>複数のチームメンバーが AI エージェントと同時に協働できるため、マーケティング組織全体で顧客インサイトへのアクセスが民主化されます。この機能により、マーケティングチームの技術的専門知識の不足によって生じるボトルネックが解消されます。</p> \n<p>エージェントは顧客とのやり取りやキャンペーンのパフォーマンスから継続的に学習するため、チームは素早い反復と最適化を通じてアプローチを改善し、よりよい成果を上げることができます。</p> \n<h3>事例：nobitel 株式会社</h3> \n<p>ヘルス＆スポーツサービスのリーディングカンパニーである nobitel 株式会社は、日本全国でストレッチ専門チェーン「Dr.Stretch」240 店舗以上を展開しています。同社はマーケティング業務において、手作業によるキャンペーン計画とデータのサイロ化により、技術チーム以外のチームが、顧客インサイトにアクセスしてタイムリーなパーソナライズされた推奨事項を提供することができないという課題を持っていました。</p> \n<p>この課題に対処するため、nobitel 社は Amazon Bedrock を含む AWS AI/ML サービスを利用して構築された Treasure Data AI Agent Foundry を導入しました。これにより、同社のマーケティング業務は変革され、技術チーム以外の、高度なデータスキルを持っていないマーケターでも、パーソナライズされたキャンペーンを実行できるようになりました。その結果、キャンペーン計画のスピードは 3 倍、店舗効率は 20% 向上しました。nobitel 社の変革の詳細については<a href=\"https://get.treasuredata.com/rs/714-XIJ-402/images/Nobitel-Case-Study-for-AWS-GenAI.pdf\" target=\"_blank\" rel=\"noopener\">ケーススタディ</a>をご覧ください。（訳注：日本語補足資料として<a href=\"https://www.treasuredata.co.jp/press-releases/20250325-nobitel/\" target=\"_blank\" rel=\"noopener\">こちら</a>もご覧ください）</p> \n<h3>AI を活用したマーケティングの未来</h3> \n<p>AI エージェントは、マーケティングとカスタマーエクスペリエンスのオペレーションを再構築する変革の始まりを象徴しています。将来的には、エージェントがメッセージのバリエーションをテストし、クリエイティブなコンテンツを生成し、マルチチャネルキャンペーンをオーケストレーションし、デバイスや地域を問わずリアルタイムで支出を最適化するようになるでしょう。</p> \n<p>マーケティングと CX の専門家は、キャンペーンを実行する役割から戦略的なオーケストレーターへと進化します。大事なことは、データインフラストラクチャが多数の自律型キャンペーンを正確かつ制御された状態で同時に実行できるかどうかです。</p> \n<p>こうした未来では、堅牢なデータ基盤、高度な AI 機能、そして大規模な信頼とコンプライアンスを確保するガバナンスフレームワークが必要とされます。すでにこのような基盤を構築している組織であれば、自律型マーケティングと CX オペレーションを活用できる態勢を整えていると言えるでしょう。</p> \n<h3>AI とデータによるマーケティングの変革</h3> \n<p>Amazon Bedrock を基盤とする Treasure Data の専用 AI エージェントと AI Agent Foundry は、マーケティング、CX、データの各チームが顧客データから価値を引き出す方法を根本的に変革します。信頼できるデータと高度な基盤モデルを組み合わせることで、チームはデータ分析、セグメント作成、ペルソナ生成、そして戦略的な意思決定を、数ヶ月ではなく数時間で実行できるようになります。</p> \n<p>この変革により、顧客インサイトへのアクセスが民主化され、複雑な分析タスクが自動化されます。マーケティングチームは市場機会への素早い対応と、迅速な反復処理によるよりよい成果の達成が可能になります。このソリューションは、効果的なマーケティングには、インテリジェントエージェントと、それらを真に強力にする堅牢なデータ基盤の両方が必要であることを示しています。</p> \n<p>セキュリティとコンプライアンスは、AWS とお客様の共有責任モデルの上にあります。AWS は Amazon Bedrock を通じて安全でコンプライアンスに準拠した基盤を提供し、お客様はデータとアクセスポリシーを管理できます。このアプローチにより、企業のガバナンス要件を満たしつつ AI を活用したイノベーションを実現できます。</p> \n<h3>まとめ</h3> \n<p>Amazon Bedrock を基盤とする Treasure Data AI Agent Foundry とプリビルドの AI エージェントが、マーケティングキャンペーンの作成プロセスを数か月から数時間、あるいは数日へと変革します。これらの AI ソリューションにより、マーケティング担当者に深い専門知識がなくても、データの迅速な分析、セグメントの作成、ペルソナの生成、そしてデータに基づく意思決定が可能になります。Amazon Bedrock の基盤モデルを活用した顧客インサイトへのアクセスの民主化と、複雑な分析タスクの自動化により、マーケティングチームは市場機会への素早い対応と迅速な反復処理を通じてよりよい成果を達成できるようになります。</p> \n<h3>Treasure Data – AWS パートナースポットライト</h3> \n<p>AWS パートナーである Treasure Data は、エンタープライズ規模に特化したインテリジェントなカスタマーデータプラットフォームです。Yum! Brands、Stellantis、AXA を始めとする 80 社を超える Global 2000 企業から信頼を得ている Treasure Data は、信頼性、パフォーマンス、そして AI ファーストのアーキテクチャを融合し、高度にパーソナライズされた顧客体験による収益向上、マーケティングコストの削減、そしてリスク軽減を実現します。Treasure Data は、すぐにご利用いただけるエージェントと AI Agent Foundry の両方を提供しています。データドリブンなチームやパートナーは、Treasure Data プラットフォーム上およびワークフロー全体で AI エージェントを活用、作成、展開し、信頼できる Treasure Data 環境内でデータを活用することができます。</p> \n<h3>関連情報</h3> \n<p><a href=\"https://aws.amazon.com/marketplace/seller-profile?id=aa906a95-308d-4b8b-b581-95d23bf4e184\" target=\"_blank\" rel=\"noopener\">Treasure Data on AWS Marketplace</a></p> \n<p><a href=\"https://partners.amazonaws.com/jp/partners/001E000000Rp5OSIAZ/Treasure%20Data\" target=\"_blank\" rel=\"noopener\">Treasure Data Partner Profile</a></p> \n<hr> \n<h4>著者について</h4> \n<p><strong>Ronak Shah</strong></p> \n<p>Ronak Shah は、ニューヨークを拠点とする AWS インダストリーバーティカルチームのプリンシパルパートナーソリューションアーキテクトです。小売消費財業界の AWS パートナーと協力し、AWS 上でのイノベーション共創を推進しています。小売業界の新たなトレンドの発見と、デジタルコマース、サプライチェーン、顧客体験、マーケティングテクノロジーの分野における革新的なソリューションの開発に関心を持っています。プライベートでは、ボーイスカウトや地元のディベート大会でボランティア活動を行っています。</p> \n<p><strong>Hiroshi Nakamura</strong></p> \n<p>Hiroshi Nakamura は、ソフトウェアエンジニアリングとシステムアーキテクチャの分野で豊富な経験を持つテクノロジーリーダーです。2014 年 10 月より Treasure Data の CTO 兼エンジニアリング担当 VP を務めており、膨大なデータに対応可能なクラウドベースのデータ管理プラットフォームの設計・開発に尽力してきました。1999 年 4 月からオープンソース開発者としても積極的に活動しており、Ruby と JRuby の大幅な機能強化に貢献しています。早稲田大学理工学修士号を取得しています。</p> \n<p><strong>Pranjal Gururani</strong></p> \n<p>Pranjal Gururani は、シアトルを拠点とする AWS のソリューションアーキテクトです。様々な顧客とともにビジネス課題を解決するクラウドソリューションの構築に取り組んでいます。趣味はハイキング、カヤック、スカイダイビング、​​そして家族との時間です。</p> \n<p>翻訳は Solutions Architect 杉中が担当しました。原文は<a href=\"https://aws.amazon.com/blogs/industries/accelerate-marketing-campaign-planning-by-3x-with-treasure-data-ai-agents-powered-by-amazon-bedrock/\">こちら</a>です。</p>"
  },
  {
    "title": "vercel/next.js – v16.0.0-canary.15",
    "date": "2025-10-19T23:46:13.000Z",
    "source": "GitHub",
    "url": "https://github.com/vercel/next.js/releases/tag/v16.0.0-canary.15",
    "content": "### Core Changes\n\n- Turbopack: Remove unneeded warning for telemetry: #85039\n- [cache components] stabilize cacheLife profiles: #85050\n- [cache components] show when cache components is enabled in the CLI: #85047\n- [cache components]: show cache components enabled in DevTools: #85048\n- [Cache Components] correctly label IO promises in devtools: #84928\n- Plumbing for cache indicator: #84955\n- Upgrade React from `93f85932-20251016` to `1324e1bb-20251016`: #84999\n- enable mcp server by default: #85058\n- Add comment that we expect the function passed to bind to be anonymous: #85070\n- Development: Addres comments on request log PR: #84945\n- Development: Implement request time for Pages Router: #85012\n- [cache components] add cache components indicator to dev start: #85069\n- cli: build partial entries --debug-build-paths arg: #85052\n- Turbopack: Better error for sassOptions.functions as it's unsupported: #85073\n\n### Misc Changes\n\n- add a message about Turbopack tracing: #85044\n- Turbopack: Implement next/font/local declarations option: #85051\n\n### Credits \n\nHuge thanks to @sokra, @ztanner, @timneutkens, @lubieowoce, @eps1lon, @huozhi, and @sebmarkbage for helping!\n"
  },
  {
    "title": "週刊生成AI with AWS – 2025/10/13週",
    "date": "2025-10-19T23:42:26.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/weekly-genai-20251013/",
    "content": "<p>みなさん、こんにちは。AWS ソリューションアーキテクトの木村です。</p> \n<p>今週 10月24日 (金) に「AWS Japan AI Agent Day 2025」が開催されます。一般提供開始された Amazon Bedrock AgentCore・Amazon Quick Suite など、AWS で AI Agent を活用するための知見を学ぶことができます。ぜひ、<a href=\"https://pages.awscloud.com/aws-japan-ai-agent-day-reg.html\">こちらの申し込みページ</a>からご登録をお願いいたします。</p> \n<p>また「AWS 生成 AI 活用ワークショップ～ Amazon Q Developer で生成 AI の一歩先へ！ ～」という Amazon Q Developer のワークショップイベントを 10月29日(水) に開催予定です。こちらも<a href=\"https://main.d2m7qvaonbzbmk.amplifyapp.com/public/\">申し込みページ</a>から登録いただけます。</p> \n<p>「<a href=\"https://pages.awscloud.com/jp-genai-accelerator-program-reg.html\">AWS ジャパン生成 AI 実用化推進プログラム</a>」も非常に多くの申し込みをいただいています。引き続き募集中ですのでよろしくお願いします。</p> \n<p>それでは、10 月 13 日週の生成 AI with AWS 界隈のニュースを見ていきましょう。<br> 先週は、Amazon Bedrock AgentCore の一般提供開始や Claude Haiku 4.5 のサポート開始など注目度が高いアップデートが多くありました。</p> \n<p><span id=\"more-167201\"></span></p> \n<p><strong>さまざまなニュース</strong></p> \n<ul> \n <li style=\"list-style-type: none\"> \n  <ul> \n   <li><a href=\"https://aws.amazon.com/jp/blogs/news/genai-case-study-makita/\"><strong>AWS生成AI国内事例ブログ「株式会社マキタ様の AWS 生成 AI 事例「AWS 上の閉鎖型 AI 環境で労働災害報告書作成支援と経営ダッシュボードを内製開発。システム開発経験の少ないエンジニアが短期間でリリースを実現」のご紹介」を公開</strong></a><br> 株式会社マキタ様が、経営ダッシュボードと労働災害報告書作成支援 AI を AWS 上で内製開発した事例を紹介しています。データのサイロ化や業務属人化の課題に対し、Amazon QuickSight や Amazon Bedrock などのマネージドサービスを活用し、経営ダッシュボードを7カ月、報告書作成支援 AI を1.5カ月という短期間でリリースしました。潤沢にエンジニアがいない環境においても内製化が可能になるAWSの容易さやサービスの豊富さを評価いただいています。</li> \n   <li><a href=\"https://aws.amazon.com/jp/blogs/news/amazon-bedrock-agentcore-is-now-generally-available/\"><strong>ブログ記事「Amazon Bedrock AgentCore、東京を含むAWSリージョンで一般提供開始：AIエージェントを現実の世界へ」を公開</strong></a><br> Amazon Bedrock AgentCore が、東京を含む9つの AWS リージョンで一般提供開始されました。本ブログでは、AI エージェントを本番環境で安全かつスケーラブルに運用するための統合プラットフォームである AgentCore の主要機能を紹介しています。またAmazon Bedrock AgentCoreをご利用の日本のお客様からのコメントも複数紹介しています。</li> \n   <li><a href=\"https://aws.amazon.com/jp/blogs/news/amazon-bedrock-now-supports-japan-cross-region-inference/\"><strong>ブログ記事「Amazon Bedrock で日本国内に閉じた Anthropic Claude 4.5 の推論が可能に！日本国内クロスリージョン推論のご紹介」を公開</strong></a><br> Amazon Bedrock で Claude Sonnet 4.5 / Claude Haiku 4.5 と共に日本国内クロスリージョン推論が導入されました。本ブログでは、データを日本国内に留めながら東京リージョンと大阪リージョンの計算リソースを活用し、予期しないトラフィックバーストに対応する仕組みや、推論プロファイルの概念、モニタリング方法、セキュリティ、料金体系などを解説しています。</li> \n   <li><a href=\"https://aws.amazon.com/jp/blogs/news/%E3%80%90%E9%96%8B%E5%82%AC%E5%A0%B1%E5%91%8A%E3%80%91amazon-sagemaker-roadshow-japan/\"><strong>ブログ記事「【開催報告】Amazon SageMaker Roadshow -Japan」を公開</strong></a><br> 本ブログは、2025年7月15日に開催された「Amazon SageMaker Roadshow -Japan」の開催報告です。Amazon SageMaker 開発チームによる次世代 Amazon SageMaker の紹介、Amazon SageMaker Unified Studio を活用したエンドツーエンドデモ、NX 情報システム様、キヤノンＩＴソリューションズ様、ソニーグループ様、NTT データ様による具体的な活用事例が紹介されています。</li> \n   <li><a href=\"https://aws.amazon.com/jp/blogs/news/migrate-and-modernize-vmware-workloads-with-aws-transform-for-vmware/\"><strong>ブログ記事「AWS Transform for VMware を使用して VMware ワークロードを移行およびモダナイズする」を公開</strong></a><br> 本ブログでは、AWS Transform for VMware を使用した VMware ワークロードの移行とモダナイゼーションについて解説しています。ディスカバリーとアセスメント（仮想マシンの発見と移行評価）の効率化、ネットワーク変換の自動化、AI 主導のウェーブプランニング（段階的な移行計画）、セキュアな移行実行など、AWS Transform for VMware のアーキテクチャと主要機能を詳しく紹介しています。</li> \n   <li><a href=\"https://aws.amazon.com/jp/blogs/news/how-i-stopped-worrying-about-readme-files/\"><strong>ブログ記事「README ファイルの心配をやめた方法」を公開</strong></a><br> Kiro のエージェントフック機能を活用して、README ファイルや API ドキュメントを自動更新する方法を紹介しています。エージェントフック機能とは、IDE 上で特定のイベントが発生したときに、あらかじめ定義されたエージェントのアクションを自動で実行するトリガー機能を指します。エージェントフックの設定方法や実際の動作例、さらにコード最適化や言語ローカライゼーションなどの他のユースケースも紹介しています。</li> \n   <li><a href=\"https://aws.amazon.com/jp/blogs/news/multi-aiagents-sales-support-with-bedrock-agentcore/\"><strong>ブログ記事「マルチAIエージェントが創る新しい店舗体験 〜Amazon Bedrock AgentCoreによる販売支援〜」を公開</strong></a><br> Amazon Bedrock AgentCore と PROTO 社のサイネージデバイスを連携させた、マルチ AI エージェントによる店舗販売支援ソリューションを紹介しています。アバターエージェント、商品情報エージェント、店舗支援エージェント、オーケストレーターエージェントが協調して動作し、来店前から店頭接客までシームレスな顧客体験を提供します。本ブログでは、AgentCore の各機能(Runtime、Gateway、Memory など)を活用したアーキテクチャと、顧客側・店舗側それぞれの活用方法を詳しく解説しています。</li> \n  </ul> </li> \n</ul> \n<p><strong>サービスアップデート</strong></p> \n<ul> \n <li style=\"list-style-type: none\"> \n  <ul> \n   <li><a href=\"https://aws.amazon.com/jp/about-aws/whats-new/2025/10/amazon-bedrock-agentcore-available/\"><strong>Amazon Bedrock AgentCore が一般提供開始</strong></a><br> Amazon Bedrock AgentCore が一般提供開始されました。このサービスは AI エージェントアプリケーションを安全かつスケーラブルに運用できるプラットフォームです。最大 8 時間の長時間実行や VPC サポートによる安全なプライベート環境での運用が可能です。CrewAI や LangGraph などの人気フレームワークに対応し、CloudWatch で運用状況を監視できます。東京リージョンを含む 9 リージョンで利用でき、従量課金制で初期費用は不要です。詳細は<a href=\"https://aws.amazon.com/jp/blogs/news/amazon-bedrock-agentcore-is-now-generally-available/\">上記のブログ</a>をご参照ください。</li> \n   <li><a href=\"https://aws.amazon.com/jp/about-aws/whats-new/2025/10/generative-ai-observability-amazon-cloudwatch/\"><strong>Amazon CloudWatch で生成 AI オブザーバビリティが一般提供開始</strong></a><br> Amazon CloudWatch で生成 AI オブザーバビリティ機能が一般提供開始となりました。Amazon Bedrock AgentCore でデプロイされるエージェントを含む AI アプリケーションの監視が可能になり、レイテンシーやトークン使用量、エラーをリアルタイムで把握できます。LangChain や LangGraph などのフレームワークにも対応し、問題の迅速な特定が可能です。追加料金なしで利用できます。詳細は<a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/GenAI-observability.html\">こちらのドキュメント</a>をご参照ください。</li> \n   <li><a href=\"https://aws.amazon.com/jp/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock/\"><strong>Anthropic の Claude 4.5 haiku が Amazon Bedrock で利用可能に</strong></a><br> Amazon Bedrock で Claude Haiku 4.5 が利用可能になりました。Claude Sonnet 4 並みの高性能でありながら、大幅にコストを抑えて高速処理を実現しています。リアルタイムのカスタマーサポートやチャットボットなど、レスポンス速度が重要なアプリケーションに最適です。性能とコストの両方を兼ね備えた AI モデルが使えるようになりました。詳細は<a href=\"https://ap-southeast-2.signin.aws.amazon.com/sessions/selector?client_id=arn%3Aaws%3Asignin%3A%3A%3Aconsole%2Famazon-bedrock&amp;code_challenge=6OIwVXJwYtujUSaVmMplAfonxr7EIcGDE0xFlh-Nfog&amp;code_challenge_method=SHA-256&amp;response_type=code&amp;redirect_uri=https%3A%2F%2Fap-southeast-2.console.aws.amazon.com%2Fbedrock%3FhashArgs%3D%2523%26isauthcode%3Dtrue%26oauthStart%3D1760741082036%26state%3DhashArgsFromTB_ap-southeast-2_7f906c1cd4e02b58%26useDefaultRegion%3Dtrue&amp;scope=openid\">こちらのコンソール</a>をご参照ください。</li> \n   <li><a href=\"https://aws.amazon.com/jp/about-aws/whats-new/2025/10/amazon-bedrock-automatic-enablement-serverless-foundation-models/\"><strong>Amazon Bedrock がサーバーレス基盤モデルの自動有効化によりアクセスを簡素化</strong></a><br> Amazon Bedrock で、サーバーレス基盤モデルへのアクセスが自動で有効化されるようになりました。従来は手動でモデルアクセスを有効化する必要がありましたが、今回のアップデートで全商用リージョンにおいて即座に AI モデルを利用開始できます。Amazon Bedrock コンソールや AWS SDK から直ちにアクセス可能です。ただし Anthropic モデルのみ初回利用時に一度だけ使用フォームの提出が必要です。詳細は<a href=\"https://aws.amazon.com/jp/blogs/security/simplified-amazon-bedrock-model-access/\">こちらのブログ記事</a>をご参照ください。</li> \n   <li><a href=\"https://aws.amazon.com/jp/about-aws/whats-new/2025/10/deepseek-openai-qwen-models-amazon-bedrock-additional-regions/\"><strong>DeepSeek、OpenAI、Qwen モデルが Amazon Bedrock の追加リージョンで利用可能に</strong></a><br> Amazon Bedrock で DeepSeek-V3.1、OpenAI オープンウェイトモデル、Qwen3 モデルが新たに複数リージョンで利用開始できるようになりました。オハイオ、フランクフルト、ジャカルタリージョンで利用でき、データ保管要件対応や遅延削減が可能になります。詳細は<a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html?trk=ba8b32c9-8088-419f-9258-82e9375ad130&amp;sc_channel=el\">こちらのドキュメント</a>をご参照ください。</li> \n   <li><a href=\"https://aws.amazon.com/jp/about-aws/whats-new/2025/10/amazon-sagemaker-ai-projects-custom-template-s3-provisioning/\"><strong>Amazon SageMaker AI Projects がカスタムテンプレートの S3 プロビジョニングをサポート</strong></a><br> Amazon SageMaker AI Projects で、Amazon S3 からカスタム ML プロジェクトテンプレートをプロビジョニングできるようになりました。これまで管理者は標準的な ML プロジェクトテンプレートの管理が困難でしたが、今回のアップデートにより S3 上でテンプレートを管理し、データサイエンティストが SageMaker AI Studio から直接アクセスできます。詳細は<a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-templates-custom.html\">こちらのドキュメント</a>をご参照ください。</li> \n   <li><a href=\"https://aws.amazon.com/jp/about-aws/whats-new/2025/10/amazon-elasticache-vector-search/\"><strong>Amazon ElastiCache のベクトル検索機能の発表</strong></a><br> Amazon ElastiCache でベクトル検索機能が一般提供開始しました。この機能により、AI アプリケーションで重要なベクトルデータをマイクロ秒レベルの超低遅延で検索できます。特に LLM のセマンティックキャッシングや RAG で威力を発揮し、応答速度向上とコスト削減を実現します。Valkey 8.2 で追加コストなしで利用でき、既存クラスターもダウンタイムなしでアップグレード可能です。詳細は<a href=\"https://aws.amazon.com/jp/blogs/database/announcing-vector-search-for-amazon-elasticache/\">こちらのブログ記事</a>をご参照ください。</li> \n  </ul> </li> \n</ul> \n<h1>著者について</h1> \n<footer> \n <div class=\"blog-author-box\"> \n  <div class=\"blog-author-image\">\n   <img src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2024/09/22/2JuY68JnyuKVqUN1727048653_1727048687.png\" alt=\"Naoto Kimura\" width=\"150\">\n  </div> \n  <h4 class=\"lb-h4\"><a href=\"https://x.com/_kimunao\" target=\"_blank\" rel=\"noopener\">木村 直登(Naoto Kimura)</a></h4> \n  <p>AWS Japan のソリューションアーキテクトとして、製造業のお客様に対しクラウド活用の技術支援を行なっています。最近は AI Agent と毎日戯れており、AI Agent 無しでは生きていけなくなっています。好きなうどんは’かけ’です。</p> \n </div> \n</footer>"
  },
  {
    "title": "Trocco の運用を Terraform 管理に変えてみた",
    "date": "2025-10-19T23:23:00.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/medley/articles/a68e98452e1adf",
    "content": "\n はじめに\nこんにちは、メドレーでデータエンジニアをしている山邉（@beniyama）です。\n先日、弊社で利用中の Trocco についてこちらの記事を寄稿させていただきましたが、今後の展望として以下を挙げていました。\n\n上述の通り段々と規模が大きくなってきて GUI での管理が大変になってきているため、API や Terraform 経由でのプロビジョニングも生成 AI を絡めて試していきたいです。\n\nhttps://findy-tools.io/products/trocco/17/662\n今回、Trocco の一部運用を Terraform による IaC (Infrastruc..."
  },
  {
    "title": "GitHub Copilot Coding Agent に実装を任せて、作業を並行化する",
    "date": "2025-10-19T22:00:01.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/shintaro/articles/48c0abd59a6088",
    "content": "\n GitHub Copilot Coding Agent とは\nGitHub Copilot Coding Agent は、GitHub が提供する Copilot 関連機能のひとつで、開発者の指示に応じて コードの変更や Pull Request（PR） の作成を自動で実行する自律エージェント です。\nhttps://docs.github.com/ja/copilot/concepts/agents/coding-agent\nCoding Agent は、チャット上や GitHub の UI から自然言語で依頼を受けると、その内容をもとにブランチを作成し、コードを変更し、PR を生..."
  },
  {
    "title": "自分用 LLMコーディングエージェント ノウハウまとめ 2025年10月版",
    "date": "2025-10-19T17:29:57.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/engawawa/articles/8936c60d13bafd",
    "content": "\n ■ はじめに\n\n色々情報拾ったり使ってみたりでなんとなく上手く使えてきたので現時点のノウハウをまとめる\nCLIで利用できるツールに関して主に取り扱う\n\nissueやPRでの運用は反復コストが思ったより大きくてあまりしていない\n\n\nLLMそのものの仕組みには特に触れず、ツールとしての使い方にフォーカスしている\n\n!\n自分なりの整理と共有用なので最新かつベストなやり方とは限らないので注意。\nまた、調べれば全て同等以上の内容が出てくるので、あくまで自分なりの整理と身内での共有のための文書という位置づけです。\n\n!\n定量的に性能を比較して試したりはしていないため、投稿者の主観により『なんかう..."
  },
  {
    "title": "【結論】TypeScriptの型定義はtypeよりinterfaceを使うべき理由",
    "date": "2025-10-19T15:32:46.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/bmth/articles/interface-props-extends",
    "content": "\n はじめに\nTypeScriptでコンポーネントのPropsやオブジェクトの型を定義するとき、typeとinterfaceのどちらを使うべきか、一度は悩んだことがあるのではないでしょうか。\n巷では「どちらでも良い」「チームで統一されていればOK」といった意見もよく見かけます。\nしかし、私は 明確な理由をもって「基本的にはinterfaceを使うべき」 だと主張します。\nこの記事では私の実体験で遭遇したReactのPropsの深刻なパフォーマンス問題を例に交えながら、なぜinterfaceが優れているのか、そしてtypeはどのような場面で使うべきなのかを解説します。\n\n type ali..."
  },
  {
    "title": "Private Link Serviceの新機能 Direct Connectを試してみた🚀",
    "date": "2025-10-19T13:22:39.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/mrt/articles/dd9f87f8aadd42",
    "content": "\n はじめに\n2025/10にPrivate Link ServiceのDirect Connect機能がPreview提供されました🎉\n実際に試してみながら、今回のアップデートを解説してみます！\n\n Private Link Serviceとは\nPrivate Link Serviceとは、独自のアプリを利用者側のVNetからアクセスできるように公開するための仕組みです。\n\nアプリの提供者（Provider）はPrivate Linkアクセスを有効し、利用者（Consumer）は自分のVNetにPrivate Endpointを設置してアクセスします。\nProviderのVNetとCo..."
  },
  {
    "title": "いきなりログイン画面を見せて11%のユーザーを失った",
    "date": "2025-10-19T11:17:15.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/kontaco/articles/16ccc2e51d7a4c",
    "content": "個人開発でアプリをリリースした後、インストールされたものの新規登録せずにログインを試みて離脱するユーザーが一定数いることに気づきました。\n子供向け画像認識学習アプリ「KORENANI」を開発する中で、いきなりログイン画面を表示したことで、約11%のユーザーを初回起動時に失っていました。\nなぜこの設計がユーザーを迷わせたのか、理由を分析して改善を試みた話を共有します。母数が少ない（n=96）ので、「検証」というほどではないですが、こういうこともあるよ、という感じで読んでもらえればと思います。\n\n TL;DR\n事実：\n\n初回起動後、約11%のユーザーがアカウント作成せずにログインを試みて失敗..."
  },
  {
    "title": "Amazon EC2 Capacity Manager を使用して単一のインターフェイスからキャパシティ使用量を監視、分析、管理",
    "date": "2025-10-19T08:04:45.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/monitor-analyze-and-manage-capacity-usage-from-a-single-interface-with-amazon-ec2-capacity-manager/",
    "content": "<p>10 月 16 日、Amazon EC2 Capacity Manager を発表いたしました。Amazon EC2 Capacity Manager は、すべてのアカウントと AWS リージョンのキャパシティ使用状況を単一のインターフェイスから監視、分析、管理できる一元化ソリューションです。このサービスは、キャパシティ情報を時間単位の更新レートで集約し、優先順位付けされた最適化の機会を提供します。これにより、以前はカスタムオートメーションや複数の AWS サービスからの手動のデータ収集が必要だったキャパシティ管理ワークフローが合理化されます。</p> \n<p><a href=\"https://aws.amazon.com/ec2/\">Amazon Elastic Compute Cloud (Amazon EC2)</a> を大規模に使用している組織は、オンデマンドインスタンス、スポットインスタンス、キャパシティ予約を使用して、複数のアベイラビリティーゾーンとアカウントで、何百ものインスタンスタイプを運用しています。この複雑さゆえに、お客様は現在、<a href=\"https://aws.amazon.com/console/\">AWS マネジメントコンソール</a>、<a href=\"https://aws.amazon.com/aws-cost-management/aws-cost-and-usage-reporting/\">コストと使用状況レポート</a>、<a href=\"https://aws.amazon.com/cloudwatch/\">Amazon CloudWatch</a>、EC2<code> describe</code> API などのさまざまな AWS サービスを介してキャパシティデータにアクセスしています。このような分散型の方法では、手動のデータ収集、ツール間のコンテキスト切り替え、キャパシティ最適化分析を実現するための情報集約用カスタムオートメーションが必要性となるため、運用上のオーバーヘッドが生じる可能性があります。</p> \n<p>EC2 Capacity Manager は、すべてのキャパシティデータを統一型のダッシュボードに統合することで、このような運用の複雑さを解消します。すべての商用 AWS リージョンのオンデマンドインスタンス、スポットインスタンス、キャパシティ予約のクロスアカウントおよびクロスリージョンのキャパシティメトリクスを 1 か所で確認できるようになりました。これにより、カスタムデータ収集ツールを構築したり、複数の AWS サービス間を移動したりする必要がなくなりました。</p> \n<p>この統合された可視性により、十分に活用されていないキャパシティ予約を強調し、インスタンスタイプ間の使用パターンを分析し、スポットインスタンスの中断パターンに関するインサイトを入手できるため、コスト削減の発見に役立ちます。包括的なキャパシティデータに 1 か所からアクセスできるようになると、インフラストラクチャの適切なサイジングと EC2 支出の最適化について、より多くの情報に基づく意思決定を行うことができます。</p> \n<p>EC2 Capacity Manager の機能について詳しくご紹介します。</p> \n<p><span style=\"text-decoration: underline\"><strong>EC2 Capacity Manager の開始方法<br> </strong></span>AWS マネジメントコンソールで Amazon EC2 に移動し、ナビゲーションペインで <strong>[Capacity Manager]</strong> を選択します。サービス設定を通じて EC2 Capacity Manager を有効にします。このサービスは、初期設定時に過去 14 日間の履歴データを集計します。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/12/AN2274-0.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-99780\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/12/AN2274-0.png\" alt=\"\" width=\"1924\" height=\"872\"></a></p> \n<p>メインの <strong>[ダッシュボード]</strong> では、主要なメトリクスを一目で把握できる包括的な概要セクションを通じて、すべてのインスタンスタイプのキャパシティ使用率が表示されます。<strong>[予約]</strong>、<strong>[使用状況]</strong>、<strong>[スポット]</strong> のキャパシティ概要カードには、傾向の指標と変化率が表示されるため、キャパシティパターンをすばやく特定できます。日付範囲の選択、タイムゾーンの設定、間隔の設定を含む日付フィルターコントロールを使用して、フィルタリングを適用できます。</p> \n<p>さまざまな単位を選択して、vCPU、インスタンス数、または推定コストごとにデータを分析し、リソース消費パターンを把握できます。推定コストは公開済みのオンデマンド料金に基づいており、Savings Plans やその他の割引は含まれていません。この料金リファレンスは、さまざまなインスタンスタイプで十分に活用されていないキャパシティの相対的な影響を比較するのに役立ちます。例えば、100 vCPU 時間の未使用の p5 予約は、100 vCPU 時間の未使用の t3 予約よりもコストに大きな影響を与えます。</p> \n<p>ダッシュボードには、合計使用量の視覚化グラフと使用状況の推移グラフの両方を含む詳細な <strong>[使用状況メトリクス]</strong> が含まれています。合計使用量セクションには、リザーブド使用量、非リザーブド使用量、スポット使用量の内訳が表示されます。使用量の推移グラフでは、時間の経過に伴うキャパシティの傾向を視覚化できるため、使用パターンとピーク需要期間の特定に役立ちます。</p> \n<p><strong>[予約メトリクス]</strong> の <strong>[リザーブドキャパシティの傾向]</strong> では、選択した期間の使用済みリザーブドキャパシティと未使用リザーブドキャパシティを視覚化し、アクティブに消費された時間に対する未使用のまま残っているリザーブド vCPU 時間の割合を示します。これにより、予約効率パターンを追跡し、一貫して使用率が低い期間を特定できます。この可視化により、使用率の低い予約を特定し、キャパシティの調整について情報に基づく意思決定を行えるようになるため、コスト削減に役立ちます。</p> \n<p><strong>[未使用キャパシティ]</strong> セクションには、インスタンスタイプとアベイラビリティーゾーンの組み合わせごとに十分に活用されていないキャパシティ予約が一覧表示され、さまざまなアベイラビリティーゾーンの特定の使用率とインスタンスタイプを確認できます。この優先順位付けされたリストでは、未使用のキャパシティコストを直接把握できるため、節約の可能性を特定するのに役立ちます。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/16/AN2274-1f.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-99900\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/16/AN2274-1f.png\" alt=\"\" width=\"1924\" height=\"2003\"></a></p> \n<p><strong>[使用状況]</strong> タブには、スポットインスタンス、オンデマンドインスタンス、キャパシティ予約、リザーブドインスタンス、Savings Plans のすべての AWS リージョンにわたる詳細な傾向履歴と使用統計が表示されます。専有ホストの使用状況は含まれていません。<strong>[ディメンションフィルター]</strong> を使用すると、アカウント ID、リージョン、インスタンスファミリー、アベイラビリティーゾーン、インスタンスタイプ別にキャパシティデータをグループ化およびフィルタリングして、アカウントと AWS Organizations 全体の使用パターンを明らかにするカスタムビューを作成できます。これにより、特定の設定を分析し、アカウントやリージョンのパフォーマンスを比較できます。</p> \n<p><strong>[集計]</strong> セクションには、EC2 インスタンスとスポットインスタンスの包括的な使用状況の表が表示されます。さまざまな単位を選択して、vCPU、インスタンス数、または推定コストごとにデータを分析し、リソース消費パターンを把握できます。この表には、合計使用量の統計、リザーブド使用量、未リザーブド使用時間、スポット使用量データを含むインスタンスファミリーの内訳が表示されます。各行には、詳細な分析を行うための <strong>[内訳を表示]</strong> アクションが含まれています。</p> \n<p><strong>[キャパシティ使用状況または推定コストの傾向]</strong> セクションは、使用状況の傾向、リザーブド使用量、未リザーブド使用量、スポット使用量を視覚化します。表示されたデータをフィルタリングし、測定単位を調整して履歴パターンを表示できます。これらのフィルタリングおよび分析ツールは、使用状況の傾向の特定、さまざまな側面でのコストの比較、キャパシティプランニングと最適化に関する情報に基づく意思決定に役立ちます。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/16/AN2274-2c.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-99901\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/16/AN2274-2c.png\" alt=\"\" width=\"1924\" height=\"2157\"></a></p> \n<p><strong>[集計]</strong> 表から <strong>[内訳を表示]</strong> を選択すると、選択したディメンションフィルターに基づいて詳細な <strong>[使用状況の内訳]</strong> が表示されます。この内訳ビューには、選択したファミリーとアベイラビリティーゾーンの組み合わせに含まれる個々のインスタンスタイプの使用パターンが表示され、特定の最適化の機会を特定するのに役立ちます。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/16/AN2274-3b.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-99902\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/16/AN2274-3b.png\" alt=\"\" width=\"1924\" height=\"1795\"></a></p> \n<p><strong>[予約]</strong> タブには、キャパシティ予約の使用率が表示されます。自動分析機能により、最適化の機会の優先順位リストが生成されます。<strong>[使用状況]</strong> タブと同様に、予約の詳細に関連する追加オプションとともに、アカウント ID、リージョン、インスタンスファミリー、アベイラビリティーゾーン、インスタンスタイプ別のディメンションフィルターを適用できます。各タブでは、ドリルダウンして各行の項目のデータを表示できます。特に予約については、特定の予約を表示したり、利用履歴、構成パラメータ、現在のステータスなど、オンデマンドキャパシティ予約 (ODCR) に関する詳細情報にアクセスしたりできます。ODCR が Capacity Manager と同じアカウントにある場合は、このインターフェイスから予約パラメータを直接変更できるため、予約管理を行うために別の EC2 コンソールセクションに移動する必要がなくなります。</p> \n<p><strong>[統計] </strong>セクションには、合計予約数、全体的な使用率、リザーブドキャパシティの合計、使用済みキャパシティと未使用キャパシティのボリューム、平均スケジュール済み予約数、アカウント、インスタンスファミリー、予約のあるリージョンの数などの概要メトリクスが表示されます。</p> \n<p>この統合ビューは、インフラストラクチャ全体の予約分布と利用パターンを理解するのに役立ちます。例えば、開発アカウントでは常に 30% の予約使用率を示しているのに対し、本番アカウントでは 95% を超える予約使用率が表示される場合があります。これは、予約を再配分または変更する機会があることを示しています。同様に、特定のリージョンの特定のインスタンスファミリーで使用率が低いことがわかれば、予約調整やワークロード最適化について検討できます。これらのインサイトは、予約の購入、変更、キャンセルについてデータに基づく決定を下すのに役立ち、リザーブドキャパシティを実際の使用パターンに合わせてより適切に調整できるようになります。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/16/AN2274-3c.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-99903\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/16/AN2274-3c.png\" alt=\"\" width=\"1924\" height=\"2171\"></a></p> \n<p><strong>[スポット] </strong>タブはスポットインスタンスの使用状況に焦点を当て、スポットインスタンスが中断されるまでの実行時間を表示します。このスポットインスタンスの使用パターンの分析は、スポットインスタンスワークロードの最適化の機会を特定するのに役立ちます。スポットプレースメントスコアの推奨を使用すると、ワークロードの柔軟性を高めることができます。</p> \n<p>データエクスポート機能を必要とする組織向けに、Capacity Manager にはキャパシティ分析のための <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (Amazon S3)</a> バケットへのデータエクスポートが含まれています。<strong>[データエクスポート]</strong> タブで、データエクスポートを表示および管理できます。これにより、新しいエクスポートの作成、配信ステータスの監視、AWS マネジメントコンソール外でキャパシティデータを分析するためのエクスポートスケジュールの設定を行うことができます。</p> \n<p>データをエクスポートすると、コンソールと API で利用可能な 90 日間の保持期間を超えてキャパシティデータを保存できるため、分析機能が拡張されます。この長期保存により、長期的な傾向分析と過去のキャパシティプランニングが可能になります。また、エクスポートしたデータを既存の分析ワークフロー、ビジネスインテリジェンスツール、またはカスタムレポート作成システムと統合して、EC2 キャパシティメトリクスをより広範なインフラストラクチャ分析および意思決定プロセスに組み込むこともできます。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/14/AN2274-4a.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-99831\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/14/AN2274-4a.png\" alt=\"\" width=\"1924\" height=\"851\"></a></p> \n<p><strong>[設定]</strong> セクションには、AWS Organizations 統合の設定オプションがあり、複数のアカウントでの一元的なキャパシティ管理を実現できます。組織管理者は、適切な許可とアクセス制御を維持しながら、企業全体のキャパシティの可視化を有効にしたり、特定のアカウントへのアクセスを委任したりできます。</p> \n<p><span style=\"text-decoration: underline\"><strong>今すぐご利用いただけます</strong></span><br> EC2 Capacity Manager は、複数のソースからキャパシティデータを収集して分析することによる運用上のオーバーヘッドを排除します。このサービスでは、自動化された最適化の機会、マルチアカウントの一元的な可視化、キャパシティ管理ツールへの直接アクセスが可能になります。EC2 インフラストラクチャ全体のキャパシティ利用率を向上し、コストを最適化しながら、手動の分析時間を削減できます。</p> \n<p>Amazon EC2 Capacity Manager は追加コストなしでご利用いただけます。Amazon EC2 Capacity Manager の使用を開始するには、<a href=\"https://console.aws.amazon.com/ec2/\">Amazon EC2 コンソール</a>にアクセスするか、サービス API を通じてアクセスしてください。本サービスは、すべての商用 AWS リージョンでご利用いただけます。</p> \n<p>詳細については、<a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/capacity-manager.html\">EC2 Capacity Manager のドキュメント</a>をご覧ください。</p> \n<p><a href=\"https://www.linkedin.com/in/esrakayabali/\">– Esra</a></p> \n<p>原文は<a href=\"https://aws.amazon.com/jp/blogs/aws/monitor-analyze-and-manage-capacity-usage-from-a-single-interface-with-amazon-ec2-capacity-manager/\">こちら</a>です。</p>"
  },
  {
    "title": "Rustのsqlxを使ったリポジトリ層の設計パターン",
    "date": "2025-10-19T07:20:05.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/qrtz/articles/sqlx-repo-patterns",
    "content": "sqlxはRustからデータベースを扱うためのライブラリです。Rust製のORMとしてはdieselなどの先発のライブラリがありますが、非同期処理に対応していることや、実装が簡単であるといった特長から、近年人気を集めています。\nsqlxの基礎的な使い方に関する解説記事は、比較的多くある一方で、実際のアプリケーションに導入する際の知見をまとめた記事は、あまり見受けられませんでした。\nそこで、本記事では、sqlxを実際のアプリケーションにおいて、リポジトリ層に導入する場合に、どのようなパターンを組むのが良いのかについて、考察してみたいと思います。\n\n 使用するバージョン\n\nConfig.to..."
  },
  {
    "title": "進捗報告のやり方 - Slava Akhmechet",
    "date": "2025-10-19T03:06:09.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/contradiction29/articles/f482262d1ab3c0",
    "content": "\nこの文章は、Slava Akhmechet氏の書いたブログ・エントリHow to send progress updatesを日本語に翻訳した文章です\n本人から翻訳の許可をいただき、翻訳を行いました\n良質な文章を紹介できる機会をもらえたことを、この場で感謝します\n\n\n価値のある仕事をしていると、遅かれ早かれ人々は興味を持ち、進捗状況の報告を求めるようになる。進捗報告のやり方は、四半期ごとの投資家向け報告、上司への週次報告、関係部署へのメールなど、さまざまだ。この場では、進捗報告のための効果的な方法を紹介しよう。\n\n\nまずは自分の役割を理解しよう。そして、一つ一つの報告ごとに、自分がその..."
  },
  {
    "title": "vercel/next.js – v16.0.0-canary.14",
    "date": "2025-10-19T00:09:45.000Z",
    "source": "GitHub",
    "url": "https://github.com/vercel/next.js/releases/tag/v16.0.0-canary.14",
    "content": "### Core Changes\n\n- Add Activity name to route layouts and pages: #85011\n- Update next-lint-to-eslint-cli to support `FlatCompat.config`: #85026\n- [cache components]: move flag out of experimental: #85035\n- [Cache Components] When caches are disabled in dev skip the cache warmup: #85014\n- [Cache Components] Use canary React when only Cache Components is enabled: #85042\n\n### Misc Changes\n\n- Turbopack: make tracing warning not fail build: #85032\n- [ci]: increase number of runners for test jobs: #85049\n\n### Credits \n\nHuge thanks to @acdlite, @devjiwonchoi, @mischnic, @ztanner, and @gnoff for helping!\n"
  },
  {
    "title": "vercel/next.js – v16.0.0-canary.13",
    "date": "2025-10-18T16:48:23.000Z",
    "source": "GitHub",
    "url": "https://github.com/vercel/next.js/releases/tag/v16.0.0-canary.13",
    "content": "### Core Changes\n\n- fix: incorrect canonicalUrl set when using output: export: #85019\n\n### Misc Changes\n\n- Turbopack: shard amount need to grow quadratic to cpu count to keep propability of conflicts constant: #84921\n- Turbopack: fix race condition when adding dependencies: #84946\n\n### Credits \n\nHuge thanks to @sokra and @ztanner for helping!\n"
  },
  {
    "title": "iOS ファーストな CMS をショートカットで構築する",
    "date": "2025-10-18T13:32:39.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/yamatoiizuka/articles/79ad1b2099b966",
    "content": "Web サイトの更新を iPhone から手軽にやりたい。\nたどり着いたのは iOS のショートカットから呼び出す CMS ツール群でした。\n\n 作った Web サイト\n1日につき、画像1枚と短いテキストが入る日記サイトです。\nSNS ライクな投稿ボリュームなので、絶対にスマホから更新したい。\n\nhttps://diary.yamatoiizuka.com/\nhttps://github.com/yamatoiizuka/diary\n\n CMS の要件\nビルドは GitHub Actions で走らせるものとすると、CMS の要件としては下記の2点となりました。\n\nGitHub 上の e..."
  },
  {
    "title": "iPhoneだけでiOSアプリ開発するワークフロー",
    "date": "2025-10-18T09:06:05.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/oikon/articles/dev-from-mobile",
    "content": "Oikonです。普段はAIツール、特にClaude Codeで遊んでいます。\n先日、Claude Code Meetup Tokyoがあり登壇の機会をいただきました。主催はAIエージェントユーザー会（AIAU）さまとAI駆動開発さまです。\nちなみに登壇内容は以下のスライドです：\nClaude Codeを駆使した初めてのiOSアプリ開発 ~ゼロから3週間でグローバルハッカソンで入賞するまで~\nhttps://speakerdeck.com/oikon48/claude-codewoqu-shi-sitachu-metenoiosapurikai-fa-zerokara3zhou-jian-..."
  },
  {
    "title": "vercel/next.js – v16.0.0-canary.12",
    "date": "2025-10-18T00:36:36.000Z",
    "source": "GitHub",
    "url": "https://github.com/vercel/next.js/releases/tag/v16.0.0-canary.12",
    "content": "### Core Changes\n\n- Add rendered search to router state: #84983\n- [segment cache]: delay revalidation prefetch pings 300ms: #84981\n- Show relative path from cwd for Proxy Middleware file conflict error: #84993\n- [Cache Components] fix docs for cacheLife(\"seconds\"): #85004\n- Rename MiddlewareMatcher to ProxyMatcher: #85005\n- [Breaking] Rename instrumentation onRequestError `context.routeType` from `middleware` to `proxy`: #85006\n- [turbopack] Prevent accidental access to `.next`: #84714\n\n### Misc Changes\n\n- Turbopack: Track errored tasks as dependency when using untracked(): #84914\n\n### Credits \n\nHuge thanks to @sokra, @acdlite, @ztanner, @devjiwonchoi, @lubieowoce, and @lukesandberg for helping!\n"
  },
  {
    "title": "vercel/next.js – v16.0.0-canary.11",
    "date": "2025-10-17T18:43:44.000Z",
    "source": "GitHub",
    "url": "https://github.com/vercel/next.js/releases/tag/v16.0.0-canary.11",
    "content": "### Core Changes\n\n- Relax default.tsx validation for parallel routes leaf segments: #84767\n- Add codemod for removing `unstable_` prefix: #84974\n- Interception routes match from nested route navigation: #84898\n- [Cache Components] Allow unstable prefix for cacheLife and cacheTag: #84934\n- Add codemod for removing `experimental_ppr`: #84979\n- fix: throw error during build when invalid export for Proxy: #84886\n- [cache components]: prevent expired entries from being served: #84975\n- Delete old prefetch cache related code: #84977\n- docs: Deprecation of Middleware: #84710\n\n### Misc Changes\n\n- Docs/sync with new features 0: #84861\n- Turbopack: transpile runtime with swc: #84931\n- docs: x-nextjs-stale-time header: #84901\n- docs: Templates on navigation: #84493\n- chore: Attempt to fix ppr-partial-hydration flakiness: #84672\n- Update Rspack production test manifest: #84939\n- Turbopack: rename Persistent Caching: #84896\n- Turbopack: Add ChunkedVec test case: #84756\n- docs: Add missing codemod docs: #84980\n- Update prefetching.mdx providing more clarity on the usage of `router.prefetch()`: #84903\n- docs: getting started installation and next lint removal: #84781\n- docs: Split \"Get Started: Route Handlers and Middleware\" to Route Handlers and Proxy: #84708\n- docs: Replace Middleware docs to Proxy: #84709\n- chore: Remove redundant copy of rust reqwest crate: #84982\n- [turbopack] Allow withRspack to work even if you already have NEXT_RSPACK set: #84987\n\n### Credits \n\nHuge thanks to @icyJoseph, @wyattjoh, @mischnic, @devjiwonchoi, @gnoff, @bgw, @vercel-release-bot, @sokra, @ztanner, @acdlite, @hallucinogenizer, and @lukesandberg for helping!\n"
  },
  {
    "title": "サーバー代0円！ P2Pと無料サービスだけでリアルタイム対戦オセロを作った話",
    "date": "2025-10-17T13:08:56.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/kinnkinn/articles/ff844e4d9e3ce4",
    "content": "\n 概要\nこの記事では、サーバーコストを一切かけずにブラウザだけで動作するリアルタイム対戦ゲームを開発した際の、技術的な裏側をご紹介します。WebRTC (PeerJS) によるP2P通信を主軸に、マッチングを仲介するシグナリングサーバーをRender、フロントエンドをGitHub Pagesにデプロイすることで、完全無料で遊べるブラウザオセロゲームを実現しました。\n\n\nゲームをプレイする: https://kinn00kinn.github.io/osero_p2p_front.github.io/\n\n\nフロントエンド (GitHub): https://github.com/kinn..."
  },
  {
    "title": "マウス不要！Git 操作を爆速化する「lazygit」が手放せない",
    "date": "2025-10-17T04:46:01.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/aishift/articles/d1a0551a444317",
    "content": "こんにちは！株式会社AI Shift で Web フロントエンドエンジニアをしている辰川です！\n今回は、筆者が愛用している Git の TUI ツールである lazygit について紹介します。\nhttps://github.com/jesseduffield/lazygit\n\n\n Git 操作、こんなことで困っていませんか？\ngit add して git commit して git push ...。\n日々の開発で繰り返す、この一連の Git 操作。\nターミナルでのコマンド入力は素早い反面、少し特殊な状況になると急に難解な呪文のように感じられますよね。\nかといって、GUI ツールに切り..."
  },
  {
    "title": "あなたはVersion Skew問題を知っていますか？ Web開発者なら知って損はない原因と対策",
    "date": "2025-10-17T01:52:09.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/coconala/articles/nextjs-version-skew-vercel-skew-protection",
    "content": "Webサイトのリリース後に 「一部のユーザーだけ画面が真っ白になる」「謎のエラーが飛んでくる」 といった現象に遭遇したことはありませんか？\nもしかしたら、それは Version Skew（バージョンスキュー） と呼ばれる問題のせいかもしれません。\n\n 最初に\nこんにちは。ココナラテックの開発をしているエンジニアのもちさんです。\n私はある日、手元の端末で再現性の低いエラーに悩まされました。\nブラウザキャッシュを消すと直る、でも根本原因がわからない。そんな厄介な症状の裏に、この「新旧リソースの混在」という構造的な問題が潜んでいました。\nこの記事では、実際に起きたトラブルの経緯をもとに、Ver..."
  },
  {
    "title": "Claude Codeに「次のタスクやっといて」ができるタスク管理ツール Task Master を使ってみた",
    "date": "2025-10-16T21:00:02.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/elyza/articles/49e997dde186aa",
    "content": "\n タスク管理できない人間のぼやき\n\nELYZAでプロダクト機械学習エンジニアをやっている中村(@tyo_yo_)です。\n新しい機能を実装する際、PRD (プロダクト要求仕様書: Product Requirements Document) から実装すべきタスクを一つひとつ切り出していく作業。「ここはこうで、あそこはああで...」と考えながらチケットを作る時間って、正直コーディングより疲れませんか。\nあと、歯を磨いている時にふと「あ、あの不具合直さなきゃ」と思い出す瞬間。スマホを取り出してバックログツールにメモしたり、いつのまにか混沌と化したバックログを見て目を背けてしまったり...\n弊..."
  },
  {
    "title": "LocalStack 実践入門 | AWS x Pulumi 入門ワークショップ",
    "date": "2025-10-16T15:08:26.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/kakakakakku/books/aws-pulumi-workshop-using-localstack",
    "content": "📕 この Zenn Book について\nLocalStack はローカル環境や CI 環境で実行できる AWS エミュレーターです。この Zenn Book は、LocalStack を使って Infrastructure as Code (IaC) ツールである Pulumi に入門する実践的なワークショップです。Pulumi と Pulumi AWS Provider を使った AWS リソースのデプロイを \"AWS アカウントを作らずに\" 体験できます。\n\n🚀 環境構築不要\nワークショップでは GitHub Codespaces を使うため、ラップトップ上に環境構築をする必要がなく、ブラウザですぐに試せます。\n\n⭐️ 登場する AWS サービス（順不同）\n・Amazon S3\n・AWS Lambda\n・Amazon CloudWatch Logs\n・AWS IAM\n\n🎁 完全無料\nこのワークショップは完全無料です。Chapter.1 から Chapter.9 まで、ワークショップのすべてのコンテンツを公開しています。Chapter.10 は応援購入のための付録です。このワークショップに関連する小ネタを紹介しています。このワークショップを継続的にメンテナンスしたり、また新しくワークショップを企画するモチベーションにもつながります。応援よろしくお願いします😃\n\n🎉 付録（応援購入コンテンツ）\n・AWSx (Pulumi Crosswalk for AWS) とは\n・AWS Native Provider とは\n・pulumi convert コマンドとは\n・追加課題の参考実装\n\n📅 更新履歴\n・2025/10/17: 公開しました\n\n🔗 LocalStack 実践入門シリーズ（全4冊）\n・LocalStack 実践入門 | AWS アプリケーション開発ワークショップ\n  https://zenn.dev/kakakakakku/books/aws-application-workshop-using-localstack\n・LocalStack 実践入門 | AWS サーバレスパターン開発ワークショップ\n  https://zenn.dev/kakakakakku/books/aws-serverless-pattern-workshop-using-localstack\n・LocalStack 実践入門 | AWS x Terraform 入門ワークショップ\n  https://zenn.dev/kakakakakku/books/aws-terraform-workshop-using-localstack"
  },
  {
    "title": "nodejs/node – 2025-10-15, Version 25.0.0 (Current), @RafaelGSS",
    "date": "2025-10-15T17:20:43.000Z",
    "source": "GitHub",
    "url": "https://github.com/nodejs/node/releases/tag/v25.0.0",
    "content": "Node.js 25 is here! We have upgraded V8 to **14.1**, bringing major `JSON.stringify`\r\nperformance improvements, built-in `Uint8Array` base64/hex conversion, and ongoing\r\nWebAssembly and JIT pipeline optimizations.\r\n\r\nThis release doubles down on secure-by-default apps and web-standard APIs: the permission\r\nmodel gains `--allow-net`, Web Storage is enabled by default, and `ErrorEvent` is now a global.\r\n\r\nWe’ve also removed or finalized long-deprecated APIs such as SlowBuffer,\r\nand added quality-of-life improvements like a portable compile cache and JSPI for WebAssembly.\r\n\r\n### Notable Changes\r\n\r\n* \\[[`8bc7dfd16f`](https://github.com/nodejs/node/commit/8bc7dfd16f)] - **build**: test on Python 3.14 release candidate 3 (Christian Clauss) [#59983](https://github.com/nodejs/node/pull/59983)\r\n* \\[[`663554abdf`](https://github.com/nodejs/node/commit/663554abdf)] - **(SEMVER-MAJOR)** **lib**: expose global ErrorEvent (Richie Bendall) [#58920](https://github.com/nodejs/node/pull/58920)\r\n* \\[[`3312e4e946`](https://github.com/nodejs/node/commit/3312e4e946)] - **(SEMVER-MAJOR)** **src**: unflag --experimental-webstorage by default (Daniel M Brasil) [#57666](https://github.com/nodejs/node/pull/57666)\r\n* \\[[`462c74181d`](https://github.com/nodejs/node/commit/462c74181d)] - **(SEMVER-MAJOR)** **src,permission**: add --allow-net permission (Rafael Gonzaga) [#58517](https://github.com/nodejs/node/pull/58517)\r\n\r\n### Deprecations and Removals\r\n\r\n* \\[[`d33f4b539a`](https://github.com/nodejs/node/commit/d33f4b539a)] - **(SEMVER-MAJOR)** **assert**: move assert.fail with multiple arguments to eol (James M Snell) [#58532](https://github.com/nodejs/node/pull/58532)\r\n* \\[[`b21574d63b`](https://github.com/nodejs/node/commit/b21574d63b)] - **(SEMVER-MAJOR)** **assert**: move CallTracker to EOL (James M Snell) [#58006](https://github.com/nodejs/node/pull/58006)\r\n* \\[[`308b6bc6de`](https://github.com/nodejs/node/commit/308b6bc6de)] - **(SEMVER-MAJOR)** **async\\_hooks**: move `asyncResource` property on bound function to EOL (James M Snell) [#58618](https://github.com/nodejs/node/pull/58618)\r\n* \\[[`daced4ab98`](https://github.com/nodejs/node/commit/daced4ab98)] - **(SEMVER-MAJOR)** **buffer**: move SlowBuffer to EOL (Filip Skokan) [#58220](https://github.com/nodejs/node/pull/58220)\r\n* \\[[`df16f0fd8d`](https://github.com/nodejs/node/commit/df16f0fd8d)] - **(SEMVER-MAJOR)** **child\\_process**: move \\_channel to end-of-life (James M Snell) [#58527](https://github.com/nodejs/node/pull/58527)\r\n* \\[[`a472745958`](https://github.com/nodejs/node/commit/a472745958)] - **(SEMVER-MAJOR)** **crypto**: runtime-deprecate default shake128/256 output lengths (Filip Skokan) [#59008](https://github.com/nodejs/node/pull/59008)\r\n* \\[[`c3b986853c`](https://github.com/nodejs/node/commit/c3b986853c)] - **(SEMVER-MAJOR)** **crypto**: move deprecated hash and mgf1Hash options to EOL (James M Snell) [#58706](https://github.com/nodejs/node/pull/58706)\r\n* \\[[`66632648ba`](https://github.com/nodejs/node/commit/66632648ba)] - **(SEMVER-MAJOR)** **crypto**: runtime deprecate ECDH.setPublicKey() (James M Snell) [#58620](https://github.com/nodejs/node/pull/58620)\r\n* \\[[`a5f9ca1f77`](https://github.com/nodejs/node/commit/a5f9ca1f77)] - **(SEMVER-MAJOR)** **dns**: move falsy hostname in lookup to end-of-life (James M Snell) [#58619](https://github.com/nodejs/node/pull/58619)\r\n* \\[[`2bb7667475`](https://github.com/nodejs/node/commit/2bb7667475)] - **(SEMVER-MAJOR)** **fs**: move FileHandle close on GC to EOL (James M Snell) [#58536](https://github.com/nodejs/node/pull/58536)\r\n* \\[[`eec0302088`](https://github.com/nodejs/node/commit/eec0302088)] - **(SEMVER-MAJOR)** **fs**: move rmdir recursive option to end-of-life (James M Snell) [#58616](https://github.com/nodejs/node/pull/58616)\r\n* \\[[`25dd206c29`](https://github.com/nodejs/node/commit/25dd206c29)] - **(SEMVER-MAJOR)** **fs**: remove `fs.F_OK`, `fs.R_OK`, `fs.W_OK`, `fs.X_OK` (Livia Medeiros) [#55862](https://github.com/nodejs/node/pull/55862)\r\n* \\[[`91dadf2897`](https://github.com/nodejs/node/commit/91dadf2897)] - **(SEMVER-MAJOR)** **http**: deprecate writeHeader (Sebastian Beltran) [#59060](https://github.com/nodejs/node/pull/59060)\r\n* \\[[`4e06a648ff`](https://github.com/nodejs/node/commit/4e06a648ff)] - **(SEMVER-MAJOR)** **perf\\_hooks**: move deprecated accessors to EOF (James M Snell) [#58531](https://github.com/nodejs/node/pull/58531)\r\n* \\[[`a3dfca90d1`](https://github.com/nodejs/node/commit/a3dfca90d1)] - **(SEMVER-MAJOR)** **process**: move multipleResolves event to EOL (James M Snell) [#58707](https://github.com/nodejs/node/pull/58707)\r\n* \\[[`790acc8689`](https://github.com/nodejs/node/commit/790acc8689)] - **(SEMVER-MAJOR)** **tls**: move IP-address servername deprecation to eol (James M Snell) [#58533](https://github.com/nodejs/node/pull/58533)\r\n* \\[[`3aaa2ebe19`](https://github.com/nodejs/node/commit/3aaa2ebe19)] - **(SEMVER-MAJOR)** **url**: move bad port deprecation in legacy url to end-of-life (James M Snell) [#58617](https://github.com/nodejs/node/pull/58617)\r\n\r\n### Semver-Major Commits\r\n\r\n* \\[[`7c9fbc15bc`](https://github.com/nodejs/node/commit/7c9fbc15bc)] - **(SEMVER-MAJOR)** **assert,util**: fail promise comparison in deep equal checks (Ruben Bridgewater) [#59448](https://github.com/nodejs/node/pull/59448)\r\n* \\[[`11222f1a27`](https://github.com/nodejs/node/commit/11222f1a27)] - **(SEMVER-MAJOR)** **assert,util**: handle invalid dates as equal in deep comparison (Ruben Bridgewater) [#57627](https://github.com/nodejs/node/pull/57627)\r\n* \\[[`acce2e8f87`](https://github.com/nodejs/node/commit/acce2e8f87)] - **(SEMVER-MAJOR)** **build**: reset embedder string to \"-node.0\" (Michaël Zasso) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`8a87ba031b`](https://github.com/nodejs/node/commit/8a87ba031b)] - **(SEMVER-MAJOR)** **build**: bump minimum Clang version to 19 (Michaël Zasso) [#59048](https://github.com/nodejs/node/pull/59048)\r\n* \\[[`21b131e93a`](https://github.com/nodejs/node/commit/21b131e93a)] - **(SEMVER-MAJOR)** **build**: reset embedder string to \"-node.0\" (Michaël Zasso) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`f31c88021b`](https://github.com/nodejs/node/commit/f31c88021b)] - **(SEMVER-MAJOR)** **build**: stop distributing Corepack (Antoine du Hamel) [#57617](https://github.com/nodejs/node/pull/57617)\r\n* \\[[`b3238442d8`](https://github.com/nodejs/node/commit/b3238442d8)] - **(SEMVER-MAJOR)** **deps**: patch V8 for illumos (Dan McDonald) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`2a1da3260d`](https://github.com/nodejs/node/commit/2a1da3260d)] - **(SEMVER-MAJOR)** **deps**: patch V8 to avoid duplicated zlib symbol (Michaël Zasso) [#54077](https://github.com/nodejs/node/pull/54077)\r\n* \\[[`7772a2df9d`](https://github.com/nodejs/node/commit/7772a2df9d)] - **(SEMVER-MAJOR)** **deps**: update V8 to 14.1.146.11 (Michaël Zasso) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`6d61175db0`](https://github.com/nodejs/node/commit/6d61175db0)] - **(SEMVER-MAJOR)** **deps**: V8: backport 1d3362c55396 (Shu-yu Guo) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`974773572e`](https://github.com/nodejs/node/commit/974773572e)] - **(SEMVER-MAJOR)** **deps**: V8: cherry-pick 4f38995c8295 (Shu-yu Guo) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`70bfc398e9`](https://github.com/nodejs/node/commit/70bfc398e9)] - **(SEMVER-MAJOR)** **deps**: V8: cherry-pick 044b9b6f589d (Rezvan Mahdavi Hezaveh) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`6bfc525cf0`](https://github.com/nodejs/node/commit/6bfc525cf0)] - **(SEMVER-MAJOR)** **deps**: V8: cherry-pick d2ad518a0b57 (Joyee Cheung) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`754d28e34f`](https://github.com/nodejs/node/commit/754d28e34f)] - **(SEMVER-MAJOR)** **deps**: V8: revert 6d6c1e680c7b (Michaël Zasso) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`8c508b9399`](https://github.com/nodejs/node/commit/8c508b9399)] - **(SEMVER-MAJOR)** **deps**: V8: revert e3cddbedb205 (Michaël Zasso) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`88ca8287b6`](https://github.com/nodejs/node/commit/88ca8287b6)] - **(SEMVER-MAJOR)** **deps**: use std::map in MSVC STL for EphemeronRememberedSet (Joyee Cheung) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`838e2332a5`](https://github.com/nodejs/node/commit/838e2332a5)] - **(SEMVER-MAJOR)** **deps**: patch V8 for illumos (Dan McDonald) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`3522731d9a`](https://github.com/nodejs/node/commit/3522731d9a)] - **(SEMVER-MAJOR)** **deps**: remove problematic comment from v8-internal (Michaël Zasso) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`d234475a33`](https://github.com/nodejs/node/commit/d234475a33)] - **(SEMVER-MAJOR)** **deps**: define V8\\_PRESERVE\\_MOST as no-op on Windows (Stefan Stojanovic) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`a738eb4a7f`](https://github.com/nodejs/node/commit/a738eb4a7f)] - **(SEMVER-MAJOR)** **deps**: fix FP16 bitcasts.h (Stefan Stojanovic) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`1744c7d991`](https://github.com/nodejs/node/commit/1744c7d991)] - **(SEMVER-MAJOR)** **deps**: patch V8 to avoid duplicated zlib symbol (Michaël Zasso) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`fff0d1554d`](https://github.com/nodejs/node/commit/fff0d1554d)] - **(SEMVER-MAJOR)** **deps**: update V8 to 13.7.152.9 (Michaël Zasso) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`968e2f47c8`](https://github.com/nodejs/node/commit/968e2f47c8)] - **(SEMVER-MAJOR)** **dgram**: move deprecated APIs to EOL (James M Snell) [#58474](https://github.com/nodejs/node/pull/58474)\r\n* \\[[`5623194a6b`](https://github.com/nodejs/node/commit/5623194a6b)] - **(SEMVER-MAJOR)** **doc,src,test**: replace use of deprecated `GetIsolate` (Michaël Zasso) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`823ca6991f`](https://github.com/nodejs/node/commit/823ca6991f)] - **(SEMVER-MAJOR)** **fs**: make `processReadResult()` and `readSyncRecursive()` private (Livia Medeiros) [#58672](https://github.com/nodejs/node/pull/58672)\r\n* \\[[`a273674dee`](https://github.com/nodejs/node/commit/a273674dee)] - **(SEMVER-MAJOR)** **fs**: move fs stream open method to eol (James M Snell) [#58529](https://github.com/nodejs/node/pull/58529)\r\n* \\[[`39d73036e7`](https://github.com/nodejs/node/commit/39d73036e7)] - **(SEMVER-MAJOR)** **lib**: use validators for argument validation (Nam Yooseong) [#59416](https://github.com/nodejs/node/pull/59416)\r\n* \\[[`cd68e35704`](https://github.com/nodejs/node/commit/cd68e35704)] - **(SEMVER-MAJOR)** **lib**: deprecate `_stream_*` modules (Dario Piotrowicz) [#58337](https://github.com/nodejs/node/pull/58337)\r\n* \\[[`a822a1cbe7`](https://github.com/nodejs/node/commit/a822a1cbe7)] - **(SEMVER-MAJOR)** **lib**: deprecate \\_tls\\_common and \\_tls\\_wrap (Dario Piotrowicz) [#57643](https://github.com/nodejs/node/pull/57643)\r\n* \\[[`705bcc2a00`](https://github.com/nodejs/node/commit/705bcc2a00)] - **(SEMVER-MAJOR)** **module**: move Module.\\_debug to end-of-life (James M Snell) [#58473](https://github.com/nodejs/node/pull/58473)\r\n* \\[[`5fe7800683`](https://github.com/nodejs/node/commit/5fe7800683)] - **(SEMVER-MAJOR)** **node-api**: add warning for NAPI\\_EXPERIMENTAL (Miguel Marcondes Filho) [#58280](https://github.com/nodejs/node/pull/58280)\r\n* \\[[`e1d4d6ab49`](https://github.com/nodejs/node/commit/e1d4d6ab49)] - **(SEMVER-MAJOR)** **repl**: eol deprecate instantiating without new (Aviv Keller) [#59495](https://github.com/nodejs/node/pull/59495)\r\n* \\[[`ed94bc48f3`](https://github.com/nodejs/node/commit/ed94bc48f3)] - **(SEMVER-MAJOR)** **src**: update crypto.getCipherInfo() to use DictionaryTemplate (James M Snell) [#60036](https://github.com/nodejs/node/pull/60036)\r\n* \\[[`37a3df3556`](https://github.com/nodejs/node/commit/37a3df3556)] - **(SEMVER-MAJOR)** **src**: fix calls to v8::Object::wrap (Andreas Haas) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`801ae26fa3`](https://github.com/nodejs/node/commit/801ae26fa3)] - **(SEMVER-MAJOR)** **src**: update NODE\\_MODULE\\_VERSION to 141 (Michaël Zasso) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`10df38a38b`](https://github.com/nodejs/node/commit/10df38a38b)] - **(SEMVER-MAJOR)** **src**: improve performance of dotenv ToObject (James M Snell) [#60038](https://github.com/nodejs/node/pull/60038)\r\n* \\[[`075936b413`](https://github.com/nodejs/node/commit/075936b413)] - **(SEMVER-MAJOR)** **src**: use std::string\\_view from node\\_report (iknoom) [#60006](https://github.com/nodejs/node/pull/60006)\r\n* \\[[`234c26cca3`](https://github.com/nodejs/node/commit/234c26cca3)] - **(SEMVER-MAJOR)** **src**: store `Local` for `CallbackScope` on stack (Anna Henningsen) [#59705](https://github.com/nodejs/node/pull/59705)\r\n* \\[[`708fd1945b`](https://github.com/nodejs/node/commit/708fd1945b)] - **(SEMVER-MAJOR)** **src**: remove node.h APIs to make callback without an async context (Chengzhong Wu) [#58471](https://github.com/nodejs/node/pull/58471)\r\n* \\[[`56989d33f5`](https://github.com/nodejs/node/commit/56989d33f5)] - **(SEMVER-MAJOR)** **src**: remove deprecated node::EmitBeforeExit and node::EmitExit (Chengzhong Wu) [#58469](https://github.com/nodejs/node/pull/58469)\r\n* \\[[`d429aa2d17`](https://github.com/nodejs/node/commit/d429aa2d17)] - **(SEMVER-MAJOR)** **src**: remove deprecated node::CreatePlatform and node::FreePlatform (Chengzhong Wu) [#58470](https://github.com/nodejs/node/pull/58470)\r\n* \\[[`e0ae14ce73`](https://github.com/nodejs/node/commit/e0ae14ce73)] - **(SEMVER-MAJOR)** **src**: remove deprecated node::InitializeNodeWithArgs (Chengzhong Wu) [#58470](https://github.com/nodejs/node/pull/58470)\r\n* \\[[`db1700e4b5`](https://github.com/nodejs/node/commit/db1700e4b5)] - **(SEMVER-MAJOR)** **src**: update NODE\\_MODULE\\_VERSION to 138 (Michaël Zasso) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`0a87084150`](https://github.com/nodejs/node/commit/0a87084150)] - **(SEMVER-MAJOR)** **test**: update cppgc-object addon config (StefanStojanovic) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`7dd49d7da4`](https://github.com/nodejs/node/commit/7dd49d7da4)] - **(SEMVER-MAJOR)** **test**: spin longer for sequential/test-worker-prof (Michaël Zasso) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`faba50df96`](https://github.com/nodejs/node/commit/faba50df96)] - **(SEMVER-MAJOR)** **test**: remove `--always-turbofan` flag (Michaël Zasso) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`496f12dec6`](https://github.com/nodejs/node/commit/496f12dec6)] - **(SEMVER-MAJOR)** **test**: update snapshot for V8 14.1 (Michaël Zasso) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`05aa3a1c70`](https://github.com/nodejs/node/commit/05aa3a1c70)] - **(SEMVER-MAJOR)** **test,win**: split addon tests (StefanStojanovic) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`308de27255`](https://github.com/nodejs/node/commit/308de27255)] - **(SEMVER-MAJOR)** **tools**: update V8 gypfiles for 14.0 (Michaël Zasso) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`b736370c07`](https://github.com/nodejs/node/commit/b736370c07)] - **(SEMVER-MAJOR)** **tools**: update V8 gypfiles for 13.9 (Michaël Zasso) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`085a94ac9b`](https://github.com/nodejs/node/commit/085a94ac9b)] - **(SEMVER-MAJOR)** **tools**: update V8 gypfiles for 13.8 (Michaël Zasso) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`a71ae18ac8`](https://github.com/nodejs/node/commit/a71ae18ac8)] - **(SEMVER-MAJOR)** **tools**: enable leaptiering for aix/ibmi (Abdirahim Musse) [#59805](https://github.com/nodejs/node/pull/59805)\r\n* \\[[`a8217a9eb8`](https://github.com/nodejs/node/commit/a8217a9eb8)] - **(SEMVER-MAJOR)** **tools**: update V8 gypfiles for 13.7 (Michaël Zasso) [#58064](https://github.com/nodejs/node/pull/58064)\r\n* \\[[`fdef0725de`](https://github.com/nodejs/node/commit/fdef0725de)] - **(SEMVER-MAJOR)** **util,console**: colorize regexp groups, character classes, etc (Ruben Bridgewater) [#59710](https://github.com/nodejs/node/pull/59710)\r\n* \\[[`411cc42d22`](https://github.com/nodejs/node/commit/411cc42d22)] - **(SEMVER-MAJOR)** **worker**: move terminate callback to end-of-life (James M Snell) [#58528](https://github.com/nodejs/node/pull/58528)\r\n\r\n### Semver-Minor Commits\r\n\r\n* \\[[`94422e8a40`](https://github.com/nodejs/node/commit/94422e8a40)] - **(SEMVER-MINOR)** **src**: add an option to make compile cache portable (Aditi) [#58797](https://github.com/nodejs/node/pull/58797)\r\n* \\[[`29738c7b42`](https://github.com/nodejs/node/commit/29738c7b42)] - **(SEMVER-MINOR)** **src,permission**: add --allow-inspector ability (Rafael Gonzaga) [#59711](https://github.com/nodejs/node/pull/59711)\r\n* \\[[`f9fcc746f3`](https://github.com/nodejs/node/commit/f9fcc746f3)] - **(SEMVER-MINOR)** **v8**: add cpu profile (theanarkh) [#59807](https://github.com/nodejs/node/pull/59807)\r\n* \\[[`4396cf2d45`](https://github.com/nodejs/node/commit/4396cf2d45)] - **(SEMVER-MINOR)** **wasm**: enable JSPI (Guy Bedford) [#59941](https://github.com/nodejs/node/pull/59941)\r\n\r\n### Semver-Patch Commits\r\n\r\n* \\[[`91f035e597`](https://github.com/nodejs/node/commit/91f035e597)] - **assert**: resolve TODO and rename function (Antoine du Hamel) [#59451](https://github.com/nodejs/node/pull/59451)\r\n* \\[[`2e675c4fa3`](https://github.com/nodejs/node/commit/2e675c4fa3)] - **benchmark**: use non-deprecated WriteUtf8V2 method (Michaël Zasso) [#60173](https://github.com/nodejs/node/pull/60173)\r\n* \\[[`0fb040603b`](https://github.com/nodejs/node/commit/0fb040603b)] - **build**: upgrade Python linter ruff, add rules ASYNC,PERF (Christian Clauss) [#59984](https://github.com/nodejs/node/pull/59984)\r\n* \\[[`f468b6c72b`](https://github.com/nodejs/node/commit/f468b6c72b)] - **build**: update minimum Xcode version to 16.4 (Michaël Zasso) [#60079](https://github.com/nodejs/node/pull/60079)\r\n* \\[[`0eda17ba20`](https://github.com/nodejs/node/commit/0eda17ba20)] - **build**: fix flags for ngtcp2 on IBM i (SRAVANI GUNDEPALLI) [#60073](https://github.com/nodejs/node/pull/60073)\r\n* \\[[`22a864a275`](https://github.com/nodejs/node/commit/22a864a275)] - **build**: remove corepack from release tarballs (Jordan Harband) [#59835](https://github.com/nodejs/node/pull/59835)\r\n* \\[[`7079041e0a`](https://github.com/nodejs/node/commit/7079041e0a)] - **build**: only mention Apple when on Apple (Michaël Zasso) [#59385](https://github.com/nodejs/node/pull/59385)\r\n* \\[[`954d3f44ef`](https://github.com/nodejs/node/commit/954d3f44ef)] - **build**: check Apple clang version in configure script (Michaël Zasso) [#59358](https://github.com/nodejs/node/pull/59358)\r\n* \\[[`2b4a09ef8b`](https://github.com/nodejs/node/commit/2b4a09ef8b)] - **build**: fix OpenSSL version detection (Richard Lau) [#59353](https://github.com/nodejs/node/pull/59353)\r\n* \\[[`af77e4bf2f`](https://github.com/nodejs/node/commit/af77e4bf2f)] - **build**: update macOS runner and Xcode (Michaël Zasso) [#59238](https://github.com/nodejs/node/pull/59238)\r\n* \\[[`86bfdb5528`](https://github.com/nodejs/node/commit/86bfdb5528)] - **build**: remove `nocorepack` `vcbuild` flag (Antoine du Hamel) [#57772](https://github.com/nodejs/node/pull/57772)\r\n* \\[[`b13f24c2da`](https://github.com/nodejs/node/commit/b13f24c2da)] - **build, src**: fix include paths for vtune files (Rahul) [#59999](https://github.com/nodejs/node/pull/59999)\r\n* \\[[`2216a3b1d5`](https://github.com/nodejs/node/commit/2216a3b1d5)] - **deps**: V8: cherry-pick 1e190bbb0396 (Richard Lau) [#60206](https://github.com/nodejs/node/pull/60206)\r\n* \\[[`1b22f6049a`](https://github.com/nodejs/node/commit/1b22f6049a)] - **deps**: upgrade npm to 11.6.2 (npm team) [#60168](https://github.com/nodejs/node/pull/60168)\r\n* \\[[`a1b73fe430`](https://github.com/nodejs/node/commit/a1b73fe430)] - **deps**: V8: cherry-pick 2abc61361dd4 (Richard Lau) [#60177](https://github.com/nodejs/node/pull/60177)\r\n* \\[[`4eb6e6fd79`](https://github.com/nodejs/node/commit/4eb6e6fd79)] - **deps**: V8: cherry-pick 87356585659b (Joyee Cheung) [#60069](https://github.com/nodejs/node/pull/60069)\r\n* \\[[`c0b8c80164`](https://github.com/nodejs/node/commit/c0b8c80164)] - **deps**: define V8\\_PRESERVE\\_MOST as no-op on Windows (Stefan Stojanovic) [#56238](https://github.com/nodejs/node/pull/56238)\r\n* \\[[`65a32bac18`](https://github.com/nodejs/node/commit/65a32bac18)] - **deps**: add ngtcp2 test binaries (James M Snell) [#59946](https://github.com/nodejs/node/pull/59946)\r\n* \\[[`ebfc28a037`](https://github.com/nodejs/node/commit/ebfc28a037)] - **deps**: update nghttp3 to 1.11.0 (James M Snell) [#59249](https://github.com/nodejs/node/pull/59249)\r\n* \\[[`dceb1fca40`](https://github.com/nodejs/node/commit/dceb1fca40)] - **deps**: update ngtcp2 to 1.14.0 (James M Snell) [#59249](https://github.com/nodejs/node/pull/59249)\r\n* \\[[`ee36b86ba3`](https://github.com/nodejs/node/commit/ee36b86ba3)] - **deps**: patch V8 to 13.7.152.19 (Node.js GitHub Bot) [#58713](https://github.com/nodejs/node/pull/58713)\r\n* \\[[`0b3fc0d7a8`](https://github.com/nodejs/node/commit/0b3fc0d7a8)] - **deps**: patch V8 to 13.7.152.14 (Node.js GitHub Bot) [#58631](https://github.com/nodejs/node/pull/58631)\r\n* \\[[`91b3bd3fe6`](https://github.com/nodejs/node/commit/91b3bd3fe6)] - **deps**: patch V8 to 13.7.152.13 (Node.js GitHub Bot) [#58539](https://github.com/nodejs/node/pull/58539)\r\n* \\[[`f77a96cd76`](https://github.com/nodejs/node/commit/f77a96cd76)] - **deps**: patch V8 to 13.7.152.10 (Node.js GitHub Bot) [#58446](https://github.com/nodejs/node/pull/58446)\r\n* \\[[`1cd16e5355`](https://github.com/nodejs/node/commit/1cd16e5355)] - **doc**: improve code snippet alternative of url.parse() using WHATWG URL (Steven) [#60209](https://github.com/nodejs/node/pull/60209)\r\n* \\[[`d54e6aec9e`](https://github.com/nodejs/node/commit/d54e6aec9e)] - **doc**: `createSQLTagStore` -> `createTagStore` (Aviv Keller) [#60182](https://github.com/nodejs/node/pull/60182)\r\n* \\[[`aef3fc37eb`](https://github.com/nodejs/node/commit/aef3fc37eb)] - **doc**: use markdown when branch-diff major release (Rafael Gonzaga) [#60179](https://github.com/nodejs/node/pull/60179)\r\n* \\[[`a2f088d516`](https://github.com/nodejs/node/commit/a2f088d516)] - **doc**: update teams in collaborator-guide.md and add links (Bart Louwers) [#60065](https://github.com/nodejs/node/pull/60065)\r\n* \\[[`75a6fff6be`](https://github.com/nodejs/node/commit/75a6fff6be)] - **doc**: disambiguate top-level `worker_threads` module exports (René) [#59890](https://github.com/nodejs/node/pull/59890)\r\n* \\[[`51df7b92bc`](https://github.com/nodejs/node/commit/51df7b92bc)] - **doc**: update macOS version used to build releases (Michaël Zasso) [#60080](https://github.com/nodejs/node/pull/60080)\r\n* \\[[`910c8796f9`](https://github.com/nodejs/node/commit/910c8796f9)] - **doc**: update BUILDING to reflect Clang 19 changes (Michaël Zasso) [#59782](https://github.com/nodejs/node/pull/59782)\r\n* \\[[`34f9b7eab9`](https://github.com/nodejs/node/commit/34f9b7eab9)] - **doc**: reserve NMV 140 for Electron 39 (David Sanders) [#59627](https://github.com/nodejs/node/pull/59627)\r\n* \\[[`3f6f6db43f`](https://github.com/nodejs/node/commit/3f6f6db43f)] - **doc**: update minimum Xcode and VS versions (Michaël Zasso) [#59358](https://github.com/nodejs/node/pull/59358)\r\n* \\[[`d9fe28bd6b`](https://github.com/nodejs/node/commit/d9fe28bd6b)] - **doc**: fix `CHANGELOG.md` version listing (Antoine du Hamel) [#59299](https://github.com/nodejs/node/pull/59299)\r\n* \\[[`0ab50c2768`](https://github.com/nodejs/node/commit/0ab50c2768)] - **doc**: reserve NMV 139 for Electron 38 (Calvin) [#58779](https://github.com/nodejs/node/pull/58779)\r\n* \\[[`516b4ebd3c`](https://github.com/nodejs/node/commit/516b4ebd3c)] - **doc**: mark Node.js 23 as End-of-Life (Antoine du Hamel) [#58563](https://github.com/nodejs/node/pull/58563)\r\n* \\[[`59b70e5fe3`](https://github.com/nodejs/node/commit/59b70e5fe3)] - **http**: fix http client leaky with double response (theanarkh) [#60062](https://github.com/nodejs/node/pull/60062)\r\n* \\[[`5cf3c3e24c`](https://github.com/nodejs/node/commit/5cf3c3e24c)] - **http2**: rename variable to additionalPseudoHeaders (Tobias Nießen) [#60208](https://github.com/nodejs/node/pull/60208)\r\n* \\[[`535efea962`](https://github.com/nodejs/node/commit/535efea962)] - **http2**: do not crash on mismatched ping buffer length (René) [#60135](https://github.com/nodejs/node/pull/60135)\r\n* \\[[`4bfa387f6d`](https://github.com/nodejs/node/commit/4bfa387f6d)] - **lib**: fix constructor in \\_errnoException stack tree (SeokHun) [#60156](https://github.com/nodejs/node/pull/60156)\r\n* \\[[`4daeec11b9`](https://github.com/nodejs/node/commit/4daeec11b9)] - **lib**: fix typo in QuicSessionStats (SeokHun) [#60155](https://github.com/nodejs/node/pull/60155)\r\n* \\[[`15278252bb`](https://github.com/nodejs/node/commit/15278252bb)] - **lib**: remove redundant destroyHook checks (Gürgün Dayıoğlu) [#60120](https://github.com/nodejs/node/pull/60120)\r\n* \\[[`83052ff9ad`](https://github.com/nodejs/node/commit/83052ff9ad)] - **lib**: add `node:` prefix in sys module deprecation warning (Dario Piotrowicz) [#58442](https://github.com/nodejs/node/pull/58442)\r\n* \\[[`d5abfbf582`](https://github.com/nodejs/node/commit/d5abfbf582)] - **lib**: add module to use in module deprecation warnings (Dario Piotrowicz) [#58442](https://github.com/nodejs/node/pull/58442)\r\n* \\[[`db0121bedd`](https://github.com/nodejs/node/commit/db0121bedd)] - **module**: fix directory option in the enableCompileCache() API (Joyee Cheung) [#59931](https://github.com/nodejs/node/pull/59931)\r\n* \\[[`822a8c3244`](https://github.com/nodejs/node/commit/822a8c3244)] - **perf\\_hooks**: fix stack overflow error (Antoine du Hamel) [#60084](https://github.com/nodejs/node/pull/60084)\r\n* \\[[`d52cd04591`](https://github.com/nodejs/node/commit/d52cd04591)] - **quic**: continue working on quic api bits (James M Snell) [#60123](https://github.com/nodejs/node/pull/60123)\r\n* \\[[`b4af647920`](https://github.com/nodejs/node/commit/b4af647920)] - **quic**: reduce boilerplate and other minor cleanups (James M Snell) [#59342](https://github.com/nodejs/node/pull/59342)\r\n* \\[[`cd9fd09a27`](https://github.com/nodejs/node/commit/cd9fd09a27)] - **quic**: multiple fixups and updates (James M Snell) [#59342](https://github.com/nodejs/node/pull/59342)\r\n* \\[[`a6c5d27739`](https://github.com/nodejs/node/commit/a6c5d27739)] - **quic**: update more of the quic to the new compile guard (James M Snell) [#59342](https://github.com/nodejs/node/pull/59342)\r\n* \\[[`ee7b8ab29c`](https://github.com/nodejs/node/commit/ee7b8ab29c)] - **quic**: few additional small comment edits in cid.h (James M Snell) [#59342](https://github.com/nodejs/node/pull/59342)\r\n* \\[[`c8b64bd023`](https://github.com/nodejs/node/commit/c8b64bd023)] - **quic**: fixup NO\\_ERROR macro conflict on windows (James M Snell) [#59381](https://github.com/nodejs/node/pull/59381)\r\n* \\[[`e2fefd78e2`](https://github.com/nodejs/node/commit/e2fefd78e2)] - **quic**: fixup windows coverage compile error (James M Snell) [#59381](https://github.com/nodejs/node/pull/59381)\r\n* \\[[`99c80e3a45`](https://github.com/nodejs/node/commit/99c80e3a45)] - **quic**: update the guard to check openssl version (James M Snell) [#59249](https://github.com/nodejs/node/pull/59249)\r\n* \\[[`0e754fa5d1`](https://github.com/nodejs/node/commit/0e754fa5d1)] - **quic**: start re-enabling quic with openssl 3.5 (James M Snell) [#59249](https://github.com/nodejs/node/pull/59249)\r\n* \\[[`200fe9e7f4`](https://github.com/nodejs/node/commit/200fe9e7f4)] - **repl**: move completion logic to internal module (Dario Piotrowicz) [#59889](https://github.com/nodejs/node/pull/59889)\r\n* \\[[`3ac88a7a66`](https://github.com/nodejs/node/commit/3ac88a7a66)] - **src**: use string\\_view in `WriteReport()` (Anna Henningsen) [#60201](https://github.com/nodejs/node/pull/60201)\r\n* \\[[`a1244f04de`](https://github.com/nodejs/node/commit/a1244f04de)] - **src**: make additional cleanups in node locks impl (James M Snell) [#60061](https://github.com/nodejs/node/pull/60061)\r\n* \\[[`fdb6e66227`](https://github.com/nodejs/node/commit/fdb6e66227)] - **src**: update locks to use DictionaryTemplate (James M Snell) [#60061](https://github.com/nodejs/node/pull/60061)\r\n* \\[[`367bcce6a6`](https://github.com/nodejs/node/commit/367bcce6a6)] - **src**: fix usage of deprecated V8 API (Michaël Zasso) [#60174](https://github.com/nodejs/node/pull/60174)\r\n* \\[[`23fa18444f`](https://github.com/nodejs/node/commit/23fa18444f)] - **src**: fix small compile warning in quic/streams.cc (James M Snell) [#60118](https://github.com/nodejs/node/pull/60118)\r\n* \\[[`0ec1d186f4`](https://github.com/nodejs/node/commit/0ec1d186f4)] - **src**: always use strong reference to `napi_async_context` resource (Anna Henningsen) [#59828](https://github.com/nodejs/node/pull/59828)\r\n* \\[[`ce748f6cae`](https://github.com/nodejs/node/commit/ce748f6cae)] - **src**: use `Global` for storing resource in Node-API callback scope (Anna Henningsen) [#59828](https://github.com/nodejs/node/pull/59828)\r\n* \\[[`36256230b4`](https://github.com/nodejs/node/commit/36256230b4)] - **src**: cleanup quic TransportParams class (James M Snell) [#59884](https://github.com/nodejs/node/pull/59884)\r\n* \\[[`985e2fb383`](https://github.com/nodejs/node/commit/985e2fb383)] - _**Revert**_ \"**test**: ensure message event fires in worker message port test\" (Luigi Pinca) [#60126](https://github.com/nodejs/node/pull/60126)\r\n* \\[[`da9cd745c8`](https://github.com/nodejs/node/commit/da9cd745c8)] - **test**: ensure assertions are reachable in `test/client-proxy` (Antoine du Hamel) [#60175](https://github.com/nodejs/node/pull/60175)\r\n* \\[[`e105e821e9`](https://github.com/nodejs/node/commit/e105e821e9)] - **test**: skip quic tests that IBM i does not support (SRAVANI GUNDEPALLI) [#60160](https://github.com/nodejs/node/pull/60160)\r\n* \\[[`bfc81ca228`](https://github.com/nodejs/node/commit/bfc81ca228)] - **test**: ensure assertions are reachable in `test/async-hooks` (Antoine du Hamel) [#60150](https://github.com/nodejs/node/pull/60150)\r\n* \\[[`712cee951c`](https://github.com/nodejs/node/commit/712cee951c)] - **test**: skip tests that cause timeouts on IBM i (SRAVANI GUNDEPALLI) [#60148](https://github.com/nodejs/node/pull/60148)\r\n* \\[[`f8a43f6f34`](https://github.com/nodejs/node/commit/f8a43f6f34)] - **test**: deflake test-fs-promises-watch-iterator (Luigi Pinca) [#60060](https://github.com/nodejs/node/pull/60060)\r\n* \\[[`1f95d39997`](https://github.com/nodejs/node/commit/1f95d39997)] - **test**: prepare junit file attribute normalization (sangwook) [#59432](https://github.com/nodejs/node/pull/59432)\r\n* \\[[`eb159a8cfd`](https://github.com/nodejs/node/commit/eb159a8cfd)] - **test**: remove duplicated allocUnsafeSlow test (Michaël Zasso) [#58524](https://github.com/nodejs/node/pull/58524)\r\n* \\[[`d93cff5af3`](https://github.com/nodejs/node/commit/d93cff5af3)] - _**Revert**_ \"**test**: fix watch tests not including completion messages\" (Joyee Cheung) [#58190](https://github.com/nodejs/node/pull/58190)\r\n* \\[[`6102159fa1`](https://github.com/nodejs/node/commit/6102159fa1)] - **test**: fix watch tests not including completion messages (Dario Piotrowicz) [#58183](https://github.com/nodejs/node/pull/58183)\r\n* \\[[`ad2c1bf62e`](https://github.com/nodejs/node/commit/ad2c1bf62e)] - **test,doc**: skip --max-old-space-size-percentage on 32-bit platforms (Asaf Federman) [#60144](https://github.com/nodejs/node/pull/60144)\r\n* \\[[`6dbf7086bb`](https://github.com/nodejs/node/commit/6dbf7086bb)] - **test\\_runner**: fix suite timeout (Moshe Atlow) [#59853](https://github.com/nodejs/node/pull/59853)\r\n* \\[[`f0aa073907`](https://github.com/nodejs/node/commit/f0aa073907)] - **test\\_runner**: add junit file attribute support (sangwook) [#59432](https://github.com/nodejs/node/pull/59432)\r\n* \\[[`cff138c6b1`](https://github.com/nodejs/node/commit/cff138c6b1)] - **tests**: start adding quic test server utilities (James M Snell) [#59946](https://github.com/nodejs/node/pull/59946)\r\n* \\[[`20dc4b514a`](https://github.com/nodejs/node/commit/20dc4b514a)] - **tools**: use cooldown property correctly (Rafael Gonzaga) [#60134](https://github.com/nodejs/node/pull/60134)\r\n* \\[[`ec26b1c01a`](https://github.com/nodejs/node/commit/ec26b1c01a)] - **tools**: add lint rule to ensure assertions are reached (Antoine du Hamel) [#60125](https://github.com/nodejs/node/pull/60125)\r\n* \\[[`bab752d4db`](https://github.com/nodejs/node/commit/bab752d4db)] - **typings**: add buffer internalBinding typing (방진혁) [#60163](https://github.com/nodejs/node/pull/60163)\r\n* \\[[`1986ee4b65`](https://github.com/nodejs/node/commit/1986ee4b65)] - **vm**: hint module identifier in instantiate errors (Chengzhong Wu) [#60199](https://github.com/nodejs/node/pull/60199)\r\n* \\[[`23b834058c`](https://github.com/nodejs/node/commit/23b834058c)] - **wasm**: revert enable JSPI as already enabled (Guy Bedford) [#60014](https://github.com/nodejs/node/pull/60014)\r\n* \\[[`4bfcad1ac5`](https://github.com/nodejs/node/commit/4bfcad1ac5)] - _**Revert**_ \"**watch**: fix watch args not being properly filtered\" (Joyee Cheung) [#58190](https://github.com/nodejs/node/pull/58190)\r\n* \\[[`4acb854039`](https://github.com/nodejs/node/commit/4acb854039)] - **watch**: fix watch args not being properly filtered (Dario Piotrowicz) [#57936](https://github.com/nodejs/node/pull/57936)\r\n"
  }
]