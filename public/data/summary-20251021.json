[
  {
    "title": "vercel/next.js – v16.0.0-canary.17",
    "date": "2025-10-21T16:38:00.000Z",
    "source": "GitHub",
    "url": "https://github.com/vercel/next.js/releases/tag/v16.0.0-canary.17",
    "content": "### Core Changes\n\n- Fix subtree layout alignment for route summary in `next build`: #85137\n- [codemod] Remove runtime config when running `middleware-to-proxy`: #85075\n- [turbopack] Improve the multiple bundler flags messge to note that perhaps your `package.json` is the problem: #85118\n- Add Learn more docs to Middleware deprecation warning: #84711\n- [BF Cache]: skip lazyData fetch logic for inactive segments: #85142\n- Pass `startTime` to initial RSC payload stream: #85144\n- guard navigation `use` hooks for React 18: #85151\n- [turbopack] Don't warn on the lightning css experimental option: #84913\n- Turbopack: Remove redundant log line, increase delay for compiling log message: #85133\n- Make params and searchParams new Promises: #85158\n- Name \"cache\" streams for React DevTools: #85159\n- Use cacheMaxMemorySize config in default cache handler: #85153\n- Omit params to from client segments: #84883\n- enable experimental.routerBfCache behind cacheComponents: #84923\n- [Cache Components] Allow stale longer than expire in cacheLife: #85115\n- Update Activity names given to routes: #85155\n- use port zero for --inspect when forking, if used by parent: #85128\n- Update blocking prerender error message: #85087\n\n### Misc Changes\n\n- Turbopack: Disable LightningCSS MediaRangeSyntax feature: #85086\n- Don't expliclitly set the `--turbopack` flag in Create Next App, it is no longer necessary: #85117\n- [turbopack] Remove the canary icon from the cache components docs: #85149\n- Bump swc to v45: #85143\n- [test] Fix test-dev with --projects: #85167\n- [test] Update snapshots: #85171\n- docs: mcp: #85010\n\n### Credits \n\nHuge thanks to @eps1lon, @devjiwonchoi, @lukesandberg, @timneutkens, @ztanner, @acdlite, @mischnic, @bgw, @sebmarkbage, @wyattjoh, @gnoff, @huozhi, and @seeplusplus for helping!\n"
  },
  {
    "title": "AWS DMS 3.5.4 におけるデータマスキングとパフォーマンス向上",
    "date": "2025-10-21T09:05:27.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/aws-dms-data-masking-performance/",
    "content": "<p><em>本投稿は、Suchindranath Hegde と Mahesh Kansaraと Leonid Slepukhinと Sridhar Ramasubramanian による記事 「<a href=\"https://aws.amazon.com/jp/blogs/database/data-masking-and-performance-improvements-in-aws-dms-3-5-4/\" target=\"_blank\" rel=\"noopener\">Data masking and performance improvements in AWS DMS 3.5.4</a>」を翻訳したものです。</em></p> \n<p><a href=\"https://aws.amazon.com/dms/\" target=\"_blank\" rel=\"noopener\">AWS Database Migration Service (AWS DMS)</a> のレプリケーションエンジンバージョン 3.5.4 で新機能が利用可能になったことをお知らせできることを嬉しく思います。<br> このリリースには、セキュリティ強化のためのデータマスキングと、データ検証時のパフォーマンス向上という 2 つの主要な機能強化が含まれています。</p> \n<p>この投稿では、これら 2 つの機能について詳しく説明します。この新バージョンで利用可能なすべての新機能のリストは、<a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_ReleaseNotes.html#CHAP_ReleaseNotes.DMS354\" target=\"_blank\" rel=\"noopener\">リリースノート</a>を参照してください。</p> \n<h2>セキュリティ強化のためのデータマスキング</h2> \n<p>データ保護を強化するため、お客様からデータマスキング機能のリクエストがありました。これにより、移行中にカラムレベルで機密データを変換し、GDPR などのデータ保護規制への準拠を支援します。AWS DMS を使用することで、カラムレベルで保護が必要な情報を編集したデータのコピーを作成できるようになりました。</p> \n<p>データベース移行中のお客様にとって最大の懸念事項の 1 つは、口座番号、電話番号、メールアドレスなどの機密情報の安全な取り扱いです。AWS DMS 3.5.4 では、3 つの柔軟な<a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Tasks.CustomizingTasks.TableMapping.SelectionTransformation.Masking.html\" target=\"_blank\" rel=\"noopener\">データ変換ルール</a>を実装しました：</p> \n<ul> \n <li>数字マスク</li> \n <li>数字のランダム化</li> \n <li>ハッシュマスク</li> \n</ul> \n<p>これらの変換ルールを説明するために、「EMPLOYEES」というテーブルを <a href=\"https://aws.amazon.com/rds/oracle/\" target=\"_blank\" rel=\"noopener\">Amazon RDS for Oracle インスタンス</a>から <a href=\"https://aws.amazon.com/rds/postgresql/\" target=\"_blank\" rel=\"noopener\">Amazon RDS for PostgreSQL</a> インスタンスに移行します。<br> 以下の手順を完了してください：</p> \n<ol start=\"1\"> \n <li>ソース (Oracle) インスタンスで以下のテーブル DDL を使用して EMPLOYEES テーブルを作成します：</li> \n</ol> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-bash\">CREATE TABLE EMPLOYEES (\n    EMPLOYEE_ID NUMBER(6) PRIMARY KEY,\n    FIRST_NAME VARCHAR2(50) NOT NULL,\n    LAST_NAME VARCHAR2(50) NOT NULL,\n    EMAIL VARCHAR2(100) UNIQUE,\n    PHONE_NUMBER VARCHAR2(20),\n    HIRE_DATE DATE NOT NULL,\n    JOB_TITLE VARCHAR2(50),\n    SALARY NUMBER(10,2),\n    DEPARTMENT_ID NUMBER(4),\n    MANAGER_ID NUMBER(6),\n    ACCOUNT_NUMBER VARCHAR2(20),\n    CREATED_DATE DATE DEFAULT SYSDATE \n  \n);\n CREATE SEQUENCE emp_seq \n    START WITH 1 \n    INCREMENT BY 1 \n    NOCACHE \n    NOCYCLE ;\n</code></pre> \n</div> \n<ol start=\"2\"> \n <li>EMPLOYEES テーブルにいくつかのレコードを挿入します。</li> \n</ol> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-bash\">INSERT INTO EMPLOYEES (EMPLOYEE_ID, FIRST_NAME, LAST_NAME, EMAIL, PHONE_NUMBER, HIRE_DATE, JOB_TITLE, SALARY, DEPARTMENT_ID, MANAGER_ID,ACCOUNT_NUMBER)\n VALUES (emp_seq.NEXTVAL, 'John', 'Smith', 'john.smith@company.com', '555-0101', DATE '2020-01-15', 'CEO', 150000, 10, NULL,'456-123-456-789');\n\n INSERT INTO EMPLOYEES (EMPLOYEE_ID, FIRST_NAME, LAST_NAME, EMAIL, PHONE_NUMBER, HIRE_DATE, JOB_TITLE, SALARY, DEPARTMENT_ID, MANAGER_ID,ACCOUNT_NUMBER)\n VALUES (emp_seq.NEXTVAL, 'Sarah', 'Johnson', 'sarah.johnson@company.com', '555-0102', DATE '2020-03-20', 'IT Director', 120000, 20, 1,'666-000-111-222');\n\n INSERT INTO EMPLOYEES (EMPLOYEE_ID, FIRST_NAME, LAST_NAME, EMAIL, PHONE_NUMBER, HIRE_DATE, JOB_TITLE, SALARY, DEPARTMENT_ID, MANAGER_ID,ACCOUNT_NUMBER)\n VALUES (emp_seq.NEXTVAL, 'Michael', 'Brown', 'michael.brown@company.com', '555-0103', DATE '2021-02-10', 'Software Engineer', 85000, 20, 2,'777-333-444-555');\n\n INSERT INTO EMPLOYEES (EMPLOYEE_ID, FIRST_NAME, LAST_NAME, EMAIL, PHONE_NUMBER, HIRE_DATE, JOB_TITLE, SALARY, DEPARTMENT_ID, MANAGER_ID,ACCOUNT_NUMBER)\n VALUES (emp_seq.NEXTVAL, 'Emily', 'Davis', 'emily.davis@company.com', '555-0104', DATE '2021-06-15', 'HR Manager', 75000, 30, 1,'899-987-654-321');\n\n INSERT INTO EMPLOYEES (EMPLOYEE_ID, FIRST_NAME, LAST_NAME, EMAIL, PHONE_NUMBER, HIRE_DATE, JOB_TITLE, SALARY, DEPARTMENT_ID, MANAGER_ID,ACCOUNT_NUMBER)\n VALUES (emp_seq.NEXTVAL, 'David', 'Wilson', 'david.wilson@company.com', '555-0105', DATE '2022-01-20', 'Software Engineer', 80000, 20, 2,'567-111-222-333');</code></pre> \n</div> \n<ol start=\"3\"> \n <li>「移行のみ」または「移行および複製」オプションを使用して <a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Tasks.Creating.html\" target=\"_blank\" rel=\"noopener\">AWS DMS タスクを作成</a> します。</li> \n</ol> \n<ol start=\"4\"> \n <li>次のテーブルマッピングルール JSON を使用して AWS DMS タスクを設定します。<code>ACCOUNT_NUMBER</code> 列には文字 <code>#</code>で、<code>PHONE_NUMBER</code>列には乱数で、<code>EMAIL</code>列にはハッシュでマスキングします。また、変換ルールを使用してすべての文字を小文字に変換するなど一部の文字を変換していますが、これはオプションです。</li> \n</ol> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-bash\">{\n&nbsp;&nbsp; &nbsp;\"rules\": [ \n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-type\": \"transformation\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-id\": \"171087779\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-name\": \"171087779\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-target\": \"column\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"object-locator\": {\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"schema-name\": \"ADMIN\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"table-name\": \"EMPLOYEES\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"column-name\": \"ACCOUNT_NUMBER\"\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-action\": \"data-masking-digits-mask\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"value\": \"*\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"old-value\": null \n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-type\": \"transformation\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-id\": \"171057753\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-name\": \"171057753\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-target\": \"column\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"object-locator\": {\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"schema-name\": \"ADMIN\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"table-name\": \"EMPLOYEES\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"column-name\": \"PHONE_NUMBER\"\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-action\": \"data-masking-digits-randomize\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"value\": null,\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"old-value\": null \n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-type\": \"transformation\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-id\": \"169940283\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-name\": \"169940283\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-target\": \"column\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"object-locator\": {\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"schema-name\": \"ADMIN\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"table-name\": \"EMPLOYEES\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"column-name\": \"EMAIL\"\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-action\": \"data-masking-hash-mask\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"value\": null,\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"old-value\": null \n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-type\": \"transformation\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-id\": \"169926638\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-name\": \"169926638\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-target\": \"column\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"object-locator\": {\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"schema-name\": \"%\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"table-name\": \"%\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"column-name\": \"%\"\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-action\": \"convert-lowercase\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"value\": null,\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"old-value\": null \n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-type\": \"transformation\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-id\": \"169918368\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-name\": \"169918368\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-target\": \"table\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"object-locator\": {\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"schema-name\": \"%\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"table-name\": \"%\"\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-action\": \"convert-lowercase\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"value\": null,\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"old-value\": null \n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-type\": \"transformation\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-id\": \"169908300\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-name\": \"169908300\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-target\": \"schema\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"object-locator\": {\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"schema-name\": \"%\"\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-action\": \"convert-lowercase\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"value\": null,\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"old-value\": null \n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;{\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-type\": \"selection\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-id\": \"169895493\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-name\": \"169895493\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"object-locator\": {\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"schema-name\": \"ADMIN\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"table-name\": \"EMPLOYEES\"\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"rule-action\": \"include\",\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"filters\": [] \n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;}\n&nbsp;&nbsp; &nbsp; ] \n}</code></pre> \n</div> \n<p>次の出力例では、データマスキングを適用した PostgreSQL インスタンスの出力を確認することができます:</p> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-bash\">dmsdb=&gt; select employee_id,phone_number,email,account_number from admin.employees ;\n&nbsp; employee_id | phone_number | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; email &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | account_number \n-------------+--------------+------------------------------------------------------------------+-----------------\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 20 | 685-9897 &nbsp; &nbsp; | FDC2A4ABC53872D0F934B5614DDC312DAA165895065BB00A5986849AADE8C322 | ***-***-***-***\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 21 | 579-3441 &nbsp; &nbsp; | 3A4FA9FE0AA0A2B468EDF13A29A75C4E3A20650243143D834D7898D40AA0FA2F | ***-***-***-***\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 22 | 156-9277 &nbsp; &nbsp; | 0985B1D142A4067E397DF5AB56B03E3BF4857FB1F229CB39B49CE06E46B7AA98 | ***-***-***-***\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 23 | 238-5321 &nbsp; &nbsp; | D07EAB207F4F1366C1E35B35E33F7842FF3EEB2C80E47FDAEB0900B49EE77697 | ***-***-***-***\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 24 | 536-1233 &nbsp; &nbsp; | 3D438AF13A839ACDC24FD0CE8EB8C8C45083B90A31DF3583A88131614086C3B9 | ***-***-***-***\n(5 rows)</code></pre> \n</div> \n<p>以下の画像は、比較のために Oracle での出力例を示しています。</p> \n<p><img loading=\"lazy\" class=\"alignnone wp-image-61544 size-full\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/18/DBBBLOG-4611-1.jpg\" alt=\"Oracle output for comparison\" width=\"844\" height=\"266\"></p> \n<p>前述の例では、データマスキング機能を使用して機密情報をマスキングする方法を示しました。詳細については、<a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Tasks.CustomizingTasks.TableMapping.SelectionTransformation.Masking.html\" target=\"_blank\" rel=\"noopener\">データマスキングを使用して機密情報を隠す</a>を参照してください。</p> \n<h2>データ検証パフォーマンスの強化</h2> \n<p>データの整合性を維持することは、どのデータベース移行においても重要ですが、多くの場合、時間とリソースを大量に消費するプロセスです。AWS DMS 3.5.4では、高速パーティション検証などの革新的な手法を使用して検証プロセスを合理化する<a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Validating.html#CHAP_Validating_Enhanced\" target=\"_blank\" rel=\"noopener\">拡張データ検証機能</a>によってこの課題に対処しています。</p> \n<p>強化されたデータ検証の主な利点には、以下のようなものがあります：</p> \n<ul> \n <li>レプリケーションインスタンスから AWS DMS のソースおよびターゲットエンドポイントへのリソース使用量の再分配</li> \n <li>潜在的なネットワーク使用量の減少</li> \n <li>LOB データ型を含まない幅広いテーブルに効率的</li> \n</ul> \n<p>拡張データ検証機能は、Oracle から PostgreSQL、SQL Server から PostgreSQL、Oracle から Oracle、SQL Server から SQL Server など、特定の AWS DMS による移行パスで利用できるようになりました。この機能を使用するには、環境が<a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Validating.html#CHAP_Validating_Enhanced\" target=\"_blank\" rel=\"noopener\">前提条件</a>を満たしていることを確認してください。</p> \n<p>AWS DMS が拡張データ検証を使用しているかどうかは、<a href=\"http://aws.amazon.com/cloudwatch\" target=\"_blank\" rel=\"noopener\">Amazon CloudWatch</a> ログを見れば確認できます。次のようなメッセージが表示されます:</p> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-bash\">2025-02-12T21:23:26 [VALIDATOR ]I: Fast validation of table 'dbo'.'customer' : partition : 178 (partition_validator.c:1001)</code></pre> \n</div> \n<p>パフォーマンスの向上を定量化するために、以下のスクリーンショットに示す設定で <a href=\"https://www.hammerdb.com/benchmarks.html\" target=\"_blank\" rel=\"noopener\">HammerDB</a> を使用してベンチマークを実施しました。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/18/DBBBLOG-4611-2.png\"><img loading=\"lazy\" class=\"alignnone wp-image-61570 size-full\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/18/DBBBLOG-4611-2.png\" alt=\"HammerDB 設定\" width=\"576\" height=\"328\"></a></p> \n<p>ベースラインとして、検証を無効にしたフルロードと変更データキャプチャ (CDC) タスクを作成し、約 9,300 万レコード (サイズ 15 GB) を <a href=\"https://aws.amazon.com/rds/sqlserver/\" target=\"_blank\" rel=\"noopener\">Amazon RDS for SQL Server</a> から <a href=\"https://aws.amazon.com/rds/aurora/\" target=\"_blank\" rel=\"noopener\">Amazon Aurora PostgreSQL 互換エディション</a> へ、合計 9 つのテーブルにわたって移行しました。</p> \n<p>次に、2 つの<a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Validating.html#CHAP_Validating.ValidationOnly\" target=\"_blank\" rel=\"noopener\">検証のみ</a>タスクを実行しました。1 つは AWS DMS 3.5.3 で、もう 1 つは AWS DMS 3.5.4 で、どちらも r6i.xlarge インスタンスを使用しました。<br> 検証を高速化するために、<code>PartitionSize</code> を 100,000 に、<code>ThreadCount</code> を 15 に増やしました：</p> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-bash\">\"ValidationSettings\": {\n\"PartitionSize\": 100000,\n\"ThreadCount\": 15,\n\"ValidationOnly\": true \n}</code></pre> \n</div> \n<p>次のスクリーンショットは、エンジンバージョン 3.5.4 で実行されている AWS DMS レプリケーションインスタンスのリソース消費量を示しています。</p> \n<p><img loading=\"lazy\" class=\"alignnone wp-image-61547 size-full\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/18/DBBBLOG-4611-3.jpg\" alt=\"エンジンバージョン 3.5.4 での CPU 使用率\" width=\"1292\" height=\"473\"></p> \n<p><img loading=\"lazy\" class=\"alignnone wp-image-61548 size-full\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/18/DBBBLOG-4611-4.jpg\" alt=\"エンジンバージョン 3.5.4 におけるタスクメモリ使用量\" width=\"1292\" height=\"473\"></p> \n<p>次のスクリーンショットは、エンジンバージョン 3.5.3 で実行されている AWS DMS レプリケーションインスタンスのリソース消費量を示しています。</p> \n<p><img loading=\"lazy\" class=\"alignnone wp-image-61549 size-full\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/18/DBBBLOG-4611-5.jpg\" alt=\"CPU utilization on engine version 3.5.3\" width=\"1292\" height=\"473\"></p> \n<p><img loading=\"lazy\" class=\"alignnone wp-image-61550 size-full\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/18/DBBBLOG-4611-6.jpg\" alt=\"Task memory usage on engine version 3.5.3\" width=\"1292\" height=\"473\"></p> \n<p>AWS DMS 3.5.3 と比較して、AWS DMS 3.5.4 で実行した場合、検証のみのタスクの TaskMemoryUsage が 91% 減少し、基盤となるAWS DMS レプリケーションインスタンスの CPU 使用率が 95% 削減されることがわかります。検証のみのタスクを別に実行したいお客様は、この機能を使用して、AWS DMS レプリケーションインスタンスのコンピューティングとメモリをより有効に活用できます。</p> \n<h2>まとめ</h2> \n<p>この投稿では、AWS DMS 3.5.4 におけるデータマスキングと強化されたデータ検証の変換ルールについて説明しました。<br> データマスキング機能を実装することで、データベース移行プロセス全体を通じて機密情報を確実に保護できます。<br> 拡張データ検証機能により、DMS レプリケーションインスタンスのリソース消費を抑えながら、検証を実行するすべての利点を得ることができます。<br> これらの機能を試してみて、あなたのユースケースにどのように役立ったかをコメント欄でお聞かせください。</p> \n<h3><strong>著者について</strong></h3> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"alignleft wp-image-61551 size-thumbnail\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/18/DBBBLOG-4611-7-100x132.jpg\" alt=\"Suchindranath Hegde\" width=\"100\" height=\"132\"><strong>Suchindranath Hegde</strong> は Amazon Web Services のシニアデータ移行スペシャリストソリューションアーキテクトです。彼はお客様と協力して、AWS DMS を使用した AWS へのデータ移行に関するガイダンスと技術支援を提供しています。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"alignleft wp-image-61552 size-thumbnail\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/18/DBBBLOG-4611-8-100x132.jpg\" alt=\"Mahesh Kansara\" width=\"100\" height=\"132\"><strong>Mahesh Kansara</strong> は、Amazon Web Services のデータベースエンジニアリングマネージャーです。<br> 彼は開発およびエンジニアリングチームと密接に協力して、移行およびレプリケーションサービスの改善に取り組んでいます。<br> また、お客様と協力して、さまざまなデータベースおよび分析プロジェクトに関するガイダンスと技術支援を提供し、AWS を使用する際のソリューションの価値向上を支援しています。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"alignleft wp-image-61553 size-thumbnail\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/18/DBBBLOG-4611-9-100x130.jpg\" alt=\"Leonid Slepukhin\" width=\"100\" height=\"130\"><strong>Leonid Slepukhin</strong> は、Amazon Web Services の Database Migration Service (DMS) チームのシニアデータベースエンジニアです。<br> AWS DMS のコア機能の開発に取り組み、社内外の顧客が複雑なデータベース移行とレプリケーションの課題を解決するのを支援することを専門としています。<br> DMS の機能強化と、AWS クラウドへのデータベース移行を成功させるための技術的専門知識の提供に重点を置いています。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"alignleft wp-image-61554 size-thumbnail\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/18/DBBBLOG-4611-10-100x132.jpg\" alt=\"Sridhar Ramasubramanian\" width=\"100\" height=\"132\"><strong>Sridhar Ramasubramanian</strong> は、AWS Database Migration Service チームのデータベースエンジニアです。<br> AWS のお客様のニーズにより適合するよう、DMS サービスの改善に取り組んでいます。</p>"
  },
  {
    "title": "PostgreSQL のアップグレード中に AWS DMS タスクを処理するためのベストプラクティス",
    "date": "2025-10-21T09:00:36.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/aws-dms-upgrade-bestpractice/",
    "content": "<p><em>本投稿は、Veeramani A と Manoj Ponnurangam による記事 「<a href=\"https://aws.amazon.com/jp/blogs/database/best-practices-to-handle-aws-dms-tasks-during-postgresql-upgrades/\" target=\"_blank\" rel=\"noopener\">Best practices to handle AWS DMS tasks during PostgreSQL upgrades</a>」を翻訳したものです。</em></p> \n<p><a href=\"https://aws.amazon.com/dms/\" target=\"_blank\" rel=\"noopener\">AWS Database Migration Service</a> は、データのセキュリティとデータの整合性を提供しながら、データベースを Amazon Web Services (AWS) に移行およびレプリケーションするためのマネージドソリューションを提供します。AWS DMS は、ソースとターゲットのデータベースが同じエンジンを使用する <a href=\"https://docs.aws.amazon.com/dms/latest/userguide/dm-migrating-data-postgresql.html\" target=\"_blank\" rel=\"noopener\">同種の移行</a>と、異なるデータベース環境間の <a href=\"https://docs.aws.amazon.com/dms/latest/userguide/Welcome.html\" target=\"_blank\" rel=\"noopener\">異種の移行</a>の両方に対応しています。</p> \n<p>AWS DMS は、PostgreSQL データベースから<a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Introduction.Targets.html\" target=\"_blank\" rel=\"noopener\">サポートされているターゲット</a>へのデータ移行を容易にし、また<a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Introduction.Sources.html\" target=\"_blank\" rel=\"noopener\">サポートされているソース</a>から PostgreSQL データベースへの移行も可能にします。これにより、企業がデータインフラストラクチャをクラウドに移行するための堅牢な経路を提供します。</p> \n<h2><strong>ソリューションの概要</strong></h2> \n<p>オープンソースの PostgreSQL は、頻繁に発生するバグ、セキュリティ問題、データ破損の問題の修正を含む<a href=\"https://www.postgresql.org/support/versioning/\" target=\"_blank\" rel=\"noopener\">新しいマイナーバージョンとメジャーバージョンをリリース</a>することがあります。一般的に、Amazon RDS は、<a href=\"https://aws.amazon.com/rds/faqs/#awt-content-topics\" target=\"_blank\" rel=\"noopener\">新しいエンジンバージョンが利用可能になってから 5 か月以内にサポート</a>することを目指しています。特定のバージョンがサポートされなくなった場合には PostgreSQL インスタンスをアップグレードする必要があります。問題の解決や新しい改善の導入、あるいはコンプライアンスの遵守やデータ保護のためにも PostgreSQL インスタンスをアップグレードする必要があります。</p> \n<p>進行中の AWS DMS タスクのソースまたはターゲットとして設定されている PostgreSQL データベースをアップグレードする場合は、これをアップグレード計画に組み込むことが重要です。</p> \n<p>この記事では、PostgreSQL のマイナーバージョンまたはメジャーバージョンへのアップグレード中に AWS DMS タスクを処理するためのベストプラクティスについて説明します。</p> \n<h2><strong>前提条件</strong></h2> \n<p>この記事のソリューションをテストするには、以下のリソースが必要です：</p> \n<ul> \n <li><a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_ReplicationInstance.Creating.html\" target=\"_blank\" rel=\"noopener\">AWS DMS レプリケーションインスタンス</a></li> \n <li><a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_GettingStarted.CreatingConnecting.PostgreSQL.html\" target=\"_blank\" rel=\"noopener\">RDS for PostgreSQL または Amazon Elastic Compute Cloud（Amazon EC2）かオンプレミスで実行されている PostgreSQL</a></li> \n <li><a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Endpoints.Creating.html\" target=\"_blank\" rel=\"noopener\">ソースとターゲットのエンドポイント</a></li> \n <li>ソースまたはターゲットでPostgreSQLを指定する <a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Tasks.Creating.html\" target=\"_blank\" rel=\"noopener\">AWS DMS タスク</a></li> \n</ul> \n<h2><strong>PostgreSQL のバージョンアップグレードの理解</strong></h2> \n<p>PostgreSQL のアップグレードが AWS DMS タスクにどのように影響するかを詳しく見る前に、PostgreSQL におけるメジャーバージョンとマイナーバージョンのアップグレードについて明確に理解しておきましょう。</p> \n<p>マイナーバージョンは、セキュリティの脆弱性を修正し、バグを修正し、一般的に新機能を追加しません。<br> マイナーリリースは内部ストレージ形式を変更せず、常に同じメジャーバージョン番号の前後のマイナーリリースと互換性があります。<br> 例えば、バージョン 14.10 は、バージョン 14.9 およびバージョン 14.16 と互換性があります。</p> \n<p>PostgreSQL のメジャーリリースでは、システムテーブル、データファイル、内部データストレージ形式も変更される可能性があります。RDS for PostgreSQL は、ネイティブの <a href=\"https://www.postgresql.org/docs/current/pgupgrade.html\" target=\"_blank\" rel=\"noopener\">pg_upgrade</a> ユーティリティを使用して、インスタンスを新しいメジャーバージョンにアップグレードします。アップグレードの詳細については、<a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.PostgreSQL.html\" target=\"_blank\" rel=\"noopener\">Amazon RDS の PostgreSQL DB エンジンのアップグレード</a>をご参照ください。</p> \n<p>マイナーリリースとメジャーリリース、またはバージョンアップグレードのいずれもダウンタイムが発生するため、適切なメンテナンスウィンドウ内で実施する必要があります。できればデータベースへのクエリが最も少ない時間帯にスケジュールされたメンテナンスウィンドウをこのアップグレード作業のために計画することをお勧めします。</p> \n<h2><strong>AWS DMS と PostgreSQL の連携</strong></h2> \n<p>AWS DMS を使用して PostgreSQL ソースから PostgreSQL ターゲットにデータを移行する場合を想定しましょう。</p> \n<p>フルロード中、AWS DMS はソースの PostgreSQL データベースに接続し、テーブルマッピングで定義されたテーブルで <code>select *</code> を実行してデータをアンロードします。ソースから取得したデータは、PostgreSQL ターゲットに向けてレプリケーションインスタンスの CSV ファイルに書き込まれます。PostgreSQL ターゲットの場合、AWS DMS は <code>COPY</code> コマンドを使用して、CSV ファイルのデータをターゲットの PostgreSQL テーブルにロードします。</p> \n<p>移行中の継続的な変更を取り込むために、AWS DMS はソースの PostgreSQL データベースに論理レプリケーションスロットを作成します。スロットは、変更のストリームを表し、ソースの PostgreSQL データベースで実行された順序でクライアントに再生することができます。DMS は、レプリケーションスロットからの変更のロジカルデコーディングに <a href=\"https://aws.amazon.com/blogs/database/comparison-of-test_decoding-and-pglogical-plugins-in-amazon-aurora-postgresql-for-data-migration-using-aws-dms/\" target=\"_blank\" rel=\"noopener\">test_decoding または pglogical プラグイン</a> のいずれかを使用します。ソースの PostgreSQL データベースで <code>pglogical</code> プラグインが利用可能な場合、DMS は <code>pglogical</code> を使用してレプリケーションスロットを作成します。そうでない場合は、<code>test_decoding</code> プラグインが使用されます。ソースから読み取られた変更は、レプリケーションインスタンス上のソーターコンポーネントに渡されます。ソーターコンポーネントはトランザクションをコミット順にソートし、その後、DMS タスクの設定に基づいて、順次またはバッチモードでこれらの変更をターゲットデータベースに適用します。</p> \n<p>レプリケーションスロットは、フルロード + CDC および CDC のみのタスクにおいて重要な役割を果たします。<br> これは、ソースの PostgreSQL データベース上で必要なログ先行書き込み (WAL) ファイルを保持する役割を担っています。<br> ソースデータベース上でレプリケーションスロットが削除されると、DMS はソースデータベースからの継続的な変更を処理できなくなります。</p> \n<h2><strong>PostgreSQL のアップグレードが AWS DMS タスクに与える影響</strong></h2> \n<p>以下のセクションでは、ソースまたはターゲットの PostgreSQL データベースのマイナーバージョンまたはメジャーバージョンのアップグレード中に、DMS タスクをどのように扱うかについて説明します。</p> \n<h3><strong>ソース PostgreSQL データベースのアップグレード時</strong></h3> \n<p>フルロードのみの DMS タスクは、1 回限りのデータ移行用に設計されています。<br> これらのタスクは、ソースの PostgreSQL データベースのマイナーバージョンまたはメジャーバージョンのアップグレード後に安全に再開できます。</p> \n<p>フルロード + CDC および CDC のみの DMS タスクは、進行中の変更をターゲットデータベースに継続的に複製します。PostgreSQL のアップグレード中に、フルロード + CDC および CDC のみの DMS タスクを処理する場合、次のセクションのベストプラクティスに従ってください。</p> \n<h4><strong>マイナーリリースまたはバージョンアップグレード</strong></h4> \n<p>マイナーバージョンのアップグレードを行う前に、実行中の AWS DMS レプリケーションタスクを停止してください。マイナーバージョンのアップグレードが完了したら、DMS タスクを再開できます。</p> \n<h4><strong>メジャーバージョンアップグレード</strong></h4> \n<p>執筆時点で、DMS は PostgreSQL バージョン 9.4 以降 (9.x バージョン)、10.x、11.x、12.x、13.x、14.x、15.x、および 16.x をサポートしています。<br> メジャーバージョンアップグレードを実行する際は、レプリケーションインスタンスが新しい PostgreSQL バージョンをサポートしていることを確認してください。</p> \n<p><code>pg_upgrade</code> を使用してメジャーバージョンアップグレードを進めるには、ソースの PostgreSQL データベース上のレプリケーションスロットを削除する必要があります。これらのスロットを削除しないと、アップグレードプロセスに影響を与える可能性があります。レプリケーションスロットを削除せずにアップグレードを試みると、<code>pg_upgrade_precheck.log</code> に 1 つ以上の論理レプリケーションスロットによってブロックされたためインスタンスをアップグレードできなかったというメッセージが表示され、アップグレードは失敗します。ただし、レプリケーションスロットを削除すると AWS DMS タスクが無効になり、進行中のレプリケーションタスクを再開できなくなります。</p> \n<p><img loading=\"lazy\" class=\"alignnone size-full wp-image-61434\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/15/DMS_blog_1.png\" alt=\"\" width=\"904\" height=\"150\"></p> \n<p>この問題に対処し、メジャーバージョンアップグレード中に進行中のレプリケーションタスクを管理するには、以下の手順を使用します：</p> \n<ol> \n <li>PostgreSQL データベースへのすべてのアプリケーション接続を停止します。以下を使用してアクティブな接続を監視します：</li> \n</ol> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-xml\">select * from pg_stat_activity where datname = 'database_name';</code></pre> \n</div> \n<p>必要に応じて、残りの接続を以下のコマンドで終了します：</p> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-xml\">select pg_terminate_backend(pid) from pg_stat_activity where datname = 'database_name'and pid &lt;&gt; pg_backend_pid();</code></pre> \n</div> \n<ol start=\"2\"> \n <li>AWS DMS タスクのメトリクスを監視して、<code>CDCLatencySource</code>と<code>CDCLatencyTarget</code>の両方がゼロに近いことを確認します。これにより、DMS タスクが変更を遅延なく複製していることを確認できます。ターゲットで<code>awsdms_txn_state</code>を使用してタスクステータスを取得することもできます（タスク設定「<code>TaskRecoveryTableEnabled = True</code>」で有効にできます）。次の画像は、<code>CDCLatencySource</code>と<code>CDCLatencyTarget</code>の Cloudwatch メトリクスを示しています。</li> \n</ol> \n<p><img loading=\"lazy\" class=\"alignnone size-full wp-image-61435\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/15/DMS_blog_2.png\" alt=\"\" width=\"1384\" height=\"479\"></p> \n<p><img loading=\"lazy\" class=\"alignnone size-full wp-image-61436\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/15/DMS_blog_3.png\" alt=\"\" width=\"1384\" height=\"473\"></p> \n<ol start=\"3\"> \n <li>レイテンシーがゼロに近づいたら、実行中のアクティブなレプリケーション DMS タスクをすべて停止してください。</li> \n</ol> \n<ol start=\"4\"> \n <li>ソースの PostgreSQL データベースから既存のレプリケーションスロットを削除します。 \n  <div class=\"hide-language\"> \n   <pre><code class=\"lang-sql\">postgres=&gt; select * from pg_replication_slots ;\n slot_name | plugin | slot_type | datoid | database | temporary | active | active_pid | xmin | catalog_xmin | restart_lsn | confirmed_flush_lsn | wal_status | safe_wal_size \n-----------------+-------------+-----------+--------+----------+-----------+--------+------------+------+-------------+-------------+-------------------+------------+---------------\n bb6jw1f3enambi4z_00014405_e3972613_00e2_4960_ae4c_fe267b1cfcde | test_decoding | logical | 14405 | postgres | f | f | | | 898 | 0/5936F798 | 0/5F1A3440 | reserved |\n\n(1 row)\n postgres=&gt; SELECT pg_drop_replication_slot('bb6jw1f3enambi4z_00014405_e3972613_00e2_4960_ae4c_fe267b1cfcde'); \n pg_drop_replication_slot \n--------------------------\n \n(1 row)</code></pre> \n  </div> </li> \n</ol> \n<ol start=\"5\"> \n <li>レプリケーションスロットがないことを確認してください。 \n  <div class=\"hide-language\"> \n   <pre><code class=\"lang-sql\">postgres=&gt; select * from pg_replication_slots ;\n slot_name | plugin | slot_type | datoid | database | temporary | active | active_pid | xmin | catalog_xmin | restart_lsn | confirmed_flush_lsn | wal_status | safe_wal_size \n-----------+--------+-----------+--------+----------+-----------+--------+------------+------+-------------+-------------+-------------------+------------+---------------\n(0 rows)</code></pre> \n  </div> </li> \n</ol> \n<ol start=\"6\"> \n <li>PostgreSQLデータベースのインプレイスアップグレードを完了してください。</li> \n</ol> \n<ol start=\"7\"> \n <li>アップグレードプロセスが正常に完了したことを確認します。データベースレベルの検証チェックを実行して、アップグレード後にデータベースが期待通りに動作していることを確認します。アプリケーションを開始する前に、DMS タスクを処理するために <code>step 8</code> または <code>step 9</code> のいずれかに従ってください。</li> \n</ol> \n<ol start=\"8\"> \n <li>CDC のみのタスクを新しく作成してください。タスク設定で、<strong>ソーストランザクションの CDC 開始モード</strong>の<strong>カスタム CDC 開始モードを無効にする</strong>を選択します。古いタスクと同様に、他のタスク設定とテーブルマッピングを定義します。</li> \n</ol> \n<p><img loading=\"lazy\" class=\"alignnone size-full wp-image-61437\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/15/DMS_blog_4.png\" alt=\"\" width=\"904\" height=\"274\"></p> \n<p>タスクが作成されたら、CDC のみのタスクを開始します。これにより、ソースの PostgreSQL データベースに新しいレプリケーションスロットが作成され、レプリケーションスロットが作成された時点からの変更の移行が開始されます。</p> \n<p><img loading=\"lazy\" class=\"alignnone size-full wp-image-61438\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/15/DMS_blog_5.png\" alt=\"\" width=\"904\" height=\"142\"></p> \n<ol start=\"9\"> \n <li>または、指定されたログシーケンス番号 (LSN) から開始する DMS CDC のみのタスクを使用して、ソース PostgreSQL データベースにレプリケーションスロットを手動で作成することもできます。ソースにレプリケーションスロットを作成し、<code>confirmed_flush_lsn</code> を記録してください。</li> \n</ol> \n<p><code>confirmed_flush_lsn</code> は、論理スロットのコンシューマーが PostgreSQL エンジンにデータを受信したことを確認した最後の LSN を表します。<br> この <code>LSN</code> より前にコミットされたトランザクションに対応するデータは、もはや利用できません。</p> \n<p><img loading=\"lazy\" class=\"alignnone size-full wp-image-61439\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/15/DMS_blog_6.png\" alt=\"\" width=\"904\" height=\"188\"></p> \n<p>a. ソースエンドポイントの設定を変更し、ソース PostgreSQL データベースで作成した目的のスロットを <code>SlotName</code> として追加します。</p> \n<p><img loading=\"lazy\" class=\"alignnone size-full wp-image-61440\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/15/DMS_blog_7.png\" alt=\"\" width=\"808\" height=\"366\"></p> \n<p>b. タスク設定を変更してください。<strong>カスタム CDC 開始モードを有効にする</strong>を選択し、<strong>ログシーケンス番号を指定する </strong>(訳者注 : DMS マネジメントコンソールの新しいナビゲーションの場合 「ネイティブな CDC 開始点」) を選択して、<code>confirmed_flush_lsn</code>から LSN を入力します。</p> \n<p><img loading=\"lazy\" class=\"alignnone size-full wp-image-61441\" style=\"margin: 10px 0px 10px 0px;border: 1px solid #CCCCCC\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/15/DMS_blog_8.png\" alt=\"\" width=\"830\" height=\"436\"></p> \n<ol start=\"10\"> \n <li>DMS タスクを開始し、変更が問題なくターゲットデータベースに移行されていることを確認します。</li> \n</ol> \n<ol start=\"11\"> \n <li>アプリケーションを起動し、DMS CDC レプリケーションを監視します。</li> \n</ol> \n<h3><strong>ターゲットの PostgreSQL データベースをアップグレードする時</strong></h3> \n<p>AWS DMS CDC は、ターゲットの PostgreSQL データベースのマイナーバージョンアップグレードの影響を受けません。<br> DMS のターゲットとして設定された PostgreSQL データベースをアップグレードする前に、DMS タスクを停止し、マイナーバージョンアップグレードが成功した後に再開してください。</p> \n<p>DMS のターゲットとして設定された PostgreSQL データベースでメジャーバージョンアップグレードを実行する場合：</p> \n<ul> \n <li>現在のレプリケーションインスタンスエンジンのバージョンが新しい PostgreSQL バージョンをサポートしていることを確認してください。</li> \n <li>新しいエンジンバージョンが現在のレプリケーションインスタンスバージョンでサポートされている場合は、AWS DMS タスクを停止し、メジャーバージョンのアップグレードを完了してから DMS タスクを再開できます。</li> \n <li>新しいエンジンバージョンが現在のレプリケーションインスタンスバージョンでサポートされていない場合は、DMS タスクを停止して、ターゲットの PostgreSQL データベースでメジャーバージョンのアップグレードを完了する必要があります。また、レプリケーションインスタンスを、ターゲットの PostgreSQL データベースの現在のバージョンをサポートするバージョンにアップグレードする必要があります。ターゲットデータベースとソースデータベースの両方が互換性のあるメジャーバージョンに更新されたら、DMSタスクを再開できます。</li> \n</ul> \n<h2><strong>クリーンアップ</strong></h2> \n<p>この投稿で作成したリソースを削除することで、変更を元に戻し、継続的な料金の発生を避けることができます：</p> \n<ol> \n <li>このソリューションのテストのために作成され、不要となった <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_DeleteInstance.html\" target=\"_blank\" rel=\"noopener\">RDS for PostgreSQL インスタンス</a>と<a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html\" target=\"_blank\" rel=\"noopener\">EC2 インスタンス</a>を削除します。</li> \n <li>このソリューションのテストのために作成された <a href=\"https://docs.aws.amazon.com/cli/latest/reference/dms/delete-replication-task.html\" target=\"_blank\" rel=\"noopener\">AWS DMS タスクを削除します</a>。</li> \n <li><a href=\"https://docs.aws.amazon.com/cli/latest/reference/dms/delete-endpoint.html\" target=\"_blank\" rel=\"noopener\">AWS DMS のソースエンドポイントとターゲットエンドポイントを削除します</a>。</li> \n <li><a href=\"https://docs.aws.amazon.com/dms/latest/userguide/CHAP_ReplicationInstance.Deleting.html\" target=\"_blank\" rel=\"noopener\">AWS DMS レプリケーションインスタンスを削除します</a>。</li> \n</ol> \n<h2><strong>まとめ</strong></h2> \n<p>この投稿では、PostgreSQL データベースを AWS DMS のソースまたはターゲットとして構成している場合に、アップグレード時に DMS タスクをどのように扱うかについて説明しました。</p> \n<p>このソリューションを試してみて、フィードバックや質問をコメントで共有してください。</p> \n<h3>About the Authors</h3> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"alignnone size-thumbnail wp-image-61448 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/15/DMS_blog_author_1-100x127.jpg\" alt=\"\" width=\"100\" height=\"127\"><strong>Veeramani A</strong> は Amazon Web Services のクラウドデータベースエンジニアで、AWS Database Migration Service とAmazon RDS for PostgreSQL で SME(Subject Matter Expert)を務めています。15 年以上にわたる多様なデータベーステクノロジーの経験を持つ彼は、AWS へのデータベース移行を進めるお客様に戦略的ガイダンスと技術的専門知識を提供しています。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-61449 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/04/15/DMS_blog_author_2.png\" alt=\"\" width=\"100\" height=\"130\"><strong>Manoj Ponnurangam</strong> は、Amazon Web Services のクラウドデータベースエンジニアとして働いています。彼はAmazon RDS for Oracle、Amazon RDS for PostgreSQL、AWS DMS の SME(Subject Matter Expert) です。Manoj はリレーショナルデータベースを15 年扱ってきた経験があります。彼はお客様と協力して、さまざまなデータベースや移行プロジェクトに関する指導や技術支援を提供しています。</p>"
  },
  {
    "title": "uv × DockerでのPython開発環境構築方法",
    "date": "2025-10-21T02:50:01.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/mkj/articles/3aaa36d6f35c08",
    "content": "松尾研究所では、Python開発における標準ツールとしてuvを推奨しています。uvはPythonのパッケージ管理ツールで、依存関係の管理や仮想環境の構築を自動化し、高速で再現性のある開発を可能にすることが特長です。\nPythonパッケージだけでなく、Node.jsやブラウザ周りのツールなど他の依存も扱うときには、uvとDockerを併用するケースもあるかと思います。Dockerのコンテナ上でuvを使用する方法について社内で話題になったとき、調べたところいくつか方法があることが分かったので、それぞれの方法の違いと松尾研究所推奨の環境構築方法についてまとめました。\n!\n本記事では、uv、Do..."
  },
  {
    "title": "Next.js 15 / React 19 実践設計ガイド 実装観点別のベストプラクティス",
    "date": "2025-10-21T02:44:31.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/k_mori/books/24320553af0956",
    "content": "Next.js 15とReact 19を使用したWebアプリケーション開発における、実践的な設計方針とベストプラクティスをまとめたガイドを作成しました。\n\n本書では、Next.js 15 / React 19を活用したモダンなWebアプリケーション開発における設計方針を、実装観点ごとに整理しています。App Routerを前提とし、ディレクトリ構成、コンポーネント設計、データ取得、データ更新、状態管理、キャッシュ戦略、エラーハンドリングといった各テーマについて、具体的なユースケースと実装手段を紹介します。"
  },
  {
    "title": "0からフロントエンドにテストを導入した話",
    "date": "2025-10-21T01:07:58.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/eversteel_tech/articles/c510e3f036b2bf",
    "content": "こんにちは。株式会社EVERSTEELで業務委託のソフトウェアエンジニアとして参画している日野原です。\n主にフロントエンドを担当しており、技術としてはNext.jsを使用しています。（詳しい技術内容はこちらを参照）\n少し前の話になりますが、ゼロからテストを導入したので、その過程や戦略について話していこうと思います。\nフロントエンドのテストを検討している方や、テストの運用方法を迷っている方の参考になるかと思います。\n\n Reactアプリにおけるテスト戦略と実践ガイド\n一昔前はフロントエンド開発においてテストはあまり重要視されていませんでした。\nしかし、フロントエンドの複雑さが増したため、最..."
  },
  {
    "title": "【イベント開催告知】企業の生成 AI 活用を加速する Dify Enterprise on AWS 〜セキュアなデータの活用とパートナー導入事例〜 (2025/11/21)",
    "date": "2025-10-21T00:43:19.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/dify-enterprise-on-aws-event-20251121/",
    "content": "<p>こんにちは！ アマゾン ウェブ サービス ジャパンのソリューションアーキテクト馬渕です。</p> \n<p>2025 年 11 月 21 日 (金) 15:30-17:00 、AWS Japan の目黒オフィスにて、Dify と AWS に関するイベント「<strong><a href=\"https://d2e7mz4alxgx8z.cloudfront.net/?TrafficSource=awsblog\">企業の生成 AI 活用を加速する Dify Enterprise on AWS 〜セキュアなデータの活用とパートナー導入事例〜</a></strong>」の開催が決定しました。社内の生成 AI 活用を加速するために Dify を利用したいお客様、すでに Dify を利用していてさらにセキュアなデータも扱いたいお客様、Dify Enterprise を利用したいものの導入・運用に不安をお持ちのお客様に、今後のさらなる活用のためのヒントをご提供します。</p> \n<p><span id=\"more-166796\"></span></p> \n<h2>Dify のご紹介と、 AWS とのシナジーのご紹介</h2> \n<p><a href=\"https://dify.ai/jp\">Dify</a> は、生成 AI アプリをノーコードで開発できるプラットフォームです。技術者以外でも AI アプリが作れる使いやすさから多くのお客様の注目を集めており、社内の生成 AI 基盤として PoC ・本番導入しているお客様が増えてきています。Dify には SaaS 利用するか自社の環境にセルフホストするかの 2 つの利用方法があり、後者のセルフホスト方式では多くのお客様が AWS 上で Dify をデプロイし、セキュアに社内の生成 AI 推進を実現しています。なお、前者の <a href=\"https://docs.dify.ai/en/getting-started/cloud#faqs\">Dify Cloud も AWS 上で稼働しており</a>、AWS 上での Dify の稼働実績を十分に裏付けるものになっています。</p> \n<p>また、AWS では、AWS 上に Dify をスケーラブルかつマネージドな環境でセルフホストするための <a href=\"https://github.com/aws-samples/dify-self-hosted-on-aws\">AWS CDK サンプル</a>や、それをワンクリックでデプロイするための <a href=\"https://aws-samples.github.io/sample-one-click-generative-ai-solutions/solutions/dify/\">AWS Generative AI Solution Box</a> を公開しています。また、<a href=\"https://catalog.us-east-1.prod.workshops.aws/workshops/95a3c231-2064-4a33-9a3d-624b7c11aaa6/ja-JP\">AWS 上に簡易な構成で Dify 環境を構築し、その上で AI アプリケーションを構築する方法を学ぶワークショップ</a>も公開しており、Dify を通じたお客様の生成 AI 活用をご支援しています。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/14/image-5-6.png\"><img loading=\"lazy\" class=\"aligncenter size-full wp-image-166798\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/14/image-5-6.png\" alt=\"\" width=\"926\" height=\"590\"></a></p> \n<p style=\"text-align: center\">GitHub 上で公開している <a href=\"https://github.com/aws-samples/dify-self-hosted-on-aws\">Dify on AWS with CDK</a> サンプルのアーキテクチャ</p> \n<h2>Dify Enterprise のメリットとユースケース</h2> \n<p>そして、 Dify をエンタープライズ規模でセキュアに社内利用するのに役立つのが <a href=\"https://dify.ai/jp/enterprise\">Dify Enterprise</a> です。OSS 版 Dify の機能に加えて、自社 IdP とのシングルサインイン機能や、マルチワークスペースによるアプリケーション利用の細かい権限管理など、社内利用に役立つガバナンス向上のための機能を備えています。<a href=\"https://aws.amazon.com/marketplace/pp/prodview-vhluia2quhiuu\">Dify Enterprise のライセンスは AWS Marketplace 上でも購入可能</a>になっており、これを用いて AWS 上にデプロイすればセルフホスト時の基盤の費用とライセンス費用を効率的に管理することが可能です。</p> \n<p>Dify Enterprise を利用することで特にメリットのあるユースケースの 1 つが、セキュアなデータソースとの連携です。Dify には様々な SaaS やアプリケーションと連携できるプラグインのエコシステムがあり、例えば企業のデータウェアハウスと連携して社内データを活用した生成 AI アプリケーションを構築できます。Dify Enterprise の権限管理機能では、アプリケーションやプラグインへの細やかなアクセス可否を制御できるため、公開範囲が厳密なデータソースを連携するアプリケーションであっても安心して組み込むことが可能になります。</p> \n<h2>11/21(金) のイベントの詳細</h2> \n<p>今回のイベントでは、企業で社内の生成 AI 活用を推進する方を対象に、Dify Enterprise をご活用いただくための情報をご提供いたします。Dify の最新情報アップデートや、 Dify Enterprise ならではのセキュアなデータを扱うユースケースのご紹介に加えて、Dify の Eliter Partner でもあり AWS パートナーでもある株式会社リコー様にもご登壇いただき、Dify Enterprise の構築・運用のナレッジについてご共有いただきます。</p> \n<h3>開催概要</h3> \n<ul> \n <li>タイトル : <a href=\"https://d2e7mz4alxgx8z.cloudfront.net/?TrafficSource=awsblog\"><strong>企業の生成 AI 活用を加速する Dify Enterprise on AWS 〜セキュアなデータの活用とパートナー導入事例〜</strong></a></li> \n <li>日時 : 2025年11月21日（金）15:30-17:00 (15:00 開場) \n  <ul> \n   <li>終了後、懇親会あり</li> \n  </ul> </li> \n <li>参加費 : 無料</li> \n <li>お申し込み方法 : イベントの<a href=\"https://d2e7mz4alxgx8z.cloudfront.net/?TrafficSource=awsblog\">ランディングページ</a>よりフォームにアクセスしてお申し込みください</li> \n <li>開催場所 : 〒153-0064 東京都目黒区下目黒1-8-1 ARCO TOWER 19 F \n  <ul> \n   <li>JR線・東急目黒線・東京メトロ南北線・都営地下鉄三田線 目黒駅より徒歩約5分</li> \n   <li>[<a href=\"https://maps.app.goo.gl/uQK4JpGpmbs48Vhy6\">google map</a>] [<a href=\"https://pages.awscloud.com/rs/112-TZM-766/images/Japanese_AccessMAP_ArcoTower.pdf\">ARCO TOWERへのアクセス方法</a>]</li> \n  </ul> </li> \n</ul> \n<h3>アジェンダ</h3> \n<table border=\"1\" cellspacing=\"1\" cellpadding=\"10\"> \n <tbody> \n  <tr> \n   <td>開始</td> \n   <td>終了</td> \n   <td>コンテンツ</td> \n   <td>プレゼンター</td> \n  </tr> \n  <tr> \n   <td>15:30</td> \n   <td>15:35</td> \n   <td>オープニング</td> \n   <td>アマゾン ウェブ サービス ジャパン 合同会社</td> \n  </tr> \n  <tr> \n   <td>15:35</td> \n   <td>15:55</td> \n   <td>Dify Updates : RAG 2.0, MCP</td> \n   <td>株式会社 LangGenius</td> \n  </tr> \n  <tr> \n   <td>15:55</td> \n   <td>16:15</td> \n   <td>Dify Enterprise でセキュアなデータを扱おう<br> 〜Snowflake と連携してインサイトを生む〜</td> \n   <td>株式会社 LangGenius<br> アマゾン ウェブ サービス ジャパン 合同会社</td> \n  </tr> \n  <tr> \n   <td>16:15</td> \n   <td>16:30</td> \n   <td>Dify on AWS の選択肢と、AWS で Dify を使う理由</td> \n   <td>アマゾン ウェブ サービス ジャパン 合同会社</td> \n  </tr> \n  <tr> \n   <td>16:30</td> \n   <td>16:50</td> \n   <td>パートナーと進める Dify 活用</td> \n   <td>株式会社リコー</td> \n  </tr> \n  <tr> \n   <td>16:50</td> \n   <td>17:00</td> \n   <td>Q&amp;A / クロージング</td> \n   <td>アマゾン ウェブ サービス ジャパン 合同会社</td> \n  </tr> \n  <tr> \n   <td>17:00</td> \n   <td>18:00</td> \n   <td>懇親会</td> \n   <td>–</td> \n  </tr> \n </tbody> \n</table> \n<p>※ アジェンダやスピーカーは変更となる可能性がございます。</p> \n<h3>こんな課題をお持ちのお客様に</h3> \n<ul> \n <li>機密性の高いシステムと生成 AI の安全な連携方法を模索している</li> \n <li>部門やプロジェクトごとに異なるセキュリティレベルでの AI 活用を検討している</li> \n <li>コンプライアンスを確保しながら生成 AI の全社展開を進めたい</li> \n <li>Dify を活用したいが、その導入・運用のナレッジやリソースに不安がある</li> \n</ul> \n<h3>お申し込み方法</h3> \n<p>イベントの<a href=\"https://d2e7mz4alxgx8z.cloudfront.net/?TrafficSource=awsblog\">ランディングページ</a>よりフォームにアクセスしてお申し込みください。会場の定員の都合上、抽選とさせていただく場合がございますのでご了承ください。ご不安・ご不明点がある場合は、 AWS の担当営業にお声がけください。</p>"
  },
  {
    "title": "RAGが苦手な「ぬるっとした日本語」と戦う",
    "date": "2025-10-21T00:01:01.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/knowledgesense/articles/83c89503b6531b",
    "content": "本記事では、RAGの性能を高めるための「DualCSE」という手法について、ざっくり理解します。\n株式会社ナレッジセンスは、生成AIやRAGを使ったプロダクトを、エンタープライズ企業向けに開発しているスタートアップです。\n\n この記事は何\nこの記事は、日本語特有の「あいまいな婉曲表現」（=ぬるっとした日本語）を含む文章でもRAGの精度を上げるための手法「DualCSE」の論文[1]について、日本語で簡単にまとめたものです。\nhttps://arxiv.org/abs/2510.09293\n今回も「そもそもRAGとは？」については、知っている前提で進みます。確認する場合は、こちらの記事もご..."
  },
  {
    "title": "nodejs/node – 2025-10-20, Version 22.21.0 'Jod' (LTS), @aduh95",
    "date": "2025-10-20T23:56:15.000Z",
    "source": "GitHub",
    "url": "https://github.com/nodejs/node/releases/tag/v22.21.0",
    "content": "\n\n\n### Notable Changes\n\n* \\[[`1486fedea1`](https://github.com/nodejs/node/commit/1486fedea1)] - **(SEMVER-MINOR)** **cli**: add `--use-env-proxy` (Joyee Cheung) [#59151](https://github.com/nodejs/node/pull/59151)\n* \\[[`bedaaa11fc`](https://github.com/nodejs/node/commit/bedaaa11fc)] - **(SEMVER-MINOR)** **http**: support http proxy for fetch under `NODE_USE_ENV_PROXY` (Joyee Cheung) [#57165](https://github.com/nodejs/node/pull/57165)\n* \\[[`af8b5fa29d`](https://github.com/nodejs/node/commit/af8b5fa29d)] - **(SEMVER-MINOR)** **http**: add `shouldUpgradeCallback` to let servers control HTTP upgrades (Tim Perry) [#59824](https://github.com/nodejs/node/pull/59824)\n* \\[[`42102594b1`](https://github.com/nodejs/node/commit/42102594b1)] - **(SEMVER-MINOR)** **http,https**: add built-in proxy support in `http`/`https.request` and `Agent` (Joyee Cheung) [#58980](https://github.com/nodejs/node/pull/58980)\n* \\[[`686ac49b82`](https://github.com/nodejs/node/commit/686ac49b82)] - **(SEMVER-MINOR)** **src**: add percentage support to `--max-old-space-size` (Asaf Federman) [#59082](https://github.com/nodejs/node/pull/59082)\n\n### Commits\n\n* \\[[`a71dd592e3`](https://github.com/nodejs/node/commit/a71dd592e3)] - **benchmark**: calibrate config dgram multi-buffer (Bruno Rodrigues) [#59696](https://github.com/nodejs/node/pull/59696)\n* \\[[`16c4b466f4`](https://github.com/nodejs/node/commit/16c4b466f4)] - **benchmark**: calibrate config cluster/echo.js (Nam Yooseong) [#59836](https://github.com/nodejs/node/pull/59836)\n* \\[[`53cb9f3b6c`](https://github.com/nodejs/node/commit/53cb9f3b6c)] - **build**: add the missing macro definitions for OpenHarmony (hqzing) [#59804](https://github.com/nodejs/node/pull/59804)\n* \\[[`ec5290fe01`](https://github.com/nodejs/node/commit/ec5290fe01)] - **build**: do not include custom ESLint rules testing in tarball (Antoine du Hamel) [#59809](https://github.com/nodejs/node/pull/59809)\n* \\[[`1486fedea1`](https://github.com/nodejs/node/commit/1486fedea1)] - **(SEMVER-MINOR)** **cli**: add --use-env-proxy (Joyee Cheung) [#59151](https://github.com/nodejs/node/pull/59151)\n* \\[[`1f93913446`](https://github.com/nodejs/node/commit/1f93913446)] - **crypto**: use `return await` when returning Promises from async functions (Renegade334) [#59841](https://github.com/nodejs/node/pull/59841)\n* \\[[`f488b2ff73`](https://github.com/nodejs/node/commit/f488b2ff73)] - **crypto**: use async functions for non-stub Promise-returning functions (Renegade334) [#59841](https://github.com/nodejs/node/pull/59841)\n* \\[[`aed9fd5ac4`](https://github.com/nodejs/node/commit/aed9fd5ac4)] - **crypto**: avoid calls to `promise.catch()` (Renegade334) [#59841](https://github.com/nodejs/node/pull/59841)\n* \\[[`37c2d186f0`](https://github.com/nodejs/node/commit/37c2d186f0)] - **deps**: update amaro to 1.1.4 (pmarchini) [#60044](https://github.com/nodejs/node/pull/60044)\n* \\[[`28aea13419`](https://github.com/nodejs/node/commit/28aea13419)] - **deps**: update archs files for openssl-3.5.4 (Node.js GitHub Bot) [#60101](https://github.com/nodejs/node/pull/60101)\n* \\[[`ddbc1aa0bb`](https://github.com/nodejs/node/commit/ddbc1aa0bb)] - **deps**: upgrade openssl sources to openssl-3.5.4 (Node.js GitHub Bot) [#60101](https://github.com/nodejs/node/pull/60101)\n* \\[[`badbba2da9`](https://github.com/nodejs/node/commit/badbba2da9)] - **deps**: update googletest to 50b8600 (Node.js GitHub Bot) [#59955](https://github.com/nodejs/node/pull/59955)\n* \\[[`48aaf98a08`](https://github.com/nodejs/node/commit/48aaf98a08)] - **deps**: update archs files for openssl-3.5.3 (Node.js GitHub Bot) [#59901](https://github.com/nodejs/node/pull/59901)\n* \\[[`e02a562ea6`](https://github.com/nodejs/node/commit/e02a562ea6)] - **deps**: upgrade openssl sources to openssl-3.5.3 (Node.js GitHub Bot) [#59901](https://github.com/nodejs/node/pull/59901)\n* \\[[`7e0e86cb92`](https://github.com/nodejs/node/commit/7e0e86cb92)] - **deps**: upgrade npm to 10.9.4 (npm team) [#60074](https://github.com/nodejs/node/pull/60074)\n* \\[[`91dda5facf`](https://github.com/nodejs/node/commit/91dda5facf)] - **deps**: update undici to 6.22.0 (Matteo Collina) [#60112](https://github.com/nodejs/node/pull/60112)\n* \\[[`3a3220a2f0`](https://github.com/nodejs/node/commit/3a3220a2f0)] - **dgram**: restore buffer optimization in fixBufferList (Yoo) [#59934](https://github.com/nodejs/node/pull/59934)\n* \\[[`09bdcce6b8`](https://github.com/nodejs/node/commit/09bdcce6b8)] - **diagnostics\\_channel**: fix race condition with diagnostics\\_channel and GC (Ugaitz Urien) [#59910](https://github.com/nodejs/node/pull/59910)\n* \\[[`b3eeb3bd13`](https://github.com/nodejs/node/commit/b3eeb3bd13)] - **doc**: provide alternative to `url.parse()` using WHATWG URL (Steven) [#59736](https://github.com/nodejs/node/pull/59736)\n* \\[[`1ddaab1904`](https://github.com/nodejs/node/commit/1ddaab1904)] - **doc**: mention reverse proxy and include simple example (Steven) [#59736](https://github.com/nodejs/node/pull/59736)\n* \\[[`3b3b71e99c`](https://github.com/nodejs/node/commit/3b3b71e99c)] - **doc**: mark `.env` files support as stable (Santeri Hiltunen) [#59925](https://github.com/nodejs/node/pull/59925)\n* \\[[`d37f67d1bd`](https://github.com/nodejs/node/commit/d37f67d1bd)] - **doc**: remove optional title prefixes (Aviv Keller) [#60087](https://github.com/nodejs/node/pull/60087)\n* \\[[`ca2dff63f9`](https://github.com/nodejs/node/commit/ca2dff63f9)] - **doc**: fix typo on child\\_process.md (Angelo Gazzola) [#60114](https://github.com/nodejs/node/pull/60114)\n* \\[[`3fca564a05`](https://github.com/nodejs/node/commit/3fca564a05)] - **doc**: add automated migration info to deprecations (Augustin Mauroy) [#60022](https://github.com/nodejs/node/pull/60022)\n* \\[[`4bc366fc16`](https://github.com/nodejs/node/commit/4bc366fc16)] - **doc**: use \"WebAssembly\" instead of \"Web Assembly\" (Tobias Nießen) [#59954](https://github.com/nodejs/node/pull/59954)\n* \\[[`4808dbdd9a`](https://github.com/nodejs/node/commit/4808dbdd9a)] - **doc**: fix typo in section on microtask order (Tobias Nießen) [#59932](https://github.com/nodejs/node/pull/59932)\n* \\[[`d6e303d645`](https://github.com/nodejs/node/commit/d6e303d645)] - **doc**: update V8 fast API guidance (René) [#58999](https://github.com/nodejs/node/pull/58999)\n* \\[[`0a3a3f729e`](https://github.com/nodejs/node/commit/0a3a3f729e)] - **doc**: add security escalation policy (Ulises Gascón) [#59806](https://github.com/nodejs/node/pull/59806)\n* \\[[`8fd669c70d`](https://github.com/nodejs/node/commit/8fd669c70d)] - **doc**: type improvement of file `http.md` (yusheng chen) [#58189](https://github.com/nodejs/node/pull/58189)\n* \\[[`9833dc6060`](https://github.com/nodejs/node/commit/9833dc6060)] - **doc**: rephrase dynamic import() description (Nam Yooseong) [#59224](https://github.com/nodejs/node/pull/59224)\n* \\[[`2870a73681`](https://github.com/nodejs/node/commit/2870a73681)] - **doc,crypto**: update subtle.generateKey and subtle.importKey (Filip Skokan) [#59851](https://github.com/nodejs/node/pull/59851)\n* \\[[`85818db93c`](https://github.com/nodejs/node/commit/85818db93c)] - **fs,win**: do not add a second trailing slash in readdir (Gerhard Stöbich) [#59847](https://github.com/nodejs/node/pull/59847)\n* \\[[`bedaaa11fc`](https://github.com/nodejs/node/commit/bedaaa11fc)] - **(SEMVER-MINOR)** **http**: support http proxy for fetch under NODE\\_USE\\_ENV\\_PROXY (Joyee Cheung) [#57165](https://github.com/nodejs/node/pull/57165)\n* \\[[`af8b5fa29d`](https://github.com/nodejs/node/commit/af8b5fa29d)] - **(SEMVER-MINOR)** **http**: add shouldUpgradeCallback to let servers control HTTP upgrades (Tim Perry) [#59824](https://github.com/nodejs/node/pull/59824)\n* \\[[`758271ae66`](https://github.com/nodejs/node/commit/758271ae66)] - **http**: optimize checkIsHttpToken for short strings (방진혁) [#59832](https://github.com/nodejs/node/pull/59832)\n* \\[[`42102594b1`](https://github.com/nodejs/node/commit/42102594b1)] - **(SEMVER-MINOR)** **http,https**: add built-in proxy support in http/https.request and Agent (Joyee Cheung) [#58980](https://github.com/nodejs/node/pull/58980)\n* \\[[`a33ed9bf96`](https://github.com/nodejs/node/commit/a33ed9bf96)] - **inspector**: ensure adequate memory allocation for `Binary::toBase64` (René) [#59870](https://github.com/nodejs/node/pull/59870)\n* \\[[`34c686be2b`](https://github.com/nodejs/node/commit/34c686be2b)] - **lib**: update inspect output format for subclasses (Miguel Marcondes Filho) [#59687](https://github.com/nodejs/node/pull/59687)\n* \\[[`12e553529c`](https://github.com/nodejs/node/commit/12e553529c)] - **lib**: add source map support for assert messages (Chengzhong Wu) [#59751](https://github.com/nodejs/node/pull/59751)\n* \\[[`d2a70571f8`](https://github.com/nodejs/node/commit/d2a70571f8)] - **lib,src**: refactor assert to load error source from memory (Chengzhong Wu) [#59751](https://github.com/nodejs/node/pull/59751)\n* \\[[`20a9e86b5d`](https://github.com/nodejs/node/commit/20a9e86b5d)] - **meta**: move Michael to emeritus (Michael Dawson) [#60070](https://github.com/nodejs/node/pull/60070)\n* \\[[`c591cca15c`](https://github.com/nodejs/node/commit/c591cca15c)] - **meta**: bump github/codeql-action from 3.30.0 to 3.30.5 (dependabot\\[bot]) [#60089](https://github.com/nodejs/node/pull/60089)\n* \\[[`090ba141b1`](https://github.com/nodejs/node/commit/090ba141b1)] - **meta**: bump codecov/codecov-action from 5.5.0 to 5.5.1 (dependabot\\[bot]) [#60091](https://github.com/nodejs/node/pull/60091)\n* \\[[`a0ba6884a5`](https://github.com/nodejs/node/commit/a0ba6884a5)] - **meta**: bump actions/stale from 9.1.0 to 10.0.0 (dependabot\\[bot]) [#60092](https://github.com/nodejs/node/pull/60092)\n* \\[[`0feca0c541`](https://github.com/nodejs/node/commit/0feca0c541)] - **meta**: bump actions/setup-node from 4.4.0 to 5.0.0 (dependabot\\[bot]) [#60093](https://github.com/nodejs/node/pull/60093)\n* \\[[`7cd2b42d18`](https://github.com/nodejs/node/commit/7cd2b42d18)] - **meta**: bump step-security/harden-runner from 2.12.2 to 2.13.1 (dependabot\\[bot]) [#60094](https://github.com/nodejs/node/pull/60094)\n* \\[[`1f3b9d66ac`](https://github.com/nodejs/node/commit/1f3b9d66ac)] - **meta**: bump actions/cache from 4.2.4 to 4.3.0 (dependabot\\[bot]) [#60095](https://github.com/nodejs/node/pull/60095)\n* \\[[`0fedbb3de7`](https://github.com/nodejs/node/commit/0fedbb3de7)] - **meta**: bump ossf/scorecard-action from 2.4.2 to 2.4.3 (dependabot\\[bot]) [#60096](https://github.com/nodejs/node/pull/60096)\n* \\[[`04590b8267`](https://github.com/nodejs/node/commit/04590b8267)] - **meta**: bump actions/setup-python from 5.6.0 to 6.0.0 (dependabot\\[bot]) [#60090](https://github.com/nodejs/node/pull/60090)\n* \\[[`2bf0a9318f`](https://github.com/nodejs/node/commit/2bf0a9318f)] - **meta**: add .npmrc with ignore-scripts=true (Joyee Cheung) [#59914](https://github.com/nodejs/node/pull/59914)\n* \\[[`e10dc7b81c`](https://github.com/nodejs/node/commit/e10dc7b81c)] - **module**: allow overriding linked requests for a ModuleWrap (Chengzhong Wu) [#59527](https://github.com/nodejs/node/pull/59527)\n* \\[[`2237142369`](https://github.com/nodejs/node/commit/2237142369)] - **module**: link module with a module request record (Chengzhong Wu) [#58886](https://github.com/nodejs/node/pull/58886)\n* \\[[`6d24b88fbc`](https://github.com/nodejs/node/commit/6d24b88fbc)] - **node-api**: added SharedArrayBuffer api (Mert Can Altin) [#59071](https://github.com/nodejs/node/pull/59071)\n* \\[[`4cc84c96f4`](https://github.com/nodejs/node/commit/4cc84c96f4)] - **node-api**: make napi\\_delete\\_reference use node\\_api\\_basic\\_env (Jeetu Suthar) [#59684](https://github.com/nodejs/node/pull/59684)\n* \\[[`e790eb6b50`](https://github.com/nodejs/node/commit/e790eb6b50)] - **repl**: fix cpu overhead pasting big strings to the REPL (Ruben Bridgewater) [#59857](https://github.com/nodejs/node/pull/59857)\n* \\[[`99ea08dc43`](https://github.com/nodejs/node/commit/99ea08dc43)] - **repl**: add isValidParentheses check before wrap input (Xuguang Mei) [#59607](https://github.com/nodejs/node/pull/59607)\n* \\[[`e4a4f63019`](https://github.com/nodejs/node/commit/e4a4f63019)] - **sqlite**: fix crash session extension callbacks with workers (Bart Louwers) [#59848](https://github.com/nodejs/node/pull/59848)\n* \\[[`42c5544b97`](https://github.com/nodejs/node/commit/42c5544b97)] - **src**: assert memory calc for max-old-space-size-percentage (Asaf Federman) [#59460](https://github.com/nodejs/node/pull/59460)\n* \\[[`686ac49b82`](https://github.com/nodejs/node/commit/686ac49b82)] - **(SEMVER-MINOR)** **src**: add percentage support to --max-old-space-size (Asaf Federman) [#59082](https://github.com/nodejs/node/pull/59082)\n* \\[[`84701ff668`](https://github.com/nodejs/node/commit/84701ff668)] - **src**: clear all linked module caches once instantiated (Chengzhong Wu) [#59117](https://github.com/nodejs/node/pull/59117)\n* \\[[`8e182e561f`](https://github.com/nodejs/node/commit/8e182e561f)] - **src**: remove unnecessary `Environment::GetCurrent()` calls (Moonki Choi) [#59814](https://github.com/nodejs/node/pull/59814)\n* \\[[`c9cde35c4d`](https://github.com/nodejs/node/commit/c9cde35c4d)] - **src**: simplify is\\_callable by making it a concept (Tobias Nießen) [#58169](https://github.com/nodejs/node/pull/58169)\n* \\[[`892b425ee1`](https://github.com/nodejs/node/commit/892b425ee1)] - **src**: rename private fields to follow naming convention (Moonki Choi) [#59923](https://github.com/nodejs/node/pull/59923)\n* \\[[`36b68db7f5`](https://github.com/nodejs/node/commit/36b68db7f5)] - **src**: reduce the nearest parent package JSON cache size (Michael Smith) [#59888](https://github.com/nodejs/node/pull/59888)\n* \\[[`26b40bad02`](https://github.com/nodejs/node/commit/26b40bad02)] - **src**: replace FIXED\\_ONE\\_BYTE\\_STRING with Environment-cached strings (Moonki Choi) [#59891](https://github.com/nodejs/node/pull/59891)\n* \\[[`34dcb7dc32`](https://github.com/nodejs/node/commit/34dcb7dc32)] - **src**: create strings in `FIXED_ONE_BYTE_STRING` as internalized (Anna Henningsen) [#59826](https://github.com/nodejs/node/pull/59826)\n* \\[[`4d748add05`](https://github.com/nodejs/node/commit/4d748add05)] - **src**: remove `std::array` overload of `FIXED_ONE_BYTE_STRING` (Anna Henningsen) [#59826](https://github.com/nodejs/node/pull/59826)\n* \\[[`bb6fd7c2d1`](https://github.com/nodejs/node/commit/bb6fd7c2d1)] - **src**: ensure `v8::Eternal` is empty before setting it (Anna Henningsen) [#59825](https://github.com/nodejs/node/pull/59825)\n* \\[[`7a91282bf9`](https://github.com/nodejs/node/commit/7a91282bf9)] - **src**: use simdjson::pad (0hm☘️) [#59391](https://github.com/nodejs/node/pull/59391)\n* \\[[`ba00875f01`](https://github.com/nodejs/node/commit/ba00875f01)] - **stream**: use new AsyncResource instead of bind (Matteo Collina) [#59867](https://github.com/nodejs/node/pull/59867)\n* \\[[`ebec3ef68b`](https://github.com/nodejs/node/commit/ebec3ef68b)] - **(SEMVER-MINOR)** **test**: move http proxy tests to test/client-proxy (Joyee Cheung) [#58980](https://github.com/nodejs/node/pull/58980)\n* \\[[`7067d79fb3`](https://github.com/nodejs/node/commit/7067d79fb3)] - **test**: mark sea tests flaky on macOS x64 (Richard Lau) [#60068](https://github.com/nodejs/node/pull/60068)\n* \\[[`ca1942c9d5`](https://github.com/nodejs/node/commit/ca1942c9d5)] - **test**: testcase demonstrating issue 59541 (Eric Rannaud) [#59801](https://github.com/nodejs/node/pull/59801)\n* \\[[`660d57355e`](https://github.com/nodejs/node/commit/660d57355e)] - **test,doc**: skip --max-old-space-size-percentage on 32-bit platforms (Asaf Federman) [#60144](https://github.com/nodejs/node/pull/60144)\n* \\[[`19a7b1ef26`](https://github.com/nodejs/node/commit/19a7b1ef26)] - **tls**: load bundled and extra certificates off-thread (Joyee Cheung) [#59856](https://github.com/nodejs/node/pull/59856)\n* \\[[`095e7a81fc`](https://github.com/nodejs/node/commit/095e7a81fc)] - **tls**: only do off-thread certificate loading on loading tls (Joyee Cheung) [#59856](https://github.com/nodejs/node/pull/59856)\n* \\[[`c42c1204c7`](https://github.com/nodejs/node/commit/c42c1204c7)] - **tools**: fix `tools/make-v8.sh` for clang (Richard Lau) [#59893](https://github.com/nodejs/node/pull/59893)\n* \\[[`b632a1d98d`](https://github.com/nodejs/node/commit/b632a1d98d)] - **tools**: skip test-internet workflow for draft PRs (Michaël Zasso) [#59817](https://github.com/nodejs/node/pull/59817)\n* \\[[`6021c3ac76`](https://github.com/nodejs/node/commit/6021c3ac76)] - **tools**: copyedit `build-tarball.yml` (Antoine du Hamel) [#59808](https://github.com/nodejs/node/pull/59808)\n* \\[[`ef005d0c9b`](https://github.com/nodejs/node/commit/ef005d0c9b)] - **typings**: update 'types' binding (René) [#59692](https://github.com/nodejs/node/pull/59692)\n* \\[[`28ef564ecd`](https://github.com/nodejs/node/commit/28ef564ecd)] - **typings**: remove unused imports (Nam Yooseong) [#59880](https://github.com/nodejs/node/pull/59880)\n* \\[[`f88752ddb6`](https://github.com/nodejs/node/commit/f88752ddb6)] - **url**: replaced slice with at (Mikhail) [#59181](https://github.com/nodejs/node/pull/59181)\n* \\[[`24c224960c`](https://github.com/nodejs/node/commit/24c224960c)] - **url**: add type checking to urlToHttpOptions() (simon-id) [#59753](https://github.com/nodejs/node/pull/59753)\n* \\[[`f2fbcc576d`](https://github.com/nodejs/node/commit/f2fbcc576d)] - **util**: fix debuglog.enabled not being present with callback logger (Ruben Bridgewater) [#59858](https://github.com/nodejs/node/pull/59858)\n* \\[[`6277058e43`](https://github.com/nodejs/node/commit/6277058e43)] - **vm**: sync-ify SourceTextModule linkage (Chengzhong Wu) [#59000](https://github.com/nodejs/node/pull/59000)\n* \\[[`5bf21a4309`](https://github.com/nodejs/node/commit/5bf21a4309)] - **vm**: explain how to share promises between contexts w/ afterEvaluate (Eric Rannaud) [#59801](https://github.com/nodejs/node/pull/59801)\n* \\[[`312b33a083`](https://github.com/nodejs/node/commit/312b33a083)] - **vm**: \"afterEvaluate\", evaluate() return a promise from the outer context (Eric Rannaud) [#59801](https://github.com/nodejs/node/pull/59801)\n* \\[[`1eadab863c`](https://github.com/nodejs/node/commit/1eadab863c)] - **win,tools**: add description to signature (Martin Costello) [#59877](https://github.com/nodejs/node/pull/59877)\n* \\[[`816e1befb1`](https://github.com/nodejs/node/commit/816e1befb1)] - **zlib**: reduce code duplication (jhofstee) [#57810](https://github.com/nodejs/node/pull/57810)\n\n"
  },
  {
    "title": "vercel/next.js – v16.0.0-canary.16",
    "date": "2025-10-20T23:37:15.000Z",
    "source": "GitHub",
    "url": "https://github.com/vercel/next.js/releases/tag/v16.0.0-canary.16",
    "content": "### Core Changes\n\n- Upgrade React from `58bdc0bb-20251019` to `f6a48828-20251019`: #85081\n- [devtools]: instrument client navigation hooks for suspense devtools: #85007\n- Remove Segment from CacheNodeSeedData: #85080\n- label as Prefetch/Prefetchable depending on prefetch config: #85076\n- [cache components]: add 'bypass' cache indicator status: #85082\n- Upgrade React from `f6a48828-20251019` to `2bcbf254-20251020`: #85112\n- [cache components]: guard against setCacheStatus since its conditionally defined: #85125\n- warn: add deprecation warning of eslint config: #85122\n- add new devtools indicator loading state: #85083\n- Await initial Flight response before hydrating: #85124\n- fix(experimental.lockDistDir): Acquire the lock in dev earlier: #85116\n- telemetry: mcp tool call: #85120\n- [Turbopack] dedupe build errors: #85062\n\n### Misc Changes\n\n- docs: experimentalClientMaxBodySize: #85105\n- Docs: Add `--debug-build-paths` next build option: #85097\n- Docs: Add note on tag limits for `cacheTag`: #85106\n- docs: no switcher for TS only examples: #85109\n- fix: Handle non-directory files in cache folder when performing cleanup: #84930\n- Turbopack: Suggest using system certs when a TLS error occurs: #85009\n- [turbopack] Try to fix v8 crashes on github actions: #85114\n- docs: Update to Zod v4 syntax: #84807\n- Docs: Add version history for `next lint` deprecation and update error message: #85100\n- Turbopack: improve module evaluation name: #84633\n- [test] Current behavior of dynamic APIs integration with React DevTools: #85111\n- [Cache Components] fix env labels in perf track test: #85132\n\n### Credits \n\nHuge thanks to @ztanner, @icyJoseph, @delbaoliveira, @acdlite, @lubieowoce, @bgw, @lukesandberg, @huozhi, @makandrr, @sokra, and @eps1lon for helping!\n"
  },
  {
    "title": "【個人開発】マッチング型サービスの技術選定",
    "date": "2025-10-20T23:00:01.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/yosashusaku/articles/perdev-matching-techselect",
    "content": "\n はじめに\nマッチング型の求人サービス「おためし転職」を個人開発しました。本記事では、求職者向け（toC）と企業向け（toB）の2つのプラットフォームを構築する上での技術選定と、その理由について解説します。\n求職者向けサイト（toC）: https://otame4.work/\n企業向けサイト（toB）: https://employer.otame4.work/\n\n 技術スタック\nインフラ：Cloudflare, Supabase\nフロント：Next.js(toC,toB共に)\nORM：Drizzle\n\n 認証（工夫した点）\nSupabase Auth: 求職者向け（toC）\nBet..."
  },
  {
    "title": "やっぱり、ゲーム開発に憧れていた。はじめてのUnity",
    "date": "2025-10-20T11:54:11.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/ty0627/articles/acd6d546dbf293",
    "content": "はじめまして。\n先日、zennの運営会社であるクラスメソッドさん主催の「DevelopersIO 2025 TOKYO」に参加させていただきました。アウトプットの重要性を熱く語っていてとても感動し、一念発起して始めてみました。\nhttps://events.classmethod.jp/seminar/251018-developersio2025-tokyo/\n\n 軽く自己紹介\n学生エンジニア見習いのあんとんです。ここで「見習い」と書いたのは、大学で学んでいる分野は情報系ではなく、エンジニアを目指して勉強を始めたのは今年から。そのため、所々用語の使い方が適切ではないかもしれませんが、温..."
  },
  {
    "title": "タスク管理に「AIに依頼」機能をつけたら開発体験がめちゃ向上した話",
    "date": "2025-10-20T10:43:32.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/himara2/articles/03fbe80334b86d",
    "content": "個人開発でタスク管理サービスを作っています。\nそのサービスに 「このタスクをAIに進めてもらう」 機能をつけたらめちゃ体験が良くなったので紹介させてください。\n\n 作ってるもの\ntone（トーン）というWebサービスを作っています。\nコンセプトは「人とAIのためのチームタスク管理」。人が使いやすいインターフェースに加え、MCP経由でAIからも使えるのが特徴のタスク管理サービスです。\nhttps://tone-task.com/\n今回、このtoneのタスクから直接AIに依頼できる機能をつけてみました。\n\n AIにタスクを依頼する\nAIにタスクを依頼する流れを紹介します。\nまずは普通にタスク..."
  },
  {
    "title": "React Compiler v1.0がリリースされました！",
    "date": "2025-10-20T08:30:16.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/terass_dev/articles/eca0bad44e8d39",
    "content": "TERASSエンジニアの@shuji_koikeです！\n昨年弊社のテックブログで同僚の@myrearが\"React Forget は何を「忘れ」させてくれるのか\"という秀逸なタイトルの記事を投稿したところトレンド入りを果たし、弊ブログとしては快挙と言える数の「いいね」をいただきました。\nそしてついに先日React Conf 2025に合わせて、React Forgetは名前を変えてReact Compiler v1.0 babel-plugin-react-compiler@1.0.0としてリリースされました！\nReact CompilerのRC版は一年近く前から公開されているので、すで..."
  },
  {
    "title": "Amazon Q Developer で Audible のユニットテスト自動化を強化",
    "date": "2025-10-20T05:44:48.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/boosting-unit-test-automation-at-audible-with-amazon-q-developer/",
    "content": "<p>本記事は 2025 年 10 月 10 日に公開された “<a href=\"https://aws.amazon.com/jp/blogs/devops/boosting-unit-test-automation-at-audible-with-amazon-q-developer/\" target=\"_blank\" rel=\"noopener\">Boosting Unit Test Automation at Audible with Amazon Q Developer</a>” を翻訳したものです。</p> \n<p>Amazon の子会社である <a href=\"https://www.audible.co.jp/?ref=Adbl_ip_rdr_from_US&amp;source_code=ADBANON002061821003I&amp;ipRedirectFrom=US&amp;ipRedirectOriginalURL=\" target=\"_blank\" rel=\"noopener\">Audible</a> は、オーディオストーリーテリングの大手プロデューサーかつプロバイダーです。オーディオブック、ポッドキャスト、特別にキュレーションされた Audible Originals を含む 100 万タイトル以上の膨大なライブラリを持っています。Audible は没入感のあるオーディオ体験で、日常を学習や想像力、エンターテイメントの機会に変えています。数百万のエンドユーザーがデバイス間でシームレスな体験を楽しめるよう、堅牢なテストが重要です。</p> \n<p>テストカバレッジが不十分なコードベースを引き継いだ経験はありませんか？あるいは、締切に間に合わせるために急いでコードを書き、「後で」テストを追加すると約束したことは？私たちは皆そのような経験があります。テストは重要ですが、締切が迫ると優先度が下がりがちです。そこで <a href=\"https://aws.amazon.com/jp/q/developer/build/\" target=\"_blank\" rel=\"noopener\">Amazon Q Developer</a> のエージェント機能が登場し、開発者のテスト生成アプローチを変革しています。このブログでは、Audible が Amazon Q Developer を活用してユニットテストカバレッジを向上させた方法を紹介します。</p> \n<h2>ソフトウェアテストのビジネスユースケース</h2> \n<p>ベロシティの高い開発環境では、厳しい締切の下でテストサイクルが圧縮されることが多く、品質に問題が生じやすくなります。Amazon Q Developer は包括的な基準を維持しながらテストを加速し、この状況を変えます。自動テスト生成、エッジケースの特定、修正提案により、チームは短い時間で徹底的なテストを実行できます。これにより迅速なリリース、QA リソースの最適化、本番環境への準備強化を実現します。</p> \n<p>適切なテストが実装されていない各関数は、作り直し、バグ、メンテナンスの課題につながる可能性があります。さらに、引き継いだコードベースは特別な課題を提示します。開発者は既存機能のテストを書くのに数週間を費やすか、テストなしでの開発を続けるかという難しい選択を迫られます。</p> \n<p>Amazon Q Developer は適切なテストカバレッジに必要な時間と労力を削減し、これらの課題に対処します。テストを面倒な作業から効率的なプロセスに変え、チームがコード品質を確保しながら新機能の提供に集中できるようにします。</p> \n<h2>Amazon Q Developer：コードベースのテストカバレッジ拡張</h2> \n<p>Amazon Q Developer のエージェント機能は、ソフトウェアテスト生成に高度なアプローチを提供します。汎用的なテストを生成する従来ツールとは異なり、Amazon Q Developer はコードの意図、ビジネスロジック、エッジケースを分析します。単にテストを生成するだけでなく、コードの動作を包括的に検証する意味のあるテストスイートを作成します。</p> \n<p>今回紹介する専用のテスト生成機能以外にも、Amazon Q Developer はテストを支援するさまざまな方法を提供します。テスト計画生成のための会話型プロンプトの使用、既存コードのテスト改善要求、テスト作成時の Amazon Q Developer とのペアプログラミングなどが可能です。テスト開発プロセス全体に AI アシスタンスを統合する柔軟性により、Amazon Q Developer は開発者にとって多用途なパートナーとなります。</p> \n<h3>Amazon Q Developer のワークフローアーキテクチャ</h3> \n<p>以下のアーキテクチャ図は、Audible がテスト生成とコード変換の両方で Amazon Q Developer を活用した方法を示しています。</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/Q-developer-workflow.png\"></p> \n<p>Amazon Q Developer の開発プロセスは、2つの主要な機能を実証します。</p> \n<ul> \n <li><span style=\"text-decoration: underline\"><strong>テスト生成：</strong></span>Amazon Q Developer は Java クラスを分析し、ユニットテスト、エッジケーステスト、例外処理テストを含む包括的なテストスイートを作成します。</li> \n <li><span style=\"text-decoration: underline\"><strong>コード変換：</strong></span>Amazon Q Developer は自動移行タスクを実行します。これには <code>JDK 8</code> から <code>JDK 17/21</code> へのアップグレード、言語バージョン互換性の処理、<code>JUnit 4</code> から <code>JUnit 5</code> への変換、テストフレームワークの構文とアノテーションのモダナイゼーション、非推奨 API とコードパターンの更新が含まれます。</li> \n</ul> \n<p>この開発プロセスがとくに強力なのは、AI 機能と人間の専門知識を組み合わせる点です。エキスパート開発者が日常の開発プロセスで AI を活用できるようにします。Amazon Q Developer はコードベースを分析してコンテキストとして使用し、エッジケースを特定し、自動変換を実行します。一方で開発者はドメイン知識を適用し、出力がビジネス要件と期待される動作に合致することを確保します。</p> \n<h2>Amazon Q Developer の可能性を活用する Audible のアプローチ</h2> \n<p>Audible チームは、Amazon Q Developer を活用してテストカバレッジを向上させるために以下のステップに従いました。</p> \n<p><span style=\"text-decoration: underline\"><strong>コード生成：</strong></span>Audible チームは Amazon Q Developer を活用し、Java クラスの追加ユニットテストを生成してテストカバレッジを強化しました。対象には静的メソッドや既存のテストケースを持つメソッドも含まれます。このアプローチは彼らの堅牢なテスト戦略を補完しました。Amazon Q Developer はクラス、メソッド、パラメータ、戻り値の型、例外を調べる能力を持っています。null 入力チェックや空文字列チェックなど、見落としやすいエッジケースをカバーするユニットテストを自動的に特定します。</p> \n<p><span style=\"text-decoration: underline\"><strong>対象を絞った要求：</strong></span>Audible チームは Amazon Q Developer に以下を提供するよう具体的に依頼しました。</p> \n<ul> \n <li>Java クラス内の指定されたメソッドをカバーするユニットテストの提案</li> \n <li>テストされていないエッジケースを対象とするユニットテストの推奨事項</li> \n <li>エラー処理と例外シナリオに対処するテストケースの推奨事項</li> \n</ul> \n<p>Audible チームはテスト生成とコード変換の両方で Amazon Q Developer を使用し、大幅な改善を達成しました。成功の鍵は体系的な開発プロセスで、対象を絞ったプロンプトとともに豊富なコンテキストを提供することでした。</p> \n<h3>開発者の作業の流れ</h3> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/developer-workflow.png\"></p> \n<p>Audible は自動化ツールからの出力をレビューするため、人間参加型のアプローチを採用しています。上記の開発プロセスは完全なプロセスを示しています。：（1）IDE でクラスファイルを開く、（2）特定のメソッドを選択してプロンプトを追加する、（3）この組み合わされたコンテキストを Amazon Q Developer に送信する、（4）生成されたテストを受け取る、（5）テストをレビューしてコードベースに統合する。</p> \n<h2>効果的なプロンプトとアプローチ</h2> \n<p>Audible チームは Amazon Q Developer が対応できる対象を絞った要求を使用し、構造化されたアプローチに従いました。</p> \n<p><span style=\"text-decoration: underline\"><strong>コード生成：</strong></span>チームは Java クラスを Amazon Q Developer に提供し、個々のメソッドのテストを生成しました。対象には静的メソッドや、既にいくつかのテストがあるが完全なカバレッジが不足しているメソッドも含まれます。Amazon Q Developer はクラス、メソッド、パラメータ、戻り値の型、例外を調べ、null 入力チェックや空文字列チェックなどのエッジケースをカバーするユニットテストを自動的に特定しました。</p> \n<h3>特定のリクエストのための汎用サンプルプロンプト</h3> \n<p><em>基本的なテスト生成：</em></p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-text\">以下の Java メソッドのユニットテストを生成してください。すべての可能な入力シナリオとエッジケースをカバーすることに焦点を当ててください：\n\n[メソッドコードをここに]\n\n以下のテストを含めてください：\n- 有効な入力シナリオ\n- Null 入力チェック\n- 空文字列検証\n- 例外処理</code></pre> \n</div> \n<p><em>エッジケースフォーカス：</em></p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-text\">ユーザー入力を処理するこのメソッドがあります。見落としている可能性のあるエッジケースをカバーするユニットテストを提案してもらえますか？境界条件とエラーシナリオにとくに注意してください：\n\n[メソッドコードをここに]</code></pre> \n</div> \n<p><em>手動フレームワーク移行（Q Developer Chat 経由）：</em></p> \n<div class=\"hide-language\"> \n <pre class=\"unlimited-height-code\"><code class=\"lang-text\">この JUnit 4 テストを JUnit 5 形式に変換してください。アノテーションを更新し、適切な場合は最新の JUnit 5 機能を使用するようにしてください：\n\n[JUnit 4 テストコードをここに]</code></pre> \n</div> \n<blockquote>\n <p>注意：Amazon Q Developer のコード変換機能は、コードベース全体で JUnit4 から JUnit5 への移行を自動的に処理できますが、Audible は上記のように手動でターゲット化された変換のために会話型インターフェイスも使用しました。両方のアプローチが利用可能です。自動変換の詳細については<a href=\"https://docs.aws.amazon.com/ja_jp/amazonq/latest/qdeveloper-ug/transform-in-IDE.html\" target=\"_blank\" rel=\"noopener\">ドキュメント</a>を参照してください。</p>\n</blockquote> \n<p><span style=\"text-decoration: underline\"><strong>テスト生成：</strong></span>チームのリクエストに基づいて、Amazon Q Developer は適切なアサーションとテストメソッドでこれらの領域に対処する特定のテスト提案を生成しました。</p> \n<p><span style=\"text-decoration: underline\"><strong>実装：</strong></span>開発チームは、レビュー後に提案されたテストを実装しました。</p> \n<p><span style=\"text-decoration: underline\"><strong>ドキュメント：</strong></span>Amazon Q Developer は、テストの目的、テストがカバーしている機能の領域を説明するコメントを追加する能力を持っています。さらに、Amazon Q Developer は、readme ファイルやプロジェクトドキュメントなど、他の側面に関連するドキュメントを生成する能力も持っています。</p> \n<h2>定量化可能な結果</h2> \n<p>Amazon Q Developer を活用することで、Audible チームは以下を達成しました。</p> \n<ul> \n <li><span style=\"text-decoration: underline\"><strong>10 以上の主要パッケージ</strong></span>が包括的なユニットテストカバレッジを受けました</li> \n <li><strong><span style=\"text-decoration: underline\">テストクラスあたり約 1 時間</span></strong>の節約（通常 8-10 の個別テストを含む）</li> \n <li><span style=\"text-decoration: underline\"><strong>5,000 以上のテストケース</strong></span>が Amazon Q Developer のコード変換と手動での会話支援の両方を使用して<code>JUnit4</code> から <code>JUnit5</code> に正常に移行されました</li> \n <li>Amazon Q Developer のコード変換を使用し、<code>JDK8</code> から <code>JDK17</code> への移行にて&nbsp;<span style=\"text-decoration: underline\"><strong>50 時間以上の手作業を節約</strong></span></li> \n <li>AI 支援変換による人的エラーの削減</li> \n</ul> \n<h2>主要機能の実証結果</h2> \n<p>Amazon Q Developer は、手動テストで見落とされがちないくつかの領域で優れていました。</p> \n<p><strong><span style=\"text-decoration: underline\">包括的な例外テスト：</span></strong>標準的な null 入力チェックと空文字列検証を超えて、<code>IllegalArgumentException</code>、<code>NullPointerException</code>、カスタムビジネス例外のテストを自動的に提案しました。例外の投げ方と特定のエラーメッセージの両方の検証を含みます。この体系的なアプローチによりテストカバレッジがより完全になり、エラー処理がより堅牢になりました。</p> \n<p><span style=\"text-decoration: underline\"><strong>自動エッジケース検出：</strong></span>Amazon Q Developer はプロンプトなしで null ポインタ例外処理のインライン提案を行い、プロセスをよりスムーズで高速にしました。</p> \n<p><span style=\"text-decoration: underline\"><strong>AI 支援による手動フレームワーク移行：</strong></span>Amazon Q Developer のパターン認識は会話支援を通じて移行プロセスを加速しました。チームはチャットを通じて Amazon Q Developer に <code>JUnit4</code> から <code>JUnit5</code> へのテスト構文を手動で変換するよう依頼できました。たとえば、以前のセットアップには <code>@UseDataProvider</code> と <code>@DataProvider</code>アノテーションを持つ <code>JUnit4</code> 構文がありました。必要な作業はコードブロックをハイライトし、Send to Prompt して、Amazon Q Developer にテストを <code>JUnit5</code> 互換にするよう依頼することだけでした。数秒以内に ParameterizedTest アノテーションと Stream of Arguments を持つ信頼性の高い JUnit5 テストを生成し、手動で実装できました。</p> \n<p><span style=\"text-decoration: underline\"><strong>コンテキスト分析：</strong></span>Amazon Q Developer は既存のコードベースを分析してパターンを認識し、チームのコーディングスタイルとテスト規約に一致するテストを生成しました。</p> \n<h2>まとめ</h2> \n<p>Amazon Q Developer はテスト生成プロセスを時間のかかる作業から効率的な開発プロセスに変換し、チームが最小限の労力で包括的なテストカバレッジを達成できるようにします。これにより開発者はコード品質と信頼性を向上させながら、より価値の高い活動に集中できます。</p> \n<p>ビジネスへの影響は大きく、テストが負担でなくなるとチームは自然により良いテスト手法を採用します。全体的なコード品質が向上し、より高速な開発サイクルとメンテナンス時間の削減という好循環を作り出します。</p> \n<p>Amazon Q Developer の機能と価格の詳細については、<a href=\"https://aws.amazon.com/jp/q/developer/\" target=\"_blank\" rel=\"noopener\">Amazon Q Developer 製品ページ</a>をご覧ください。</p> \n<p>翻訳はApp Dev Consultantの宇賀神が担当しました。</p> \n<h2>著者について</h2> \n<p><img loading=\"lazy\" class=\"wp-image-1533 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/10/08/kirankumar.jpeg\" alt=\"kirankumar.jpeg\" width=\"218\" height=\"294\"></p> \n<p>Kirankumar Chandrashekar は AWS の Generative AI Specialist Solutions Architect で、Q Developer、Kiro、AI を使用した Developer Productivity などの次世代開発者体験ツールに焦点を当てています。AWS クラウドサービス、DevOps、モダナイゼーション、Infrastructure as Code の深い専門知識を持ち、革新的な AI 駆動ソリューションを通じて顧客の開発サイクルを加速し、開発者の生産性を向上させることを支援しています。Amazon Q Developer を活用することで、チームがアプリケーションをより高速に構築し、日常的なタスクを自動化し、開発作業の流れを合理化できるようにしています。Kirankumar は、複雑な顧客の課題を解決しながら開発者の効率を向上させることに専念しており、音楽、料理、旅行を楽しんでいます。</p> \n<p>&nbsp;</p> \n<p><img loading=\"lazy\" class=\"wp-image-1533 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/alex-torres-1.jpg\" alt=\"alex-torres.jpeg\" width=\"218\" height=\"294\" data-wp-editing=\"1\"></p> \n<p>Alex Torres は AWS の Senior Solutions Architect で、AWS 上でのアプリケーションのアーキテクチャ設計、設計、構築において <a href=\"https://amazon.com\" target=\"_blank\" rel=\"noopener\">Amazon.com</a> をサポートしています。セキュリティ、ガバナンス、開発者向けエージェント AI の深い専門知識を持ち、顧客が最先端のクラウド技術を活用して人々の生活を形作る製品を作成することを支援しています。革新的な AWS ソリューションを通じて複雑な課題を解決するチームの支援に情熱を注ぎ、Alex は最高水準のセキュリティとガバナンスを維持しながら顧客の成功を推進することに専念しています。仕事以外では、料理とハイキングを楽しんでいます。</p> \n<p>&nbsp;</p> \n<p><img loading=\"lazy\" class=\"wp-image-1533 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/GK_Profile_Picture-1.jpg\" width=\"218\" height=\"294\" data-wp-editing=\"1\"></p> \n<p>GK は Senior Customer Solutions Manager で、AWS の顧客としての Amazon をサポートする戦略的顧客アドバイザーです。AWS での 4 年間で、開発者の生産性向上と AWS サービス全体での Amazon のニーズの擁護に焦点を当て、ユーザー体験を向上させ、2つの組織間のより深い連携を推進してきました。高度な Amazon チームとの彼女の仕事は、最終的に内部と外部の両方の AWS 顧客に利益をもたらすソリューションの提供を支援しています。GK は、GenAI が開発者と非開発者の間のギャップをどのように埋めているかにとくに関心があり、GenAI とセキュリティの課題解決に多くの時間を費やしています。彼女はサンフランシスコベイエリアを拠点とし、ハイキングとキャンプを楽しんでいます。</p> \n<p>&nbsp;</p> \n<p><img loading=\"lazy\" class=\"wp-image-1533 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/aditi-linkedin.jpeg\" width=\"218\" height=\"294\" data-wp-editing=\"1\"></p> \n<p>Aditi Joshi は Audible のソフトウェアエンジニアで、Amazon プラットフォーム全体での Audible の存在拡大に取り組んでいます。フルスタック開発者として、主に Web 技術、クラウドサービス、JavaScript と Java などのプログラミング言語を使用して、Amazon iOS アプリでの Audible 購入機能の導入などの最近のプロジェクトを含む、クロスプラットフォーム統合機能を構築・強化しています。ユーザーインターフェイス開発、レスポンシブデザイン、Web 技術の専門知識を持ち、Audible オファーの紹介と Amazon エコシステム全体での Audible の可視性向上に焦点を当てています。Aditi は、クリーンで効率的なコードでスケーラブルなシステムを構築することに焦点を当てたソフトウェアアーキテクチャとユーザー体験に情熱を注いでいます。コーディング以外では、旅行、ヨガ、音楽鑑賞を楽しんでいます。</p> \n<p>&nbsp;</p> \n<p><img loading=\"lazy\" class=\"wp-image-1533 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/10/10/SP-headshot.jpeg\" width=\"218\" height=\"294\" data-wp-editing=\"1\"></p> \n<p>Sam Park は Audible のソフトウェア開発エンジニアで、Amazon プラットフォーム全体での Audible 機能の構築に焦点を当てています。Amazon Cart を通じた Audible 購入の有効化、および Amazon iOS と Android アプリ内での Audible の可視性拡大において重要な役割を果たしてきました。彼の仕事は、検索、商品ページ、チェックアウト、カート体験を含む Amazon エコシステム内の複数のタッチポイントにわたっています。Sam は、直感的な顧客体験を創出するソリューションの開発と、開発効率と生産性を向上させるための GenAI の活用に情熱を注いでいます。仕事以外では、旅行、バスケットボール、クリーブランド・キャバリアーズの応援を楽しんでいます。</p>"
  },
  {
    "title": "vitejs/vite – v5.4.21",
    "date": "2025-10-20T05:30:37.000Z",
    "source": "GitHub",
    "url": "https://github.com/vitejs/vite/releases/tag/v5.4.21",
    "content": "Please refer to [CHANGELOG.md](https://github.com/vitejs/vite/blob/v5.4.21/packages/vite/CHANGELOG.md) for details."
  },
  {
    "title": "vitejs/vite – v6.4.1",
    "date": "2025-10-20T05:25:55.000Z",
    "source": "GitHub",
    "url": "https://github.com/vitejs/vite/releases/tag/v6.4.1",
    "content": "Please refer to [CHANGELOG.md](https://github.com/vitejs/vite/blob/v6.4.1/packages/vite/CHANGELOG.md) for details."
  },
  {
    "title": "vitejs/vite – v7.0.8",
    "date": "2025-10-20T05:20:29.000Z",
    "source": "GitHub",
    "url": "https://github.com/vitejs/vite/releases/tag/v7.0.8",
    "content": "Please refer to [CHANGELOG.md](https://github.com/vitejs/vite/blob/v7.0.8/packages/vite/CHANGELOG.md) for details."
  },
  {
    "title": "vitejs/vite – v7.1.11",
    "date": "2025-10-20T05:09:01.000Z",
    "source": "GitHub",
    "url": "https://github.com/vitejs/vite/releases/tag/v7.1.11",
    "content": "Please refer to [CHANGELOG.md](https://github.com/vitejs/vite/blob/v7.1.11/packages/vite/CHANGELOG.md) for details."
  },
  {
    "title": "LLMの責務を最小化する設計 — Claude Codeの中身は50代のベテランエンジニアかもしれない件",
    "date": "2025-10-20T02:59:31.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/sogab3/articles/fbf0230234ffe1",
    "content": "\n TL;DR\n本記事は、著者自身の振り返りとClaude Codeの分析を通して得た気づきを共有するものです。要点は下記です：\n\nDeep Learning時代のEnd-to-End学習の成功体験が、汎用LLM時代では逆に足かせになっているのではないか\n汎用性が高すぎるLLMには、むしろ古典的な設計原則（SOLID、関心の分離）が必要\n\nClaude Codeの成功には、LLMの責務を最小化し従来の設計原則を忠実に適用していることが寄与している\n\nLLMの責務を減らすことで開発者の責務は増えるが、これは「本来あるべき姿」への回帰\nパラダイムは変わっても、ソフトウェアエンジニアリングの基..."
  },
  {
    "title": "[資料公開 & 開催報告] Amazon Q Developer Meetup #3 を開催しました",
    "date": "2025-10-20T02:57:22.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/amazon-q-developer-meetup-3-report/",
    "content": "<p>2025 年 9 月 30 日に AWS Startup Loft Tokyo (目黒) で開催された「<a href=\"https://aws-experience.com/apj/smb/event/a9fb2855-8aae-43ed-b8bd-3e5cb537682c\">Amazon Q Developer Meetup #3 生成AIの利用を中心としたソフトウェア開発の新しいアプローチであるAI-DLCおよびその活用実績のご紹介</a>」のイベントの様子をレポートします。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167073\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-1024x573.png\" alt=\"\" width=\"1024\" height=\"573\"></a></p> \n<p>このイベントは、生成 AI を中心としたソフトウェア開発に対する新たなアプローチである、<strong>AI 駆動開発ライフサイクル (AI-DLC)</strong> をテーマに実施しました。まず Developer Specialist SA の金森から AI-DLC が必要とされる背景と、AI-DLC の概要、進め方をご紹介しました。続いて、すでに AI-DLC を体験していただいた LINE ヤフー株式会社様、株式会社サイバーエージェント様、東京海上日動システムズ株式会社様に、実際の進め方や学び、今後の展望などについて発表していただきました。</p> \n<p>現地参加・オンライン参加合わせて 200 名以上の方にご登録いただきました。参加者の方からは「実際に AI-DLC を実施した結果としての良い点、課題点が聞けたことが良かったです。」とのご感想をいただきました。AI-DLC を始めて知った方、これから AI-DLC の実施を検討されている方、すでに AI-DLC を体験されて改善に取り組まれている方、それぞれの皆様にご参考いただける情報をお届けしました。</p> \n<p>現地参加の方のみ、ケータリングをご用意し、ネットワーキングのための懇親会を実施しました。<br> 登壇者の方への質問や、参加者同士の意見交換、AWS メンバーへの相談が活発におこなわれていました。</p> \n<h2>イベント概要</h2> \n<ul> \n <li>開催日時: 2025年9月30日</li> \n <li>会場: AWS Startup Loft Tokyo (目黒)、オンライン配信</li> \n <li>スピーカー \n  <ul> \n   <li>LINE ヤフー株式会社様「AI-DLC を活用した、 負荷試験環境の構築」</li> \n   <li>株式会社サイバーエージェント様「CA 流、現場と伴走する AI 駆動開発 (AI-DLC)」</li> \n   <li>東京海上日動システムズ株式会社様「AI-DLC 体験記」</li> \n   <li>Developer Specialist SA 金森政雄, Amazon Web Services Japan G.K. 「AI 駆動開発ライフサイクル (AI-DLC) ソフトウェアエンジニアリングの再構築」</li> \n  </ul> </li> \n <li>登壇資料: <a href=\"https://pages.awscloud.com/rs/112-TZM-766/images/qdev-meetup3.zip\">こちらからダウンロード (zip)</a></li> \n</ul> \n<h2>AI 駆動開発ライフサイクル(AI-DLC)ソフトウェアエンジニアリングの再構築</h2> \n<p>スピーカー: Developer Specialist SA 金森政雄, Amazon Web Services Japan G.K.</p> \n<p>はじめに、Developer スペシャリストソリューションアーキテクトの金森より、AI-DLC をご紹介しました。<br> まず、ソフトウェア開発における生成 AI 利用に対する既存のアプローチの課題を挙げ、AI-DLC が必要とされる背景について述べました。続いて、開発プロセスを生成 AI が制御し、開発者が最終的な責任を保持するという AI-DLC のコンセプトを示し、AI-DLC を構成する各ステップの詳細についてご説明しました。そして AI-DLC を実践するためのアプローチであり、ご登壇いただいた各社様にご体験いただいた、AI-DLC Unicorn Gym についてケーススタディに基づいて仕組みや期待される成果についてご説明しました。<br> AI-DLC についてさらに詳しく知りたい方は、添付資料と併せてブログ「<a href=\"https://aws.amazon.com/jp/blogs/news/ai-driven-development-life-cycle/\">AI 駆動開発ライフサイクル:ソフトウェアエンジニアリングの再構築</a>」をご覧ください。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-1.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167074\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-1-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a><img loading=\"lazy\" class=\"alignnone size-large wp-image-167075\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-2-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-3.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167076\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-3-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-4.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167077\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/intro-4-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a></p> \n<h2>LINEヤフー株式会社 様「AI-DLC を活用した、 負荷試験環境の構築」</h2> \n<p>LINE ヤフー株式会社様からは「AI-DLC を活用した、 負荷試験環境の構築」と題して、負荷試験環境の構築に AI-DLC を実践した事例についてご紹介いただきました。負荷試験ツールである Locust の設定や API、DB 初期化スクリプト等を AI-DLC を応用して作成した際の留意事項や実際の手順、工夫や今後の展望についてご説明いただきました。<br> 一次情報は社員が普段から利用しているツールから MCP Server 経由で取得していることや、AI-DLC のアウトプットを新規担当者のキャッチアップ資料などに活用していること、AI-DLC を軽量にカスタマイズして取り入れていることをご紹介いただきました。AI エージェントとの対話内容の例や実際のアウトプットについてもご共有いただきました。これからの展望として、アウトプットであるドキュメントの更新・メンテナンスの仕組みについても検討されていることをご紹介いただきました。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-1.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167079\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-1-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-2.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167080\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-2-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-3.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167081\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-3-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-4.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167082\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ly-4-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a></p> \n<h2>株式会社サイバーエージェント様 「CA 流、現場と伴走する AI 駆動開発 (AI-DLC)」</h2> \n<p>株式会社サイバーエージェント様からは「CA 流、現場と伴走する AI 駆動開発」と題して、AI 駆動開発の全社展開を目指す背景とその実践についてお話しいただきました。AI 駆動開発の浸透・普及により AI 活用を強化し、競争力のあるプロダクトを作ることの重要性や、AI を前提とした開発文化の定着には全社への浸透、行動様式や意思決定プロセスの変革も必要である、と言う方針についてご紹介いただきました。既存プロジェクトへの AI-DLC の適用においてはドメイン知識に関するコンテキストの不足や、伝達の難しさについてお話しいただいたのち、Code を Single source of truth とすることや、ドメインごとに独立したコンテキストを与えるという AI へのドメイン知識の伝達方法をご説明いただきました。最後に、AI 活用の普及には継続的に開発チームとコミュニケーションし、二人三脚で進めていくことが重要であるとも述べていただきました。</p> \n<p>AI-DLC Unicorn Gym 実施内容の詳細はブログ「<a href=\"https://note.com/ca_ai_ope/n/n23e13ccf2c8d\">既存開発フローに AI-DLCを適用する</a> 」と「<a href=\"https://note.com/ca_ai_ope/n/n14ba20754a53\">AWS 発「AI-DLC」ワークショップレポート！現場に適用するには？ </a>」も併せてご覧ください。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-1.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167083\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-1-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-2.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167084\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-2-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-3.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167085\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-3-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-4.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-167086\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/ca-4-1024x575.png\" alt=\"\" width=\"1024\" height=\"575\"></a></p> \n<h2>東京海上日動システムズ株式会社様 「AI-DLC 体験記」</h2> \n<p>東京海上日動システムズ株式会社様からは「AI-DLC 体験記」というタイトルで、AI-DLC ワークショップにご参加いただいた背景や準備、当日の様子や今後の展望についてご紹介いただきました。要件定義から実装フェーズの効率化の検証のため、既存システム改修と新規システム構築を対象とし、さまざまな部門・役割のメンバーが参加されたという背景をお話しいただきました。ワークショップ当日の成果物の例や完成したアプリケーションもご紹介いただきました。最後に各参加者からのフィードバックや、今後の AI-DLC を広く導入するための取り組みについてご説明いただきました。</p> \n<p>AI-DLC Unicorn Gym 実施内容の詳細はブログ「<a href=\"https://aws.amazon.com/jp/blogs/news/tokio-marine-ai-dlc/\">東京海上日動システムズ株式会社様の AWS 生成 AI 事例：金融業界初 AI-DLC Unicorn Gym による開発変革への挑戦</a>」も併せてご覧ください。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.30.14.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-166133\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.30.14-1024x577.png\" alt=\"\" width=\"1024\" height=\"577\"></a><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.30.38.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-166132\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.30.38-1024x578.png\" alt=\"\" width=\"1024\" height=\"578\"></a><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.31.06.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-166131\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.31.06-1024x578.png\" alt=\"\" width=\"1024\" height=\"578\"></a><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.31.20.png\"><img loading=\"lazy\" class=\"alignnone size-large wp-image-166130\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/01/Screenshot-2025-10-01-at-17.31.20-1024x578.png\" alt=\"\" width=\"1024\" height=\"578\"></a></p> \n<h2>おわりに</h2> \n<p>今回の Amazon Q Developer Meetup #3 では、AI 駆動開発ライフサイクル (AI-DLC) をテーマとしてその概要と実際に体験されたお客様からの事例をご紹介いただきました。LINE ヤフー株式会社様、株式会社サイバーエージェント様、東京海上日動システムズ株式会社様にご登壇いただき、実施の背景や体験していただいた内容、学びや今後の展望についてお話しいただきました。今後も、開発者の皆様が生成 AI をより有効に活用していただくための AI-DLC をはじめとしたプラクティスや Amazon Q Developer や Kiro といったツールについて発信・アップデートをお届けします。</p> \n<h2>次回予告: Amazon Q Developer &amp; Kiro Meetup #4 AWS サポートが語るよくある問い合わせ紹介とKiroのユースケース紹介</h2> \n<p>次回から Amazon Q Developer &amp; Kiro Meetup にシリーズ名をアップデートします！</p> \n<p>Amazon Q Developer &amp; Kiro Meetup #4 では AWS サポートエンジニアから Amazon Q Developer に関するよくあるお問い合わせとその回答を、株式会社アド・ダイセン様から Kiro のユースケースをご紹介いただきます。皆様のご登録をお待ちしています。</p> \n<ul> \n <li>参加登録: <a href=\"https://aws-experience.com/apj/smb/event/fd28de00-3189-49c4-909f-eb4c57a1ec3c\">Amazon Q Developer Meetup &amp; Kiro #4 AWS サポートが語るよくある問い合わせ紹介とKiroのユースケース紹介</a></li> \n <li>開催日時: 2025年10月31日 (金) 19:00-21:00</li> \n <li>会場: AWS Startup Loft Tokyo (目黒)、オンライン配信</li> \n <li>お客様登壇 \n  <ul> \n   <li>株式会社アド・ダイセン ソリューション部 部長 吉田 和弘 様「非エンジニアが生成AIでチームのイノベーション文化を創った実践事例」</li> \n  </ul> </li> \n</ul> \n<div></div> \n<footer> \n <div class=\"blog-author-box\"> \n  <div class=\"blog-author-image\"> \n   <div id=\"attachment_164799\" style=\"width: 310px\" class=\"wp-caption alignnone\">\n    <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/09/08/profile-20250806.jpg\"><img aria-describedby=\"caption-attachment-164799\" loading=\"lazy\" class=\"size-medium wp-image-164799\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/09/08/profile-20250806-300x296.jpg\" alt=\"\" width=\"300\" height=\"296\"></a>\n    <p id=\"caption-attachment-164799\" class=\"wp-caption-text\">yamazaki hiroki profile-20250806</p>\n   </div> \n  </div> \n  <h4 class=\"lb-h4\"><a href=\"https://x.com/yh1roki\" target=\"_blank\" rel=\"noopener\">山崎 宏紀 (Hiroki Yamazaki)</a></h4> \n  <p>山崎宏紀 は Amazon Web Services Japan G.K. のソリューションアーキテクトとして、ISV/SaaS 業界のお客様を中心にアーキテクチャ設計や構築、生成 AI の活用をご支援しています。Amazon Q Developer や AWS CDK を好みます。(より良いご支援のために) AI エージェントに代わりに働いてもらおうと画策しています。</p> \n </div> \n</footer>"
  },
  {
    "title": "2025/10/20時点で最良のAIコーディングプロセス",
    "date": "2025-10-20T02:09:26.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/erukiti/articles/2510-ai-coding",
    "content": "2025年10月20日の僕が考えるAIコーディング（バイブコーディング）プロセスです。\n個人的な結論としては、1ミリでも気に食わないコードを生成してきたら、そのタスクは最終的には破棄すべきというものです。「このコード気に食わない」「この設計気に食わない」の直感がAIコーディングで品質を維持する生命線です。\n\n\nバイブコーディング時代ではコードレビューのお局ビリティが鍵です。\nレビューに全時間を割こう。レビューに時間がかかりすぎるというより、レビューに時間をもっとかけるくらい\n1ミリでも知らないことをなくそう\n\n断片的なAIコーディングでいえば1年弱、本格的なコーディングエージェントを使い..."
  },
  {
    "title": "なぜResult型ライブラリを再発明したのか",
    "date": "2025-10-20T02:00:19.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/praha/articles/9d24390b869499",
    "content": "\n はじめに\nTypeScriptでエラーハンドリングを型安全に行いたいと考えたとき、皆さんはどのようなアプローチを取るでしょうか。\nJavaScript/TypeScriptの標準的なエラーハンドリング手法であるtry/catchは、型安全性に欠け、エラーが発生する可能性のあるコードを追跡するのが難しいという問題があります。\nそんな課題を解決するために、よく用いられるのがResult型を用いたエラーハンドリングです。\nResult型とは、成功時の値と失敗時のエラーを明示的に表現する型です。\nTypeScriptにおけるResult型ライブラリといえば、neverthrowが最も有名で広..."
  },
  {
    "title": "週刊AWS – 2025/10/13週",
    "date": "2025-10-20T01:56:19.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/aws-weekly-20251013/",
    "content": "<p>みなさん、こんにちは。ソリューションアーキテクトの戸塚です。今週も <a href=\"https://aws.amazon.com/jp/blogs/news/tag/%E9%80%B1%E5%88%8Aaws/\" target=\"_blank\" rel=\"noopener\">週刊AWS</a> をお届けします。</p> \n<p>AWS Bedrock AgentCore の一般提供開始を受け、私たちリテールチームは、店舗への導入ですぐに価値を発揮できるソリューションとして、マルチ AI エージェントによる販売支援を提案しています。実際に実機のデジタルサイネージを用いたデモをイベントなどで展示し、その内容をブログにまとめました。ぜひこちらもご覧ください。<br> <a href=\"https://aws.amazon.com/jp/blogs/news/multi-aiagents-sales-support-with-bedrock-agentcore/\">マルチ AI エージェントが創る新しい店舗体験 〜Amazon Bedrock AgentCoreによる販売支援〜</a></p> \n<p>こちらのデモは、10/28(火)-30(木)で開催される <a href=\"https://www.gartner.com/jp/conferences/apac/symposium-japan?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=EVT_JP_2025_JXP25_CPC_SEM1_BRAND&amp;utm_adgroup=181036754158&amp;utm_term=gartner%20it%20symposium&amp;ad=761661092565&amp;matchtype=e&amp;gad_source=1&amp;gad_campaignid=22604767100&amp;gbraid=0AAAAADFC_-Ui4vrFt6CCE9EqdOPnS9roe&amp;gclid=CjwKCAjwmNLHBhA4EiwA3ts3mei2Q0B2kNNPDRLdl5tlSwkTl01DDlT3Nx7wiTQwtsvga7aY-4Up5RoCZagQAvD_BwE\">Gartner IT Symposium</a> での展示予定となっております。</p> \n<p>それでは、先週の主なアップデートについて振り返っていきましょう。</p> \n<p><span id=\"more-167149\"></span></p> \n<h4>2025年10月13日週の主要なアップデート</h4> \n<ul> \n <li>10/13(月) \n  <ul> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/generative-ai-observability-amazon-cloudwatch/\" target=\"_blank\" rel=\"noopener\">Amazon CloudWatch で生成 AI オブザーバビリティが一般提供開始</a><br> Amazon CloudWatch で生成 AI オブザーバビリティ機能が一般提供開始となりました。AI アプリケーション全体の監視が可能になり、レイテンシーやトークン使用量、エラーをリアルタイムで把握できます。LangChain や LangGraph などのフレームワークにも対応し、問題の迅速な特定が可能です。追加料金なしで利用できます。詳細は<a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/GenAI-observability.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-bedrock-agentcore-available/\" target=\"_blank\" rel=\"noopener\">Amazon Bedrock AgentCore が一般提供開始</a><br> Amazon Bedrock AgentCore が一般提供開始されました。このサービスは AI エージェントを簡単に構築・運用できるプラットフォームです。従来は複雑だったエージェント開発が、インフラ管理不要で実現できるようになりました。最大 8 時間の長時間実行や VPC サポートによる安全なプライベート環境での運用が可能です。CrewAI や LangGraph などの人気フレームワークに対応し、CloudWatch で運用状況を監視できます。東京リージョンを含む 9 リージョンで利用でき、従量課金制で初期費用は不要です。詳細は<a href=\"https://aws.amazon.com/jp/blogs/news/amazon-bedrock-agentcore-is-now-generally-available/\" target=\"_blank\" rel=\"noopener\">こちらの Blog 記事をご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-sagemaker-ai-projects-custom-template-s3-provisioning\" target=\"_blank\" rel=\"noopener\">Amazon SageMaker AI Projects がカスタムテンプレートの S3 プロビジョニングをサポート</a><br> Amazon SageMaker AI Projects で、Amazon S3 からカスタム ML プロジェクトテンプレートをプロビジョニングできるようになりました。これまで管理者は標準的な ML プロジェクトテンプレートの管理が困難でしたが、今回のアップデートにより S3 上でテンプレートを管理し、データサイエンティストが SageMaker AI Studio から直接アクセスできます。組織の要件に合った標準化された ML 開発ワークフローを簡単に構築でき、全社的な ML プロジェクトの品質向上とガバナンス強化が実現します。詳細は<a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-templates-custom.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n  </ul> </li> \n <li>10/14(火) \n  <ul> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-msk-connect-ten-additional-regions/\" target=\"_blank\" rel=\"noopener\">Amazon MSK Connect が 10 の追加 AWS リージョンで利用可能に</a><br> Amazon MSK Connect が 10 の新しいリージョン (ジャカルタ、香港、大阪、メルボルンなど) で利用可能になりました。MSK Connect は Apache Kafka のデータ連携を完全マネージドで実現するサービスです。データベースやファイルシステムなどの外部システムと Kafka 間でデータを移動するコネクターを、インフラ管理不要で簡単にデプロイできます。従来は自分でサーバーを管理する必要がありましたが、これで使った分だけの課金で自動スケールが可能になります。詳細は<a href=\"https://docs.aws.amazon.com/msk/latest/developerguide/msk-connect.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-route-53-profiles-supports-aws-privatelink\" target=\"_blank\" rel=\"noopener\">Amazon Route 53 Profiles が AWS PrivateLink をサポート開始</a><br> Amazon Route 53 Profiles が AWS PrivateLink をサポート開始しました。従来はパブリックインターネット経由でのアクセスが必要でしたが、今回のアップデートでプライベートネットワーク経由での安全なアクセスが可能になりました。Route 53 Profiles は複数の VPC に統一された DNS 設定を適用できるサービスで、今回セキュリティが大幅に向上しました。詳細は<a href=\"https://docs.aws.amazon.com/Route53/latest/APIReference/API_Operations_Route_53_Profiles.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-appstream-license-included-apps\" target=\"_blank\" rel=\"noopener\">Amazon AppStream 2.0 がライセンス込み Microsoft アプリケーションの提供を発表</a><br> Amazon AppStream 2.0 で Microsoft Office や Visio、Project 2021/2024 がライセンス込みで利用できるようになりました。これまでは別途ライセンスの準備が必要でしたが、今回のアップデートにより AWS が提供するライセンス込みバージョンを直接利用可能です。リモートワークや在宅勤務で Microsoft アプリケーションを安全にクラウド経由で提供したい企業にとって、ライセンス管理の手間が大幅に削減されます。詳細は<a href=\"https://docs.aws.amazon.com/appstream2/latest/developerguide/tutorial-image-builder.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n  </ul> </li> \n <li>10/15(水) \n  <ul> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-aurora-postgresql-zero-etl-integration-sagemaker\" target=\"_blank\" rel=\"noopener\">Amazon Aurora PostgreSQL と Amazon SageMaker のゼロ ETL 統合が利用可能に</a><br> Amazon Aurora PostgreSQL が SageMaker Lakehouseとの zero-ETL 統合をサポート開始しました。これまで複雑な ETL プロセスが必要だったデータ分析が、リアルタイムに近い形で可能になります。PostgreSQL のデータを自動的にデータレイクハウスに同期し、Apache Iceberg 互換形式で SQL や Spark、機械学習ツールから直接利用できます。ノーコードで設定でき、本番環境への影響もありません。詳細は<a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/zero-etl.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-bedrock-automatic-enablement-serverless-foundation-models\" target=\"_blank\" rel=\"noopener\">Amazon Bedrock がサーバーレス基盤モデルの自動有効化によりアクセスを簡素化</a><br> Amazon Bedrock で、サーバーレス基盤モデルへのアクセスが自動で有効化されるようになりました。従来は手動でモデルアクセスを有効化する必要がありましたが、今回のアップデートで全商用リージョンにおいて即座に AI モデルを利用開始できます。Amazon Bedrock コンソールや AWS SDK から直ちにアクセス可能で、開発効率が大幅に向上します。ただし Anthropic モデルのみ初回利用時に一度だけ使用フォームの提出が必要です。詳細は<a href=\"https://aws.amazon.com/blogs/security/simplified-amazon-bedrock-model-access/\" target=\"_blank\" rel=\"noopener\">こちらの Blog 記事をご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock\" target=\"_blank\" rel=\"noopener\">Anthropic の Claude 4.5 Haiku が Amazon Bedrock で利用可能に</a><br> Amazon Bedrock で Claude Haiku 4.5 が利用可能になりました。Claude Sonnet 4 並みの高性能でありながら、大幅にコストを抑えて高速処理を実現しています。リアルタイムのカスタマーサポートやチャットボットなど、レスポンス速度が重要なアプリケーションに最適です。従来は性能とコストのどちらかを諦める必要がありましたが、両方を兼ね備えた AI モデルが使えるようになりました。</li> \n  </ul> </li> \n <li>10/16(木) \n  <ul> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/aws-security-hub-cspm-cis-foundations-benchmark-v5/\" target=\"_blank\" rel=\"noopener\">AWS Security Hub CSPM が CIS AWS Foundations Benchmark v5.0 をサポート開始</a><br> AWS Security Hub CSPM で CIS AWS Foundations Benchmark v5.0 がサポート開始されました。この業界標準のベンチマークには 40 のコントロールが含まれ、AWS リソースのセキュリティ設定を自動チェックできます。従来版から最新のセキュリティ要件に対応し、組織全体のアカウントで一括有効化も可能です。セキュリティ設定の見落としを防ぎ、コンプライアンス対応が効率化されます。詳細は<a href=\"https://docs.aws.amazon.com/securityhub/latest/userguide/cis-aws-foundations-benchmark.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-ec2-cpu-options-optimization-license-included-instances\" target=\"_blank\" rel=\"noopener\">Amazon EC2 がライセンス込みインスタンスの CPU オプション最適化をサポート</a><br> Amazon EC2 でライセンス込み Windows インスタンスの CPU オプション最適化が可能になりました。これまで固定だった vCPU 数やハイパースレッディングを調整できるようになり、Microsoft SQL Server などの vCPU ベースライセンス費用を大幅削減できます。例えば r7i.8xlarge インスタンスでハイパースレッディングを無効にすることで、32 vCPU を 16 vCPU に削減し、ライセンス費用を 50% 節約しながら、メモリ 256 GiB と IOPS 40,000 の性能は維持可能です。詳細は<a href=\"https://aws.amazon.com/blogs/modernizing-with-aws/optimize-cpus-best-practices-for-sql-server-workloads-continued/\" target=\"_blank\" rel=\"noopener\">こちらの Blog 記事をご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/aws-location-services-new-map-styling-enchanced-customization\" target=\"_blank\" rel=\"noopener\">Amazon Location Service が強化されたカスタマイゼーションのための新しいマップスタイリング機能を導入</a><br> Amazon Location Service で新しい地図スタイリング機能が利用可能になりました。地形の可視化、等高線表示、リアルタイム交通情報、交通手段別ルーティングなどが追加され、用途に応じたカスタマイズが可能です。物流アプリではトラック専用ルートの制限情報を表示したり、アウトドアアプリでは標高や地形の詳細を可視化できます。従来の基本的な地図表示から、より実用的で詳細な地図アプリケーションの開発が実現できるようになりました。詳細は<a href=\"https://docs.aws.amazon.com/location/latest/developerguide/what-is.html\" target=\"_blank\" rel=\"noopener\">こちらの Developer Guide をご参照ください。</a></li> \n  </ul> </li> \n <li>10/17(金) \n  <ul> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/aws-systems-manager-patch-manager-windows/\" target=\"_blank\" rel=\"noopener\">AWS Systems Manager Patch Manager が Windows 向けセキュリティ更新通知を開始</a><br> AWS Systems Manager Patch Manager で Windows 向けセキュリティ更新通知機能がリリースされました。この機能により、パッチベースラインで承認されていないセキュリティ更新を AvailableSecurityUpdate 状態として識別できます。これまで ApprovalDelay などを使用する際に、意図せずインスタンスがパッチ未適用のままになるリスクがありましたが、デフォルトで Non-Compliant として明確に表示されるため、セキュリティパッチの見落としを防げます。詳細は<a href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/patch-manager-compliance-states.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/amazon-ec2-capacity-manager\" target=\"_blank\" rel=\"noopener\">Amazon EC2 Capacity Manager の発表</a><br> Amazon EC2 Capacity Manager が一般提供開始されました。これまで複数のアカウントやリージョンにまたがる EC2 容量の管理は煩雑でしたが、単一のインターフェースで一元管理できるようになりました。On-Demand、Spot、Capacity Reservation の使用状況をダッシュボードで可視化し、履歴トレンドや最適化の機会も確認できます。全商用リージョンで追加コストなしで利用可能です。詳細は<a href=\"https://aws.amazon.com/jp/blogs/news/monitor-analyze-and-manage-capacity-usage-from-a-single-interface-with-amazon-ec2-capacity-manager/\" target=\"_blank\" rel=\"noopener\">こちらの Blog 記事をご参照ください。</a></li> \n   <li><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/10/database-insights-tag-based-access-control\" target=\"_blank\" rel=\"noopener\">CloudWatch Database Insights でタグベースアクセス制御をサポート開始</a><br> Amazon CloudWatch Database Insights で、タグベースアクセス制御がサポート開始されました。これまで RDS や Aurora インスタンスに設定したタグが Performance Insights のメトリクスに適用されず、データベースリソースごとに個別で権限設定する必要がありましたが、今回のアップデートでインスタンスのタグが自動評価されるようになりました。IAM ポリシーでタグベースアクセス条件を定義でき、複数のデータベースを論理的にグループ化した権限管理が可能です。詳細は<a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.access-control.html\" target=\"_blank\" rel=\"noopener\">こちらのドキュメントをご参照ください。</a></li> \n  </ul> </li> \n</ul> \n<p>もうすぐ 今年もラスベガスにて、<a href=\"https://reinvent.awsevents.com/\" target=\"_blank\" rel=\"noopener\">AWS re:Invent</a> が開催されます。私は、BuildersFair のコーナーにて、LLM を活用したロボットのデモ展示対応をしております。ぜひ遊びにきてください。<br> それでは、また来週お会いしましょう！</p> \n<h1>著者について</h1> \n<footer> \n <div class=\"blog-author-box\"> \n  <div class=\"blog-author-image\">\n   <img src=\"https://d1.awsstatic.com/Developer%20Marketing/jp/magazine/profile/photo_totsuka-tomoya.7a8175c15da4a36f9232592a389c5f5c18663193.jpg\" alt=\"Tomoya Tozuka\" width=\"150\">\n  </div> \n  <h3 class=\"lb-h4\"><a href=\"https://x.com/tottu22\" target=\"_blank\" rel=\"noopener\">戸塚 智哉(Tomoya Tozuka) / @tottu22</a></h3> \n  <p>飲料やフィットネス、ホテル業界全般のお客様をご支援しているソリューション アーキテクトで、AI/ML、IoT を得意としています。最近では AWS を活用したサステナビリティについてお客様に訴求することが多いです。<br> 趣味は、パデルというスペイン発祥のスポーツで、休日は仲間とよく大会に出ています。</p> \n </div> \n</footer>"
  },
  {
    "title": "2025年版 スタートアップエンジニアが考えるWebアプリの技術選定",
    "date": "2025-10-20T01:30:00.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/m_noto/articles/5e4c9f705f500b",
    "content": "はじめまして、_minoです！\nこの記事では、最近公開されたムーザルちゃんねるさんの動画「2025年版「Webアプリ作るなら技術どれにする？」」を見て、私も今年を振り返り採用してよかった技術や、トレンドから見た来年以降流行りそうな技術についてまとめました。\n「その技術いいよね！」「この技術よかった!」などのご意見がありましたら、コメントで教えていただけると嬉しいです!\n!\n筆者がフロントエンドメインということもあり、フロントエンド目線での技術構成になっています。\n\n\n 🧩 言語・フレームワーク\n\n TypeScript\nJavaScriptに静的型付けを追加し、開発時の型安全性とツールサ..."
  },
  {
    "title": "Amazon MWAA における Apache Airflow 2.x から Apache Airflow 3.x への移行のベストプラクティス",
    "date": "2025-10-20T00:50:12.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/best-practices-for-migrating-from-apache-airflow-2-x-to-apache-airflow-3-x-on-amazon-mwaa/",
    "content": "<p>本記事は、2025 年 10 月 7 日に公開された <a href=\"https://aws.amazon.com/jp/blogs/big-data/best-practices-for-migrating-from-apache-airflow-2-x-to-apache-airflow-3-x-on-amazon-mwaa/\" target=\"_blank\" rel=\"noopener\">Best practices for migrating from Apache Airflow 2.x to Apache Airflow 3.x on Amazon MWAA</a> を翻訳したものです。翻訳はクラウドサポートエンジニアの山本が担当しました。</p> \n<p>Amazon MWAA の Apache Airflow 3.x では、セキュリティと分離性を強化する API ベースのタスク実行など、アーキテクチャの改善が導入されています。その他の主要なアップデートには、ユーザーエクスペリエンスを向上させた UI の再設計、パフォーマンスを改善したスケジューラーベースのバックフィル、<a href=\"https://www.python.org/downloads/release/python-3120/\" target=\"_blank\" rel=\"noopener\">Python 3.12</a> のサポートが含まれています。Amazon MWAA における Airflow のマイナーバージョンのインプレースアップグレードとは異なり、Airflow 2 から Airflow 3 へのアップグレードには根本的な破壊的変更があるため、慎重な計画と移行アプローチによる実行が必要です。</p> \n<p>この移行は、ビジネス継続性を確保しながら、次世代のワークフローオーケストレーション機能を導入する機会となります。しかし、これは単なるアップグレードではありません。Amazon MWAA で Airflow 3.x に移行する組織は、ワーカーからのメタデータデータベースへの直接アクセスの削除、SubDAG の廃止、デフォルトのスケジューリング動作の変更、ライブラリ依存関係の更新など、破壊的変更を理解する必要があります。この記事では、ミッションクリティカルなデータパイプラインへの影響を最小限に抑えながら、Airflow 3 の強化された機能を最大限に活用するための、ベストプラクティスとして合理的なアプローチを提供します。</p> \n<h2>移行プロセスの理解</h2> \n<p>Amazon MWAA における Airflow 2.x から 3.x への移行には、組織が移行を開始する前に理解しておくべき、いくつかの基本的な変更が含まれています。これらの変更は主要なワークフローの操作に影響を与えるため、スムーズな移行を実現するには慎重な計画が必要です。</p> \n<p>以下の破壊的な変更に注意してください：</p> \n<ul> \n <li><strong>直接的なデータベースアクセスの削除</strong> – Airflow 3 における破壊的変更は、ワーカーノードからのメタデータデータベースへの直接アクセスができなくなったことです。タスクとカスタムオペレーターは、直接的なデータベースアクセスではなく REST API を介して通信する必要があります。この設計変更は、以前 SQLAlchemy 接続を通じてメタデータデータベースに直接アクセスしていたコードに影響を与え、既存の DAG とカスタムオペレーターのリファクタリングが必要になります。</li> \n <li><strong>SubDAG の廃止</strong> – Airflow 3 では、TaskGroups、Assets、Data Aware Scheduling を優先し、SubDAG 構造を削除します。組織は既存の SubDAG を前述のいずれかの構造にリファクタリングする必要があります。</li> \n <li><strong>スケジューリング動作の変更</strong> – デフォルトのスケジューリングオプションに関する 2 つの注目すべき変更により、影響分析が必要です： \n  <ul> \n   <li>catchup_by_default と create_cron_data_intervals のデフォルト値が False に変更されました。この変更は、これらのオプションを明示的に設定していない DAG に影響を与えます。</li> \n   <li>Airflow 3 では、execution_date、tomorrow_ds、yesterday_ds、prev_ds、next_ds などのいくつかのコンテキスト変数が削除されます。これらの変数を、現在サポートされているコンテキスト変数に置き換える必要があります。</li> \n  </ul> </li> \n <li><strong>ライブラリと依存関係の変更</strong> – Airflow 3.x では多数のライブラリが変更され、DAG コードのリファクタリングが必要になります。以前に含まれていた多くのプロバイダーパッケージは、<code>requirements.txt</code> ファイルに明示的に追加する必要が場合があります。</li> \n <li><strong>REST API の変更</strong> – REST API のパスが /api/v1 から /api/v2 に変更され、外部統合に影響を与えます。Airflow REST API の使用に関する詳細については、<a href=\"https://docs.aws.amazon.com/ja_jp/mwaa/latest/userguide/access-mwaa-apache-airflow-rest-api.html#create-web-server-session-token\" target=\"_blank\" rel=\"noopener\">ウェブサーバーセッショントークンを作成し、Apache Airflow REST API を呼び出す</a>をご参照ください。</li> \n <li><strong>認証システム</strong> – Airflow 3.0.1 以降のバージョンでは Flask-AppBuilder の代わりに SimpleAuthManager がデフォルトになりますが、Amazon MWAA は Airflow 3.x でも引き続き Flask-AppBuilder を使用します。これは、Amazon MWAA のお客様には認証の変更が発生しないことを意味します。</li> \n</ul> \n<p>この移行では、インプレースアップグレードではなく、新しい環境を作成する必要があります。このアプローチはより多くの計画とリソースを必要としますが、移行プロセス中にフォールバックオプションとして既存の環境を維持できるという利点があり、ビジネスの継続性を確保できます。</p> \n<h2>移行前の計画と評価</h2> \n<p>移行を成功させるには、現在の環境を徹底的に計画し評価することが重要です。この段階では、依存関係、構成、潜在的な互換性の問題を特定することで、スムーズな移行の基盤を確立します。前述の互換性に影響する変更点に照らして環境とコードを評価し、移行を成功に導きましょう。</p> \n<h3>環境評価</h3> \n<p>まず、現在の Amazon MWAA 環境の完全なインベントリを作成します。すべての DAG、カスタムオペレーター、プラグイン、依存関係について、それぞれの特定のバージョンと構成を含め文書化します。Airflow 3.x を搭載した Amazon MWAA へのアップグレードに最適な互換性パスを提供するため、現在の環境がバージョン 2.10.x であることを確認してください。</p> \n<p>DAG コード、requirements ファイル、起動スクリプト、プラグインが含まれている <a href=\"https://aws.amazon.com/jp/s3/\" target=\"_blank\" rel=\"noopener\">Amazon Simple Storage Service</a> (Amazon S3) バケットの構造を確認します。この構造を新しい環境用の新しいバケットに複製します。環境ごとに個別のバケットを作成することで、競合を回避し、現在のパイプラインに影響を与えることなく開発を継続できます。</p> \n<h3>設定ドキュメント</h3> \n<p>すべてのカスタム Amazon MWAA 環境変数、Airflow 接続、環境設定を文書化してください。新しい環境の実行ロールには同一のポリシーが必要となるため、<a href=\"https://aws.amazon.com/jp/iam/\" target=\"_blank\" rel=\"noopener\">AWS Identity and Access Management (IAM)</a> の<a href=\"https://docs.aws.amazon.com/ja_jp/mwaa/latest/userguide/access-policies.html\" target=\"_blank\" rel=\"noopener\">リソース</a>を確認してください。Airflow UI にアクセスする IAM ユーザーまたはロールには、新しい環境に対する CreateWebLoginToken 権限が必要です。</p> \n<h3>パイプラインの依存関係</h3> \n<p>パイプラインの依存関係を理解することは、段階的な移行を成功させるために重要です。Datasets (現在は <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/assets.html\" target=\"_blank\" rel=\"noopener\">Assets</a>)、SubDAG、TriggerDagRun オペレーター、または外部 API との連携を通じて相互依存関係を特定してください。これらの依存関係に基づいて移行計画を立て、関連する DAG を同時に移行できるようにします。</p> \n<p>移行ウェーブを計画する際は、DAG のスケジューリング頻度を考慮してください。実行間隔が長い DAG は、頻繁に実行される DAG と比較して、より長い移行期間を確保でき、重複実行のリスクも低くなります。</p> \n<h3>テスト戦略</h3> \n<p>互換性の問題を特定するための体系的なアプローチを定義して、テスト戦略を作成します。<a href=\"https://github.com/astral-sh/ruff\" target=\"_blank\" rel=\"noopener\">ruff linter</a> を AIR30 ルールセットと共に使用して、更新が必要なコードを自動的に特定します。</p> \n<pre><code class=\"lang-code\">ruff check --preview --select AIR30 &lt;path_to_your_dag_code&gt;</code></pre> \n<p>次に、環境の <code>requirements.txt</code> ファイルを確認し、パッケージのバージョンが更新された制約ファイルに準拠するように更新してください。また、以前は airflow-core パッケージに含まれていた一般的に使用されるオペレーターは、現在は別のパッケージに移動されているため、requirements ファイルに追加する必要があります。</p> \n<p>Airflow 3.x 用の <a href=\"https://github.com/aws/amazon-mwaa-docker-images\" target=\"_blank\" rel=\"noopener\">Amazon MWAA Docker イメージ</a>を使用して DAG をテストします。これらのイメージを使用することで、requirements ファイルの作成とテスト、そしてスケジューラーが DAG を正常にパースすることを確認できます。</p> \n<h2>移行戦略とベストプラクティス</h2> \n<p>体系的な移行アプローチにより、明確な検証チェックポイントを提供しながら、リスクを最小限に抑えることができます。推奨される戦略は、信頼性の高い移行と即時のロールバック機能を提供する段階的ブルー/グリーンデプロイメントモデルを採用しています。</p> \n<h3>段階的な移行のアプローチ</h3> \n<p>以下の移行フェーズは、移行計画の定義に役立ちます。</p> \n<ul> \n <li><strong>フェーズ 1: 発見、評価、計画</strong> – このフェーズでは、環境のインベントリ、依存関係のマッピング、変更による影響の分析を完了します。収集した情報を基に、詳細な移行計画を策定します。この計画には、コードの更新、requirements ファイルの更新、テスト環境の作成、テスト、ブルー/グリーン環境の作成 (この記事の後半で説明)、および移行手順が含まれます。また、計画には、トレーニング、モニタリング戦略、ロールバック条件、ロールバック計画も含める必要があります。</li> \n <li><strong>フェーズ 2: パイロット移行</strong> – パイロット移行フェーズでは、影響範囲が限定された管理環境で詳細な移行計画の検証を行います。異なるスケジュールや依存関係など、多様な特性を持つ 2 ～ 3 個の重要度の低い DAG にフォーカスします。前のフェーズで定義した移行計画を使用して、選択した DAG を移行します。このフェーズを活用して計画とモニタリングツールを検証し、実際の結果に基づいて両者を調整します。パイロット中に、完全な移行のパフォーマンスを予測するのに役立つ基準となる移行メトリクスを確立します。</li> \n <li><strong>フェーズ 3: 段階的な本番移行</strong> – パイロットが成功したら、残りの DAG の段階的な完全移行を開始する準備が整います。残りの DAG を、ビジネスの重要度 (重要度の低いものから開始)、技術的な複雑さ、相互依存関係 (依存関係のある DAG をまとめて移行)、スケジュールの頻度 (実行頻度の低い DAG は移行に時間を確保できる) に基づいて論理的なウェーブにグループ化します。ウェーブを定義したら、ステークホルダーと協力してウェーブスケジュールを作成します。次のウェーブを開始する前に、ウェーブが成功したことを確認するための十分な検証期間を設けます。この時間は、移行の問題が発生した場合の影響範囲を抑え、ロールバックを実行するための十分な時間も確保します。</li> \n <li><strong>フェーズ 4: 移行後のレビューと廃止</strong> – すべてのウェーブが完了したら、得られた知見、最適化の機会、その他の未解決の項目を特定するために移行後のレビューを実施します。これはシステムの安定性を承認するのにも適した時期です。最後のステップは、元の Airflow 2.x 環境の廃止です。ビジネス要件と意見に基づいて安定性が確認されたら、元の (ブルー) 環境を廃止します。</li> \n</ul> \n<p><img loading=\"lazy\" class=\"alignnone wp-image-83993 size-full\" src=\"https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2025/09/30/MWAA-5280-Blue-Green-Migration-Timeline-.png\" alt=\"\" width=\"1400\" height=\"800\"></p> \n<h3>ブルー/グリーンデプロイメント戦略</h3> \n<p>安全で元に戻せる移行のために、ブルー/グリーンデプロイメント戦略を実装します。この戦略では、移行中に 2 つの Amazon MWAA 環境が稼働し、どの DAG をどの環境で実行するかを管理します。</p> \n<p>ブルー環境 (現行の Airflow 2.x) は、移行中に本番ワークロードを維持します。移行前に DAG の変更に対する停止期間を設定することで、直前のコードの競合を回避できます。この環境は、新しい (グリーン) 環境で問題が特定された場合の即時ロールバック環境として機能します。</p> \n<p>グリーン環境 (新しい Airflow 3.x) は、制御された段階で移行された DAG を受け取ります。ブルー環境からネットワーク、IAM ロール、セキュリティ設定をミラーリングします。この環境はブルー環境と同じオプションで構成し、同一の監視メカニズムを作成して、両環境を同時に監視できるようにします。DAG の重複実行を避けるため、DAG が単一の環境でのみ実行されるようにしてください。これには、グリーン環境で DAG をアクティブ化する前に、ブルー環境で DAG を一時停止することが含まれます。移行全体を通じて、ブルー環境をウォームスタンバイモードで維持します。各移行段階での具体的なロールバック手順を文書化し、少なくとも 1 つの重要度の低い DAG でロールバック手順をテストしてください。さらに、ロールバックのトリガー基準（特定の失敗率や SLA 違反など）を明確に定義してください。</p> \n<h2>段階的な移行プロセス</h2> \n<p>このセクションでは、移行を実施するための詳細な手順を説明します。</p> \n<h3>移行前の評価と準備</h3> \n<p>移行プロセスを開始する前に、現在の環境を徹底的に評価し、移行計画を策定してください。</p> \n<ul> \n <li>現在の Amazon MWAA 環境がバージョン 2.10.x であることを確認してください</li> \n <li>DAG、カスタムオペレーター、プラグインについて、それらの依存関係とバージョンを含む詳細なインベントリを作成してください</li> \n <li>現在の <code>requirements.txt</code> ファイルを確認し、パッケージの要件を理解してください</li> \n <li>すべての環境変数、接続、設定を文書化してください</li> \n <li><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/installation/upgrading_to_airflow3.html#breaking-changes\" target=\"_blank\" rel=\"noopener\">Apache Airflow 3.x リリース</a>ノートを確認し、破壊的変更を理解してください</li> \n <li>移行の成功基準、ロールバック条件、ロールバック計画を決定してください</li> \n <li>パイロット移行に適した少数の DAG を特定してください</li> \n <li>Amazon MWAA ユーザーに対する Airflow 3 のトレーニングまたは習熟計画を策定してください</li> \n</ul> \n<h3>互換性のチェック</h3> \n<p>互換性の問題を特定することは、移行を成功させる上で重要です。このステップにより、開発者は Airflow 3 と互換性のない特定のコードに焦点を当てることができます。 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/installation/upgrading_to_airflow3.html#step-3-dag-authors-check-your-airflow-dags-for-compatibility\" target=\"_blank\" rel=\"noopener\">ruff linter</a>を AIR30 ルールセットと共に使用して、更新が必要なコードを自動的に特定します。</p> \n<pre><code class=\"lang-code\">ruff check --preview --select AIR30 &lt;path_to_your_dag_code&gt;</code></pre> \n<p>さらに、<a href=\"https://airflow.apache.org/docs/apache-airflow/stable/installation/upgrading_to_airflow3.html#step-5-review-custom-operators-for-direct-db-access\" target=\"_blank\" rel=\"noopener\">メタデータベースへの直接アクセス</a>がコードに含まれていないか確認してください。</p> \n<h3>DAG コードの更新</h3> \n<p>互換性テストの結果に基づいて、Airflow 3.x に影響を受ける DAG コードを更新してください。ruff DAG チェックユーティリティを使用すると、一般的な変更を自動的に修正できます。以下のコマンドを使用して、更新モードでユーティリティを実行してください：</p> \n<pre><code class=\"lang-code\">ruff check dag/ --select AIR301 --fix ––preview</code></pre> \n<p>一般的な変更点は以下の通りです:</p> \n<ul> \n <li>メタデータベースへの直接アクセスを API 呼び出しに置き換える： \n  <div class=\"hide-language\"> \n   <pre><code class=\"lang-python\"># Before (Airflow 2.x) - Direct DB access\n\nfrom airflow.settings import Session\nfrom airflow.models.taskInstance import TaskInstance\nsession=Session()\nresult=session.query(TaskInstance)\n\nFor Apache Airflow v3.x, utilize in the Amazon MWAA SDK.\nUpdate core construct imports with the new Airflow SDK namespace:\n# Before (Airflow 2.x)\nfrom airflow.decorators import dag, task\n\n# After (Airflow 3.x)\nfrom airflow.sdk import dag, task</code></pre> \n  </div> </li> \n <li>非推奨のコンテキスト変数を最新の同等のものに置き換える： \n  <div class=\"hide-language\"> \n   <pre><code class=\"lang-python\"># Before (Airflow 2.x)\ndef my_task(execution_date, **context):\n    # Using execution_date\n\n# After (Airflow 3.x)\ndef my_task(logical_date, **context):\n    # Using logical_date</code></pre> \n  </div> </li> \n</ul> \n<p>次に、2 つのスケジューリング関連のデフォルト変更の使用状況を評価します。<code>catchup_by_default</code> が <code>False</code> になったため、欠落した DAG の実行は自動的にバックフィルされなくなりました。バックフィルが必要な場合は、DAG の定義を <code>catchup=True</code> に更新してください。DAG にバックフィルが必要な場合は、この移行とバックフィルの影響を考慮する必要があります。履歴のないクリーンな環境に DAG を移行するため、バックフィルを有効にすると、指定された start_date から始まるすべての実行に対して DAG 実行が作成されます。不要な実行を避けるため、start_date の更新を検討してください。</p> \n<p><code>create_cron_data_intervals</code> も <code>False</code> になりました。この変更により、cron 式は <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/timetable.html#crontriggertimetable\" target=\"_blank\" rel=\"noopener\">CronTriggerTimetable</a> コンストラクトとして評価されます。</p> \n<p>最後に、手動および Asset トリガーの DAG に対する<a href=\"https://airflow.apache.org/docs/apache-airflow/3.0.0/release_notes.html#context-behavior-for-asset-and-manually-triggered-dags\" target=\"_blank\" rel=\"noopener\">非推奨のコンテキスト変数</a>の使用状況を評価し、適切な代替コードに更新してください。</p> \n<h3>requirements の更新とテスト</h3> \n<p>パッケージバージョンの変更に加えて、airflow-core パッケージに含まれていた複数の Airflow コアオペレーターが apache-airflow-providers-standard パッケージに移行されました。これらの変更は、<code>requirements.txt</code> ファイルに反映する必要があります。requirements ファイルでパッケージバージョンを指定 (固定) することはベストプラクティスであり、この移行でも推奨されています。requirements ファイルを更新するには、以下の手順を実行します：</p> \n<ol> \n <li>Amazon MWAA Docker イメージをダウンロードして設定します。詳細については、<a href=\"https://github.com/aws/amazon-mwaa-docker-images\" target=\"_blank\" rel=\"noopener\">GitHub リポジトリ</a>を参照してください。</li> \n <li>現在の環境の <code>requirements.txt</code> ファイルを新しいファイルにコピーします。</li> \n <li>必要に応じて、新しい requirements ファイルに apache-airflow-providers-standard パッケージを追加します。</li> \n <li>対象の Airflow バージョンに適した Airflow constraints ファイルを作業ディレクトリにダウンロードします。constraints ファイルは、Airflow バージョンと Python バージョンの組み合わせごとに用意されています。URL は以下の形式になります：<code>https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt</code></li> \n <li>バージョン指定のない requirements ファイルと constraints ファイルを使用して、バージョン指定された requirements ファイルを作成します。requirements ファイルの作成ガイダンスについては、<a href=\"https://docs.aws.amazon.com/ja_jp/mwaa/latest/userguide/working-dags-dependencies.html#working-dags-dependencies-test-create\" target=\"_blank\" rel=\"noopener\"><code>requirements.txt</code> ファイルの作成</a>を参照してください。次のステップに進む前に、依存関係の競合がないことを確認してください。</li> \n <li>Docker イメージを使用して requirements ファイルを検証します。実行中のコンテナ内で以下のコマンドを実行します： \n  <div class=\"hide-language\"> \n   <pre><code class=\"lang-code\">./run.sh test-requirements</code></pre> \n  </div> <p>インストールエラーが発生した場合は、パッケージのバージョンを更新して対処します。</p></li> \n</ol> \n<p>ベストプラクティスとして、Amazon MWAA へのデプロイ用にパッケージを ZIP ファイルにパッケージ化することをお勧めします。これにより、すべての Airflow ノードに同じパッケージが確実にインストールされます。依存関係のパッケージ化に関する詳細については、<a href=\"https://docs.aws.amazon.com/ja_jp/mwaa/latest/userguide/best-practices-dependencies.html#best-practices-dependencies-different-ways\" target=\"_blank\" rel=\"noopener\">PyPI.org 要件ファイルフォーマットを使用した Python 依存関係のインストール</a>を参照してください。</p> \n<h3>新しい Amazon MWAA 3.x 環境の作成</h3> \n<p>Amazon MWAA はメジャーバージョンアップグレードに移行アプローチを必要とするため、ブルー/グリーンデプロイメント用に新しい環境を作成する必要があります。この記事では例として <a href=\"https://aws.amazon.com/jp/cli/\" target=\"_blank\" rel=\"noopener\">AWS Command Line Interface</a> (AWS CLI) を使用しますが、Infrastructure as Code (IaC) を使用することもできます。</p> \n<ol> \n <li>現在の S3 バケットと同じ構造で新しい S3 バケットを作成します。</li> \n <li>更新された requirements ファイルとプラグインパッケージを新しい S3 バケットにアップロードします。</li> \n <li>新しい環境設定のテンプレートを生成します： \n  <div class=\"hide-language\"> \n   <pre class=\"unlimited-height-code\"><code class=\"lang-bash\">aws mwaa create-environment --generate-cli-skeleton &gt; new-mwaa3-env.json</code></pre> \n  </div> </li> \n <li>生成された JSON ファイルを変更します： \n  <ol type=\"a\"> \n   <li>既存の環境から設定をコピーします。</li> \n   <li>環境名を更新します。</li> \n   <li>AirflowVersion パラメータをターゲットの 3.x バージョンに設定します。</li> \n   <li>S3 バケットのプロパティを新しい S3 バケット名で更新します。</li> \n   <li>必要に応じて他の設定パラメータを確認し更新します。</li> \n  </ol> <p>既存の環境と同じネットワーク設定、セキュリティグループ、IAM ロールで新しい環境を設定します。これらの設定については、<a href=\"https://docs.aws.amazon.com/ja_jp/mwaa/latest/userguide/what-is-mwaa.html\" target=\"_blank\" rel=\"noopener\">Amazon MWAA ユーザーガイド</a>を参照してください。</p></li> \n <li>新しい環境を作成します： \n  <div class=\"hide-language\"> \n   <pre class=\"unlimited-height-code\"><code class=\"lang-bash\">aws mwaa create-environment --cli-input-json file://new-mwaa3-env.json</code></pre> \n  </div> </li> \n</ol> \n<h3>メタデータの移行</h3> \n<p>新しい環境には、同じ変数、接続、ロール、プールの設定が必要です。このセクションを、これらの情報の移行ガイドとして使用してください。<a href=\"https://aws.amazon.com/jp/secrets-manager/\" target=\"_blank\" rel=\"noopener\">AWS Secrets Manager</a> をシークレットのバックエンドとして使用している場合は、接続を移行する必要はありません。環境サイズに応じて、Airflow UI または <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html\" target=\"_blank\" rel=\"noopener\">Apache Airflow REST API</a> を使用してこのメタデータを移行できます。</p> \n<ol> \n <li>Airflow UI を使用して、新しい環境でカスタムプールの情報を更新します。</li> \n <li>メタデータベースをシークレットバックエンドとして使用する環境の場合、すべての接続を新しい環境に移行します。</li> \n <li>すべての変数を新しい環境に移行します。</li> \n <li>カスタム Airflow ロールを新しい環境に移行します。</li> \n</ol> \n<h3>移行の実行と検証</h3> \n<p>古い環境から新しい環境への移行を計画し、実行します。</p> \n<ol> \n <li>ワークフローの影響を最小限に抑えるため、アクティビティの少ない期間に移行をスケジュールしてください。</li> \n <li>移行前および移行中で DAG の変更の停止期間を設定してください。</li> \n <li>移行を以下のフェーズで実行してください： \n  <ol type=\"a\"> \n   <li>古い環境で DAG を一時停止します。少数の DAG の場合は Airflow UI を使用できます。大規模なグループの場合は、REST API の使用を検討してください。</li> \n   <li>Airflow UI で実行中のすべてのタスクが完了したことを確認します。</li> \n   <li>DAG トリガーと外部統合を新しい環境にリダイレクトします。</li> \n   <li>更新された DAG を新しい環境の S3 バケットにコピーします。</li> \n   <li>新しい環境で DAG を有効化します。少数の DAG の場合は Airflow UI を使用できます。大規模なグループの場合は、REST API の使用を検討してください。</li> \n  </ol> </li> \n <li>初期運用期間中は新しい環境を注意深く監視してください： \n  <ol type=\"a\"> \n   <li>失敗したタスクやスケジューリングの問題がないか監視します。</li> \n   <li>変数や接続の欠落がないか確認します。</li> \n   <li>外部システムとの統合が正しく機能しているか確認します。</li> \n   <li><a href=\"https://aws.amazon.com/jp/cloudwatch/\" target=\"_blank\" rel=\"noopener\">Amazon CloudWatch</a> メトリクスをモニタリングして、環境が期待通りに動作していることを確認します。</li> \n  </ol> </li> \n</ol> \n<h3>移行後の検証</h3> \n<p>移行後、新しい環境を徹底的に検証します:</p> \n<ul> \n <li>すべての DAG が定義されたスケジュールに従って正しくスケジュールされていることを確認します。</li> \n <li>タスク履歴とログにアクセス可能で完全であることを確認します。</li> \n <li>重要なワークフローのエンドツーエンドテストを実施し、正常に実行されることを確認します。</li> \n <li>外部システムへの接続が適切に機能していることを検証します。</li> \n <li>パフォーマンスの検証のために CloudWatch メトリクスを監視します。</li> \n</ul> \n<h3>クリーンアップと文書化</h3> \n<p>移行が完了し、新しい環境が安定したら、以下の手順を実行してください。</p> \n<ol> \n <li>移行プロセス中に行った変更を文書化します。</li> \n <li>新しい環境を反映するように、運用手順書とオペレーション手順を更新します。</li> \n <li>ステークホルダーが定めた十分な安定期間の後、古い環境を廃止します： \n  <div class=\"hide-language\"> \n   <pre><code class=\"lang-code\">aws mwaa delete-environment --name old-mwaa2-env</code></pre> \n  </div> </li> \n <li>組織のデータ保持ポリシーに従ってバックアップデータをアーカイブします。</li> \n</ol> \n<h2>まとめ</h2> \n<p>Amazon MWAA における Airflow 2.x から 3.x への移行は、ワークフロー運用の信頼性を維持しながら、次世代のワークフロー オーケストレーション機能を活用する機会となります。これらのベストプラクティスに従い、体系的なアプローチを維持することで、ビジネス運用へのリスクと混乱を最小限に抑えながら、この移行を成功させることができます。</p> \n<p>移行を成功させるには、入念な準備、体系的なテスト、そしてプロセス全体を通じた明確なドキュメントの維持が必要です。この移行アプローチは初期の労力は大きくなりますが、このような重要なアップグレードに必要な安全性と制御を提供します。</p> \n<hr> \n<h3>著者について</h3> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/Anurag-Srivastava-badge-100x133-1-1.jpg\"><img loading=\"lazy\" class=\"size-full wp-image-167293 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/Anurag-Srivastava-badge-100x133-1-1.jpg\" alt=\"\" width=\"100\" height=\"133\"></a>Anurag Srivastava</strong> は、AWS のシニアテクニカルアカウントマネージャーとして、Amazon MWAA を専門に担当しています。お客様のスケーラブルなデータパイプラインとワークフロー自動化ソリューションの構築支援に情熱を注いでいます。</p> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/BDB-3847-awskamen-100x100-1-1.png\"><img loading=\"lazy\" class=\"size-full wp-image-167295 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/BDB-3847-awskamen-100x100-1-1.png\" alt=\"\" width=\"100\" height=\"100\"></a>Kamen Sharlandjiev</strong> は、ビッグデータおよび ETL ソリューションアーキテクトのシニアで、Amazon MWAA と AWS Glue ETL のエキスパートです。複雑なデータ統合とオーケストレーションの課題に直面するお客様の負担を軽減することをミッションとしています。最小限の労力で成果を出せるフルマネージド型 AWS サービスが彼の秘密兵器です。Amazon MWAA と AWS Glue の最新機能やニュースについては、LinkedIn で Kamen をフォローしてください！</p> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/Ankit-1-100x100-1.png\"><img loading=\"lazy\" class=\"size-full wp-image-167296 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/Ankit-1-100x100-1.png\" alt=\"\" width=\"100\" height=\"100\"></a>Ankit Sahu</strong> は、革新的なデジタル製品やサービスの構築において 18 年以上の実績があります。製品戦略、市場投入の実行、デジタルトランスフォーメーションイニシアチブにわたる幅広い経験を持ちます。現在は Amazon Web Services (AWS)のシニアプロダクトマネージャーとして、Amazon MWAA サービスを主導しています。</p> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/jeeten.png\"><img loading=\"lazy\" class=\"size-full wp-image-167297 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/jeeten.png\" alt=\"\" width=\"100\" height=\"119\"></a>Jeetendra Vaidya</strong> は、AWS のシニアソリューションアーキテクトとして、AI/ML、サーバーレス、データ分析の分野で専門性を発揮しています。お客様の安全で、スケーラブルで、信頼性が高く、コスト効率の良いソリューションの設計を支援することに情熱を注いでいます。</p> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/ellisms-resize.jpeg\"><img loading=\"lazy\" class=\"size-full wp-image-167298 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/ellisms-resize.jpeg\" alt=\"\" width=\"100\" height=\"133\"></a>Mike Ellis</strong> は、AWS のシニアテクニカルアカウントマネージャーで、Amazon MWAA のスペシャリストです。お客様の Amazon MWAA 支援に加えて、Airflow オープンソースプロジェクトにも貢献しています。</p> \n<p style=\"clear: both\"><strong> <a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/venu.jpeg\"><img loading=\"lazy\" class=\"size-full wp-image-167299 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/19/venu.jpeg\" alt=\"\" width=\"100\" height=\"133\"></a>Venu Thangalapally</strong> は、シカゴを拠点とする AWS のシニアソリューションアーキテクトで、クラウドアーキテクチャ、データ分析、コンテナ、アプリケーションモダナイゼーションに関する深い専門知識を持っています。金融サービス業界のお客様と協力して、ビジネス目標を安全で、スケーラブルで、コンプライアンスに準拠したクラウドソリューションに転換し、測定可能な価値を提供しています。技術を活用してイノベーションと業務効率の向上を推進することに情熱を注いでいます。仕事以外では、家族との時間を大切にし、読書や散歩を楽しんでいます。</p>"
  },
  {
    "title": "NTT西日本の AWS 事例：Amazon Bedrock Knowledge Bases を活用した営業支援 AI ボットの開発",
    "date": "2025-10-20T00:46:07.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/aws-genai-usecases-nttwest-elgana-rag/",
    "content": "<p><em>本ブログは、NTT西日本グループ 吉田 健哉氏、同 中井 智絵氏、アマゾン ウェブ サービス ジャパン合同会社 ソリューションアーキテクト 川岸 が共同で執筆しました。</em></p> \n<h2>はじめに</h2> \n<p><a href=\"https://www.ntt-west.co.jp/\">NTT西日本株式会社</a>（以下、NTT西日本）では、<a href=\"https://business.ntt-west.co.jp/service/assist/elgana/\">ビジネスチャット『elgana』（エルガナ）</a>をサービス提供しています。<a href=\"https://aws.amazon.com/jp/solutions/case-studies/ntt-west/\">2022 年 7 月にアマゾン ウェブ サービス (AWS) へプラットフォーム</a>を移行し、生成 AI による新機能開発も加速しています。</p> \n<p>elgana Project 「AI Lab.チーム」では、生成 AI を実際の業務にどう活かせるかをテーマにトライアル開発を進めています。本記事では、営業担当者支援を目的として <a href=\"https://docs.aws.amazon.com/ja_jp/bedrock/latest/userguide/knowledge-base.html\">Amazon Bedrock Knowledge Bases</a> を活用した RAG を構築し、そのトライアルを実施した取り組みについて紹介します。</p> \n<h2>取り組み背景</h2> \n<p>elgana は一般の企業様を中心にご利用いただいているサービスですが、生成 AI による新機能開発は社内向けに検証を開始しました。NTT西日本グループにおいて営業担当者は日々多様な商材を扱い、膨大なマニュアルや資料を参照しています。しかし実際には、情報が複数のシステムに散在しており、必要な情報を探し出すのに時間がかかる・属人化してしまうといった課題がありました。加えて、商材の問い合わせ窓口である社内ヘルプデスクは限られた対応時間の中で運用されており、すべての問い合わせに即時対応することは難しい状況でした。そこで、生成 AI に社内ナレッジを組み合わせる RAG を活用し、効率的に「聞ける・探せる・使える」仕組みを提供できないか検証することにしました。AWS サービスとの親和性、日本語対応、セキュリティ設計の容易さから、Amazon Bedrock Knowledge Bases を採用しました。</p> \n<h2>営業支援 AI ボット</h2> \n<p>営業支援 AI ボットは elgana 上に構築しました。トークルーム上で営業支援 AI ボットに対して商材に関する質問を入力すると、AI ボットが即時に回答を提示する仕組みです。また、AI ボットからの回答には、補足情報として関連するマニュアルページへのリンクを設けることで、裏付けとなる情報を容易に確認できる設計としました。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_chat_image1.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-167117\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_chat_image1.png\" alt=\"\" width=\"904\" height=\"446\"></a></p> \n<p>さらに、回答後には「解決した／解決していない」の簡易アンケートを設け、解決率を収集するとともに、未解決のユーザーをヘルプデスクに誘導する流れを設けています。これにより、AI の強みと有人対応を組み合わせた実用的なサポート体験を実現しています。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_chat_image2.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-167118\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_chat_image2.png\" alt=\"\" width=\"904\" height=\"450\"></a></p> \n<h2>アーキテクチャ</h2> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_architecture.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-167120\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_architecture.png\" alt=\"\" width=\"2220\" height=\"1232\"></a></p> \n<p>本システムでは、AWS のマネージドサービスをフル活用して構成し、最新技術の活用、インフラ運用の負担軽減とアプリレイヤの改善への集中を実現しています。elgana 上で営業支援 AI ボットに質問すると、Amazon API Gateway と AWS Lambda で実装したアプリケーションがメッセージを受信し、Amazon Bedrock Knowledge Bases を呼び出して質問に回答します。ナレッジのドキュメントの保存先のベクトルストアとして Amazon OpenSearch Serverless を利用しています。</p> \n<p>営業支援 AI ボットでは、利用者体験を向上させるため、回答生成に利用したマニュアルのページ番号まで案内すること、関連するサービスマニュアルのナレッジだけを参照するよう<a href=\"https://aws.amazon.com/jp/blogs/news/knowledge-bases-for-amazon-bedrock-now-supports-metadata-filtering-to-improve-retrieval-accuracy/\">メタデータフィルタリング</a>を活用して検索対象を絞り込むことで回答精度を向上させる工夫をしています。</p> \n<p>具体的な処理内容としては、運用者が Amazon S3 にアップロードしたマニュアルの pdf ファイルは AWS Lambda (pre-processing) を通じて、(A) ページ分割した上で、Markdown 形式に変換、(B) マニュアルに付与するメタデータを作成、の 2 つの処理が行われた後、Amazon S3 に格納されます。(A) の処理では、ページ分割することで RAG 回答で参照したマニュアルのページ番号をファイル名から特定できるようにしています。また、マニュアルに含まれる表データの抽出精度向上のため、pdf 文書をテキスト化するための python ライブラリである pdfminer を用いて HTML 化し、その後 Claude 3.5 Sonnet で Markdown 形式に変換しています。なお、Claude 3.5 Sonnet はマルチモーダル対応 LLM であるため、画像認識による情報抽出も可能ですが、検証時点では pdfminer を介す方法の方が優れていると判断しました。(B) の処理では、S3 のオブジェクトキー情報からカテゴリ情報等を抽出して、<code>.metadata.json</code> メタデータファイルを作成しています。</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_architecture2.png\"><img loading=\"lazy\" class=\"alignnone size-full wp-image-167121\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/16/elgana_rag_architecture2.png\" alt=\"\" width=\"2060\" height=\"720\"></a><br> 以下はメタデータファイルの中身の例です。</p> \n<pre><code class=\"lang-json\">{\n    \"metadataAttributes\": {\n        \"original-s3-key\": \"docs/商材A/pdf/manualA.pdf\",\n        \"file-type\": \"pdf\",\n        \"category\": \"商材A\"\n    }\n}</code></pre> \n<p>このメタデータは、ベクトルストアからドキュメント検索する際に、メタデータに基づき事前にフィルタリングした上で、関連するドキュメントを検索できます。上記の例では、単一の Knowledge Base に複数の商材のマニュアルを格納していた場合にも、<code>category = 商材A</code> でフィルタリングすることで関連する情報を取得できるため、検索精度向上に寄与します。</p> \n<h2>トライアル結果</h2> \n<p>今回の取り組みでは、実際の営業担当者に数週間トライアル利用していただき、その後、ユーザーアンケートを実施し様々な評価を得ました。利用者からは「知りたい情報に素早くアクセスできる」「マニュアルを探す時間が減った」といった声が多く寄せられ、業務効率化につながる手応えを実感していただいており、現場での実用性を確認する結果となりました。一方で、「回答速度を上げてほしい」や「回答の幅（サービスの種類）を広げてほしい」などの改善意見もポイントも挙げられました。こうした声を踏まえ、今後も更なる機能改善を繰り返し利用者がさらに安心して業務に取り入れられるよう、進化させていく予定です。</p> \n<h2>今後の展望</h2> \n<p>今回のトライアルで得られた成果をもとに機能改善を重ねて実運用を目指していく予定です。<br> また、開発した RAG 基盤は Amazon S3 にナレッジドキュメントを格納するだけで対象商材に特化した検索基盤を自動的に構築できる仕組みであり、幅広い業務で活用できる柔軟な基盤へ発展させることも視野に入れています。将来的には Amazon Bedrock AgentCore 等を活用することで、単なる検索や回答にとどまらずタスク実行まで支援できる「Agentic RAG」へ時代に即した価値創出を目指します。</p> \n<h2>まとめ</h2> \n<p>本ブログでは、NTT西日本グループによる、 Amazon Bedrock Knowledge Bases を活用した営業支援 AI ボットによる情報検索効率化の取り組み事例をご紹介しました。生成 AI の業務利用にあたっては、ハルシネーションのような不確実性を課題視されるお客様もいらっしゃると思います。本事例では、関連マニュアルのページ番号まで明示することで情報の正確性を迅速に確認できる仕組みを構築するとともに未解決の場合にはヘルプデスクに誘導する仕組みを設け、AI の強みと有人対応を組み合わせた実用的なサポート体験を実現しています。皆様の生成 AI 活用の参考になれば幸いです。</p> \n<h3>著者</h3> \n<p>吉田 健哉<br> NTTビジネスソリューションズ株式会社 バリューデザイン部 システム開発部門</p> \n<p>中井 智絵<br> NTT西日本株式会社 ビジネス営業本部 バリューデザイン部 DXプラットフォーム部門</p> \n<p>川岸 基成<br> アマゾン ウェブ サービス ジャパン合同会社 技術統括本部 ストラテジックインダストリー技術本部 通信グループ<br> ソリューションアーキテクト</p>"
  },
  {
    "title": "【Claude Code】Serenaの導入でAI活用を加速！",
    "date": "2025-10-20T00:30:01.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/hacobell_dev/articles/claude-code-serena-mcp-experience",
    "content": "\n 3行まとめ\n\nClaude Codeの出力精度を安定させるための設定ファイル整備に苦労していた\nSerena導入で、コードベース全体の一貫性を保持しつつ、暗黙知の言語化コストを大幅削減\nLSPとIndexingによりToken使用量が削減され、APIコストを低減\n\n\n はじめに\nClaude Codeを導入してみたものの、期待した効果が得られずに悩んでいる方も多いのではないでしょうか。私もその一人でした。具体的には、コードベース全体との一貫性や、チーム固有の設計思想を踏まえた生成がうまくいかず、そのたびにCLAUDE.mdやプロンプトで補足情報を足すのですが、暗黙知を毎回言語化して投..."
  },
  {
    "title": "Amazon MWAA における Apache Airflow 3 の紹介：新機能と機能拡張",
    "date": "2025-10-20T00:10:37.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/introducing-apache-airflow-3-on-amazon-mwaa-new-features-and-capabilities/",
    "content": "<p>本記事は、2025/10/1 に公開された <a href=\"https://aws.amazon.com/jp/blogs/big-data/introducing-apache-airflow-3-on-amazon-mwaa-new-features-and-capabilities/\" target=\"_blank\" rel=\"noopener\">Introducing Apache Airflow 3 on Amazon MWAA: New features and capabilities</a> を翻訳したものです。翻訳はプロフェッショナルサービスの佐藤が担当しました。</p> \n<p>本日、Amazon Web Services (AWS) は、<a href=\"https://aws.amazon.com/managed-workflows-for-apache-airflow/\" target=\"_blank\" rel=\"noopener\">Amazon Managed Workflows for Apache Airflow (Amazon MWAA)</a> における <a href=\"https://airflow.apache.org/blog/airflow-three-point-oh-is-here/\" target=\"_blank\" rel=\"noopener\">Apache Airflow 3</a> の一般提供開始を発表しました。このリリースにより、組織がクラウド上でデータパイプラインやビジネスプロセスをオーケストレーションするために Apache Airflow を使用する方法が変革され、強化されたセキュリティ、改善されたパフォーマンス、そして最新のワークフローオーケストレーション機能がもたらされます。</p> \n<p>Amazon MWAA は、AWS のお客様向けにワークフロー管理を最新化する Airflow 3 の機能を導入します。Apache コミュニティによる 2025 年 4 月の Airflow 3 リリースに続き、AWS はこれらの機能を Amazon MWAA に組み込みました。Airflow は現在、再設計された直感的な UI を備えており、あらゆるレベルのユーザーにとってワークフローオーケストレーションを簡素化します。Task Execution Interface (Task API) により、タスクは Airflow 内とスタンドアロンの Python スクリプトの両方として実行でき、コードの移植性とテストが向上します。スケジューラー管理のバックフィルは、操作を CLI からスケジューラーに移行し、Airflow UI を通じて一元的な制御と可視性を提供します。CLI のセキュリティ改善により、データベースへの直接アクセスが API 呼び出しに置き換えられ、インターフェース全体で一貫したセキュリティが維持されます。Airflow は現在、event-driven ワークフローをサポートしており、AWS サービスや外部ソースからのトリガーが可能になります。Amazon MWAA は Python 3.12 のサポートも追加し、ワークフロー開発に最新の言語機能をもたらします。</p> \n<p>この記事では、Amazon MWAA における Airflow 3 の機能を探求し、ワークフローオーケストレーション機能を向上させる拡張機能の概要を説明します。このサービスは、前払いのコミットメントなしで Amazon MWAA の従量課金制の料金モデルを維持します。<a href=\"https://console.aws.amazon.com/mwaa/home\" target=\"_blank\" rel=\"noopener\">Amazon MWAA コンソール</a>にアクセスし、<a href=\"https://console.aws.amazon.com/\" target=\"_blank\" rel=\"noopener\">AWS マネジメントコンソール</a>、<a href=\"https://aws.amazon.com/cli/\" target=\"_blank\" rel=\"noopener\">AWS コマンドラインインターフェイス</a> (AWS CLI)、<a href=\"https://aws.amazon.com/cloudformation/\" target=\"_blank\" rel=\"noopener\">AWS CloudFormation</a>、または <a href=\"https://aws.amazon.com/developer/tools/\" target=\"_blank\" rel=\"noopener\">AWS SDK</a> を通じて Apache Airflow 環境を起動することで、数分以内に開始できます。</p> \n<h2>Amazon MWAA における Airflow 3 のアーキテクチャの進歩</h2> \n<p>Amazon MWAA における Airflow 3 は、セキュリティ、パフォーマンス、柔軟性を向上させる重要なアーキテクチャの改善を導入します。これらの進歩により、既存のワークフローとの下位互換性を維持しながら、ワークフローオーケストレーションのためのより堅牢な基盤が構築されます。</p> \n<h3>セキュリティの強化</h3> \n<p>Airflow 3 を搭載した Amazon MWAA は、コンポーネントの分離をオプションではなく標準とすることで、セキュリティモデルを変更します。Airflow 2 では、DAG プロセッサー (DAG ファイルを解析および処理するコンポーネント) はデフォルトでスケジューラープロセス内で実行されますが、スケーラビリティとセキュリティの分離を向上させるために、オプションで独自のプロセスに分離できました。Airflow 3 では、この分離を標準とし、デプロイメント全体で一貫したセキュリティプラクティスを維持します。</p> \n<h3>API サーバーと Task API</h3> \n<p>このセキュリティモデルの上に、Airflow 3 を搭載した Amazon MWAA では新しい API サーバーコンポーネントが導入され、タスクインスタンスと Airflow メタデータデータベース間の仲介役として機能します。この変更により、タスクから Airflow メタデータデータベースへの直接アクセスを最小限に抑えることができ、ワークフローのセキュリティ態勢が向上します。タスクは現在、最小権限のデータベースアクセスで動作し、あるタスクが他のタスクに影響を与えるリスクを軽減し、データベースへの直接アクセスを減らすことで全体的なシステムの安定性を向上させます。</p> \n<p>明確に定義された API エンドポイントを通じた標準化された通信により、より安全で、スケーラブル、柔軟なワークフローオーケストレーションの基盤が構築されます。Task API により、タスクは Airflow 内とスタンドアロンの Python スクリプトの両方として実行でき、コードの移植性とテスト機能が向上します。</p> \n<h3>data-aware スケジューリングから event-driven スケジューリングへ</h3> \n<p>Airflow の event-driven スケジューリングへの進化は、Airflow 2.4 での data-aware スケジューリングの導入から始まり、時刻だけでなくデータの変更や更新を検知して DAG をトリガーできるようになりました。Airflow 3 を搭載した Amazon MWAA は、Dataset から Asset への名称変更を含む移行を通じてこの基盤の上に構築され、Asset パーティション、外部イベント統合、Asset 中心のワークフロー設計などの高度な機能を導入します。</p> \n<p>Dataset から Asset への移行は、単純な名称変更以上のものを表しています。 Asset は、データベーステーブル、永続化された ML モデル、埋め込みダッシュボード、ファイルを含むディレクトリなど、多様なデータ製品を表すことができる、論理的に関連するデータのコレクションです。</p> \n<p>Airflow 3 を搭載した Amazon MWAA は、ワークフローの設計方法における重要な変化を表す新しい Asset 中心の構文を導入します。@asset デコレーターにより、開発者は Asset をワークフロー設計の中心に置くことができ、より直感的な asset-driven パイプラインを作成できます。</p> \n<p>以下は、asset-aware DAG スケジューリングの例です:</p> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-python\">from airflow.sdk import DAG, Asset\nfrom airflow.providers.standard.operators.python import PythonOperator\n\n# Define the asset\ncustomer_data_asset = Asset(name=\"customer_data\", uri=\"s3://my-bucket/customer-data.csv\")\n\ndef process_customer_data():\n    \"\"\"Process customer data...\"\"\"\n    # Implementation here\n\n# Create the DAG and task\nwith DAG(dag_id=\"process_customer_data\", schedule=\"@daily\"):\n    PythonOperator(\n        task_id=\"process_data\", \n        outlets=[customer_data_asset], \n        python_callable=process_customer_data\n    )</code></pre> \n</div> \n<p>以下は、@asset デコレーターを使用した Asset 中心のアプローチを示しています:</p> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-python\">from airflow.sdk import asset\n\n@asset(uri=\"s3://my-bucket/customer-data.csv\", schedule=\"@daily\")\ndef customer_data():\n    \"\"\"Process customer data...\"\"\"\n    # Implementation here</code></pre> \n</div> \n<p>@asset デコレーターは、関数名を持つ Asset、同じ識別子を持つ DAG、および Asset を生成するタスクを自動的に作成します。これにより、コードの複雑さが軽減され、各 Asset が自己完結型のワークフローユニットになる自動 DAG 作成が容易になります。</p> \n<h3>Asset Watchers による external event-driven スケジューリング</h3> \n<p>Airflow 3 を搭載した Amazon MWAA における重要な進歩は、Asset Watchers の導入です。これにより、Airflow は Airflow システム自体の外部で発生するイベントに反応できるようになります。以前のバージョンでは内部のクロス DAG 依存関係をサポートしていましたが、Asset Watchers は AssetWatcher クラスを通じて、この機能を外部データシステムやメッセージキューに拡張します。</p> \n<p>Airflow 3 を搭載した Amazon MWAA には、Asset Watchers を通じた <a href=\"https://aws.amazon.com/sqs/\" target=\"_blank\" rel=\"noopener\">Amazon Simple Queue Service (Amazon SQS)</a> のサポートが含まれています。これにより、ワークフローを外部メッセージによってトリガーでき、より event-driven なスケジューリングが促進されます。Airflow は現在、event-driven ワークフローをサポートしており、AWS サービスや外部ソースからのトリガーが可能になります。Asset Watchers は外部システムを非同期的に監視し、特定のイベントが発生したときにワークフローの実行をトリガーします。これにより、従来のセンサーベースのポーリングメカニズムのオーバーヘッドなしに、ビジネスイベント、データ更新、またはシステム通知に応答できるようになります。</p> \n<h3>最新の React ベース UI</h3> \n<p>Airflow 3 を搭載した Amazon MWAA は、React と FastAPI で構築された完全に再設計された直感的な UI を備えており、あらゆるレベルのユーザーにとってワークフローオーケストレーションを簡素化します。新しいインターフェースは、より直感的なナビゲーションとワークフローの可視化を提供し、タスクのステータスと履歴をより良く可視化する強化されたグリッドビューを備えています。ユーザーは、長時間の使用中の疲労を軽減するダークモードのサポートの追加と、特に大規模な DAG を扱う際に顕著な全体的に高速なパフォーマンスを高く評価するでしょう。</p> \n<p>新しい UI は、DAG 管理と監視のためのより最新で効率的なエクスペリエンスを提供しながら、使い慣れたワークフローを維持し、開発者と運用者の両方にとって日常業務をより生産的にします。レガシー UI は完全に削除され、システム全体でよりクリーンで一貫したエクスペリエンスを提供します。新しい UI の基盤は、REST API と UI 操作用の内部 API のセットに基づいて構築されており、両方とも FastAPI に基づいているため、プログラムアクセスと UI 操作の両方に対して、より統合的で安全なアーキテクチャが構築されます。</p> \n<h3>スケジューラーの最適化</h3> \n<p>Airflow 3 を搭載した Amazon MWAA の強化されたスケジューラーは、タスク実行とワークフロー管理のパフォーマンス向上を実現します。再設計されたスケジューリングエンジンは、タスクをより効率的に処理し、タスクの送信と実行の間の時間を短縮します。この最適化は、迅速なタスク処理とタイムリーなワークフロー完了を必要とするデータパイプライン操作に利益をもたらします。</p> \n<p>スケジューラーは現在、コンピューティングリソースをより効果的に管理し、ワークロードがスケールしても安定したパフォーマンスを実現します。複数の DAG を同時に実行する場合、改善されたリソース割り当てシステムは、ボトルネックを防ぎ、一貫した実行速度を維持するのに役立ちます。この進歩は、さまざまなリソース要件を持つ複雑なワークフローを実行する組織にとって特に有用です。新しいスケジューラーは、同時操作をより高い精度で処理するため、チームはシステムの安定性と予測可能なパフォーマンスを維持しながら、複数の DAG インスタンスを同時に実行できます。</p> \n<h3>強化されたスケジューラーバックフィル操作</h3> \n<p>スケジューラー管理のバックフィル (過去の日付に対して DAG を実行するプロセス) は、操作を CLI からスケジューラーに移行し、Airflow UI を通じて一元的な制御と可視性を提供します。Airflow 3 を搭載した Amazon MWAA は、スケジューラーのバックフィル機能に重要なアップグレードを提供し、データチームが過去のデータをより効率的に処理できるようにします。バックフィルプロセスは、パフォーマンスの向上のために最適化されており、これらの操作中のデータベース負荷を軽減し、バックフィルをより迅速に完了できるようにし、ニアリアルタイムのワークフロー実行への影響を最小限に抑えます。</p> \n<p>Airflow 3 を搭載した Amazon MWAA は、バックフィル操作の管理も改善し、スケジューラーはバックフィルジョブ間のより良い分離を提供し、過去の Dataset より効率的な処理をサポートします。運用者は現在、バックフィルジョブの進行状況とステータスを追跡するためのより良い監視ツールを持っており、これらの重要なデータ処理タスクのより効果的な管理が可能になります。</p> \n<h2>開発者向けの改善</h2> \n<p>Amazon MWAA における Airflow 3 は、簡素化されたタスク定義からより良いワークフロー管理機能まで、開発者エクスペリエンスを向上させるために設計されたいくつかの拡張機能を提供します。</p> \n<h3>Task SDK</h3> \n<p><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html\" target=\"_blank\" rel=\"noopener\">Task SDK</a> は、タスクと DAG を定義するためのより直感的な方法を提供します:</p> \n<div class=\"hide-language\"> \n <pre><code class=\"lang-python\"># Example using the Task SDK\nfrom airflow.sdk import dag, task\nfrom datetime import datetime\n\n@dag(\n    start_date=datetime(2023, 1, 1),\n    schedule=\"@daily\",\n    catchup=False\n)\ndef modern_etl_workflow():\n    \n    @task\n    def extract():\n        # Extract data from source\n        return {\"data\": [1, 2, 3, 4, 5]}\n    \n    @task\n    def transform(input_data):\n        # Transform the data\n        return [x * 10 for x in input_data]\n    \n    @task\n    def load(transformed_data):\n        # Load data to destination\n        print(f\"Loading data: {transformed_data}\")\n    \n    # Define the workflow\n    extracted_data = extract()\n    transformed_data = transform(extracted_data[\"data\"])\n    load(transformed_data)\n\n# Instantiate the DAG\netl_dag = modern_etl_workflow()</code></pre> \n</div> \n<p>このアプローチは、タスク間のより直感的なデータフロー、改善された型ヒントによるより良い統合開発環境 (IDE) サポート、およびタスクロジックのより簡単な単体テストを提供します。その結果、パイプラインの実際のデータフローをより良く表現する、よりクリーンで保守しやすいコードが得られます。このパターンを採用するチームは、特にワークフローが複雑さを増すにつれて、DAG がより読みやすく、保守が簡単になることがよくあります。</p> \n<h3>DAG バージョニング</h3> \n<p>Airflow 3 を搭載した Amazon MWAA には、Airflow 3 にデフォルトで付属する基本的な DAG バージョニング機能が含まれています。DAG が変更されてデプロイされるたびに、Airflow は DAG 定義をシリアル化して保存し、履歴を保持します。この自動バージョン追跡により、手動での記録管理の必要性が最小限に抑えられ、すべての変更が記録されます。</p> \n<p>Airflow UI を通じて、チームは DAG の履歴にアクセスして確認できます。この視覚的表現は、バージョン番号 (v1、v2、v3 など) を示し、チームがワークフローが時間とともにどのように進化したかを理解するのに役立ちます。</p> \n<p>Amazon MWAA でサポートされている DAG バージョニングは、Airflow UI で実行されたさまざまな DAG バージョンを確認する機能を提供し、複雑で進化するデータパイプラインを管理するデータエンジニアリングチームに、改善されたワークフローの可視性と強化されたコラボレーションを提供します。</p> \n<h3>Python 3.12 サポート</h3> \n<p>Amazon MWAA は <a href=\"https://www.python.org/downloads/release/python-3120/\" target=\"_blank\" rel=\"noopener\">Python 3.12</a> のサポートを追加し、ワークフロー開発に最新の言語機能をもたらします。このアップグレードにより、最新の Python 言語の改善、パフォーマンスの強化、ライブラリの更新にアクセスでき、データパイプラインを最新かつ効率的に保ちます。</p> \n<h2>Amazon MWAA で現在サポートされていない機能</h2> \n<p>このリリースで Amazon MWAA に Airflow 3 の機能のほとんどを導入していますが、現時点ではサポートされていない機能がいくつかあります:</p> \n<p>Flask AppBuilder の置き換え (<a href=\"https://cwiki.apache.org/confluence/display/AIRFLOW/AIP-79%3A+Remove+Flask+AppBuilder+as+Core+dependency\" target=\"_blank\" rel=\"noopener\">AIP-79</a>) – 完全な置き換え機能<br> Edge Executor とタスクの分離 (<a href=\"https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=301795932\" target=\"_blank\" rel=\"noopener\">AIP-69</a>) – リモート実行機能<br> 多言語サポート (<a href=\"https://cwiki.apache.org/confluence/display/AIRFLOW/Test+cases+AIP-72+Task+Execution+Interface+aka+Task+SDK\" target=\"_blank\" rel=\"noopener\">AIP-72</a>) – Python 以外の言語のサポート<br> これらの機能は、Amazon MWAA における Airflow の今後のバージョンでサポートする予定です。</p> \n<h2>まとめ</h2> \n<p>Amazon MWAA における Airflow 3 は、強化されたワークフロー自動化機能を提供します。アーキテクチャの改善、強化されたセキュリティモデル、開発者フレンドリーな機能により、より信頼性が高く保守しやすいデータパイプラインを構築するための堅固な基盤が提供されます。Asset Watchers の導入により、ワークフローが外部イベントに応答する方法が変わり、真のevent-driven スケジューリングが可能になります。この機能は、新しい Asset 中心のワークフロー設計と組み合わせることで、Airflow 3 をより強力で柔軟なオーケストレーションサービスにします。</p> \n<p>スケジューラーの最適化により、タスク実行とワークフロー管理のパフォーマンスが向上し、強化されたバックフィル機能により、過去のデータ処理がより効率的になります。DAG バージョニングシステムは、ワークフローの安定性とコラボレーションを向上させ、Python 3.12 サポートにより、データパイプラインを最新かつ効率的に保ちます。</p> \n<p>組織は現在、Amazon MWAA における Airflow 3 のこれらの新機能と改善を活用して、ワークフローオーケストレーション機能を強化できます。開始するには、<a href=\"https://aws.amazon.com/managed-workflows-for-apache-airflow/\" target=\"_blank\" rel=\"noopener\">Amazon MWAA 製品ページ</a>をご覧ください。</p> \n<hr> \n<h3>著者について</h3> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167222 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/Anurag-Srivastava-badge-100x133-1.jpg\" alt=\"\" width=\"100\" height=\"133\"><strong>Anurag Srivastava</strong> は、Amazon Web Services (AWS) のシニアビッグデータクラウドエンジニアとして、Amazon MWAA を専門としています。彼は、お客様が AWS 上でスケーラブルなデータパイプラインとワークフロー自動化ソリューションを構築するのを支援することに情熱を注いでいます。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167221 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/BDB-3847-awskamen-100x100-1.png\" alt=\"\" width=\"100\" height=\"100\"><strong>Kamen Sharlandjiev</strong> は、シニアビッグデータおよび ETL ソリューションアーキテクトであり、Amazon MWAA と AWS Glue ETL のエキスパートです。彼は、複雑なデータ統合とオーケストレーションの課題に直面しているお客様の生活を楽にすることを使命としています。彼の秘密兵器?は、最小限の労力で仕事を完了できる完全マネージド型 AWS サービスです。最新の Amazon MWAA と AWS Glue の機能とニュースを最新の状態に保つために、LinkedIn で Kamen をフォローしてください!</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167220 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/Ankit-1-100x100-1.png\" alt=\"\" width=\"100\" height=\"100\"><strong>Ankit Sahu</strong> は、革新的なデジタル製品とサービスの構築において 18 年以上の専門知識を持っています。彼の多様な経験は、製品戦略、市場投入の実行、デジタルトランスフォーメーションイニシアチブにまたがっています。現在、Ankit は Amazon Web Services (AWS) のシニアプロダクトマネージャーとして、Amazon MWAA サービスをリードしています。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167219 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/sabeel.jpg\" alt=\"\" width=\"100\" height=\"133\"><strong>Mohammad Sabeel</strong> は、Amazon Web Services (AWS) のシニアクラウドサポートエンジニアとして、AWS Glue、Amazon MWAA、Amazon Athena を含む AWS Analytics サービスを専門としています。14 年以上の IT 経験を持つ彼は、お客様がスケーラブルなデータ処理パイプラインを構築し、AWS 上の分析ソリューションを最適化するのを支援することに情熱を注いでいます。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167218 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/SatyaChikkala-1-100x150-1.jpg\" alt=\"\" width=\"100\" height=\"150\"><strong>Satya Chikkala</strong> は、Amazon Web Services のソリューションアーキテクトです。オーストラリアのメルボルンを拠点とし、エンタープライズのお客様と緊密に協力してクラウドジャーニーを加速しています。仕事以外では、自然と写真撮影に非常に情熱を注いでいます。</p> \n<p style=\"clear: both\"><img loading=\"lazy\" class=\"size-full wp-image-167217 alignleft\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/18/saadari-1-100x133-1.jpg\" alt=\"\" width=\"100\" height=\"133\"><strong>Sriharsh Adari</strong> は、Amazon Web Services (AWS) のシニアソリューションアーキテクトであり、お客様がビジネス成果から逆算して AWS 上で革新的なソリューションを開発するのを支援しています。長年にわたり、彼は業界の垂直市場全体でデータシステムの変革において複数のお客様を支援してきました。彼の中核的な専門分野には、テクノロジー戦略、データ分析、データサイエンスが含まれます。余暇には、スポーツをしたり、テレビ番組を一気見したり、タブラを演奏したりすることを楽しんでいます。</p>"
  },
  {
    "title": "Amazon Bedrock 搭載の Treasure Data AI エージェントによってマーケティングキャンペーンプランニングを 3 倍に加速",
    "date": "2025-10-19T23:47:19.000Z",
    "source": "Amazon Web Services ブログ",
    "url": "https://aws.amazon.com/jp/blogs/news/accelerate-marketing-campaign-planning-by-3x-with-treasure-data-ai-agents-powered-by-amazon-bedrock/",
    "content": "<p><em>この記事は <a href=\"https://aws.amazon.com/blogs/industries/accelerate-marketing-campaign-planning-by-3x-with-treasure-data-ai-agents-powered-by-amazon-bedrock/\" target=\"_blank\" rel=\"noopener\">Accelerate Marketing campaign planning by 3x with Treasure Data AI Agents powered by Amazon Bedrock</a> の翻訳記事です。</em></p> \n<p>マルチチャネル・キャンペーンの企画・実行において、マーケティングチームは大きな課題に直面しています。従来のキャンペーン企画​では、仮説設定、オーディエンス分析、ジャーニーマッピング、コンテンツ開発、アクティベーション、そして効果測定など、システムとチーム間の調整だけで数ヶ月を必要とします。この長いプロセスの間に、顧客がエンゲージメントを必要とする重要な瞬間を逃してしまうことがあるのです。<span id=\"more-166247\"></span></p> \n<p>Treasure Dataの<a href=\"https://www.treasuredata.co.jp/product/intelligent-cdp/\" target=\"_blank\" rel=\"noopener\">顧客データプラットフォーム（CDP）</a>は、世界中の大手ブランドにサービスを提供しており、インターネット接続人口の大部分の顧客プロファイルを管理しています。Amazon Web Services（AWS）と連携し、Amazon Bedrock を利用したマーケティングチーム向けの AI 活用ソリューションを開発しました。<a href=\"https://aws.amazon.com/jp/bedrock/\" target=\"_blank\" rel=\"noopener\">Amazon Bedrock</a> は、生成 AI アプリケーションを構築するための高性能な<a href=\"https://docs.aws.amazon.com/ja_jp/bedrock/latest/userguide/models-supported.html\" target=\"_blank\" rel=\"noopener\">基盤モデル</a>へのフルマネージドアクセスを提供し、自然言語の指示を理解し、様々なシステムと自律的に対話する AI エージェントの導入を可能にするサービスです。</p> \n<p>このブログでは、Amazon Bedrock を使って構築された Treasure Data の AI を活用したサービスによって、どのようにしてキャンペーン作成を数か月かかるプロセスから数時間または、数日へと変革することができるのか解説します。これらのソリューションにより、マーケティングチームと CX チームは、エンタープライズ企業が求めるセキュリティとガバナンスの基準を有しつつ、市場機会に迅速に対応し、パーソナライズされた体験を大規模に提供できるようになります。</p> \n<h3>信頼できるデータを基にした AI エージェント構築</h3> \n<p>AI の真の力は、高度な基盤モデルと高品質な顧客データを組み合わせることにこそあります。Treasure Data のプラットフォームと Amazon Bedrock の統合により、マーケティング担当者が顧客データを迅速に分析し、ターゲットオーディエンスセグメントを生成し、詳細なペルソナを定義し、技術的な専門知識がなくてもデータに基づく意思決定を行うことができるようになります。この組み合わせにより、キャンペーン作成時間が大幅に短縮され、ターゲティングの精度とキャンペーンのパフォーマンスが向上します。</p> \n<h3>AWS との共同開発</h3> \n<p>Treasure Data は AWS と緊密に連携し、従来のキャンペーン計画・実行プロセスにおける主要なボトルネックを特定しました。既存のツールにチャットインターフェースを単に追加するのではなく、AI の効果を最大限に高めるための基本的なワークフローを再設計することに重点を置きました。</p> \n<p>このパートナーシップでは、人間の持つ専門知識と AI の能力の適切なバランスを見つけることを重視しました。マーケティング担当者は戦略的な全体監督としての役割を維持し、AI エージェントが時間のかかる分析タスクを処理します。このアプローチでは、複雑なデータの相関性を処理し、実際の顧客の行動に基づいた実用的なインサイトを提供できるエージェントを構築する必要がありました。</p> \n<p>このコラボレーションにより、Amazon Bedrock 上に構築されたマルチエージェント・フレームワークが実現し、エンタープライズ企業が求めるセキュリティとコンプライアンスの標準を維持しながら、特定のマーケティング課題に対処できるようになりました。</p> \n<h3>Amazon Bedrock の価値</h3> \n<p>Treasure Data が AI エージェント基盤として Amazon Bedrock を選択したのは、制御性やセキュリティを犠牲にすることなく迅速な導入を可能にするためです。Amazon Bedrock はモデル選択を簡素化し、チームにデータサイエンスの専門知識がなくても高度な基盤モデルにアクセスできるようになります。</p> \n<p>このフルマネージドプラットフォームにより、カスタムインフラストラクチャをゼロから構築することなく、本番環境への迅速な導入が可能になります。顧客データは AWS とお客様による責任共有モデルの範囲内でプライバシーとセキュリティが確保されます。AWS が基盤となるインフラストラクチャを保護し、お客様はコンテンツとアクセス権限を管理できます。</p> \n<p>Treasure Data の顧客データに関する専門知識と Amazon Bedrock が提供する AI 基盤モデルを組み合わせることにより、組織がセキュリティとガバナンスの標準を維持しつつ AI イニシアチブを拡張することができます。</p> \n<h3>Treasure Data の目的別 AI エージェント</h3> \n<p>Treasure Data は、Amazon Bedrock を基盤として、特定のマーケティング課題に対応するための目的別 AI エージェントをいくつか開発しました。各エージェントは、キャンペーンの計画・実行プロセスにおける重要な課題を専門に扱います。</p> \n<p><a href=\"https://www.treasuredata.co.jp/product/ai-agents/\" target=\"_blank\" rel=\"noopener\">Audience Agent</a> を利用すれば、マーケティング担当者が SQL や高度なデータ操作スキルを持たなくても、行動シグナルから高価値のオーディエンスセグメントを素早く発見・作成できます。エージェントが顧客行動のパターンを自動的に識別してくれるため、データ分析とオーディエンスセグメンテーションの速度と精度が向上します。図 1 はクエリに基づいて顧客データを取得する Audience Agent の例です。例えば「最もロイヤルティの高い顧客について知りたい」という要求に対して、Audience Agent が関連する属性を識別し、結果を提示しています。</p> \n<p><img loading=\"lazy\" class=\"aligncenter size-full wp-image-166474\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/07/Figure-1-Audience-Agent-Console.png\" alt=\"\" width=\"624\" height=\"387\"></p> \n<p style=\"text-align: center\">図 1: Audience Agent コンソール</p> \n<p><a href=\"https://www.treasuredata.com/blog/deep-research-analysis-agent/\" target=\"_blank\" rel=\"noopener\">Deep Research &amp; Analysis Agent</a> は、仮説構築プロセスを数ヶ月から 1 週間未満にまで短縮します。手作業による分析やマーケティングに膨大な時間を費やす代わりに、顧客チームは行動シグナルに基づいた高品質な仮説を構築し、戦略、テスト、実行の意思決定に役立てることができます。Treasure Data の Deep Insight Platform は「質問管理」機能を提供しており、ユーザーは図 2 に示すように、解約率の傾向やメールのパフォーマンス分析など、いろいろな分析のための質問を作成できます。</p> \n<p><img loading=\"lazy\" class=\"aligncenter size-full wp-image-166475\" src=\"https://d2908q01vomqb2.cloudfront.net/b3f0c7f6bb763af1be91d9e74eabfeb199dc1f1f/2025/10/07/Figure-2-Treasure-Data-Deep-Insight-Platform.png\" alt=\"\" width=\"624\" height=\"192\"></p> \n<p style=\"text-align: center\">図 2: Treasure Data Deep Insight Platform</p> \n<p>Treasure Data の <a href=\"https://www.treasuredata.co.jp/marketing-tool-trade-up-2025/\" target=\"_blank\" rel=\"noopener\">CDP トレードアッププログラム</a>の一部として提供される <a href=\"https://www.treasuredata.com/blog/meet-the-migration-agent/\" target=\"_blank\" rel=\"noopener\">Migration Agent</a> は、既存の顧客データプラットフォームからの移行を最大 60% 加速します。現在のシステムからクエリ、セグメント、変換ロジックを抽出し、SQL、パイプライン、オーケストレーション・ワークフローを自動生成します。このエージェントにより、既存のセグメント、ワークフロー、ビジネスロジックを維持したままデータを移行できるため、ゼロから構築する必要がなくなります。</p> \n<p>これらのエージェントは、データ処理機能と Amazon Bedrock の推論機能を組み合わせた Retrieval Augumented Generation (RAG) を利用しており、正確でデータに基づいた応答を提供します。これにより、AI による提案が一般的な推奨事項ではなく、実際の顧客行動を反映したものになります。</p> \n<h3>Treasure Data AI Agent Foundryのご紹介</h3> \n<p>予め提供されるエージェントは一般的なマーケティング課題に対応していますが、Treasure Data のお客様からは、独自のビジネス要件や業界固有のユースケースに合わせてカスタマイズされたエージェントを作成する必要性も指摘されていました。<a href=\"https://www.treasuredata.co.jp/product/ai-agent-foundry/\" target=\"_blank\" rel=\"noopener\">AI Agent Foundry</a> はこのニーズに応えるソリューションとして登場しました。</p> \n<p>AI Agent Foundry は、特定のビジネスニーズに合わせてカスタマイズされた AI エージェントを構築するための基盤です。マーケティングチーム、カスタマーエクスペリエンスチーム、データチームは、深い専門知識を持たなくても、エージェントを作成、改良、導入することができます。効果の高いユースケースとしては、ジャーニーオーケストレーション、データヘルスモニタリング、組織固有のキャンペーン最適化などが挙げられます。</p> \n<p>AI Agent Foundry には、エンタープライズガバナンス要件を満たすセキュリティ機能、権限管理、監査機能、アクセス管理が組み込まれています。チームは、データセキュリティ、プライバシー、規制コンプライアンスを維持しつつ、AI 機能を試し、エージェントを導入できます。このアプローチにより、お客様は特定の市場動向やビジネスプロセスに対応するエージェントを構築できます。</p> \n<h3>成果に直結する実用的なアプリケーション</h3> \n<p>これら専用エージェントは、Amazon Bedrock との統合で、複数の重要なマーケティングユースケースにも対応します。意思決定支援機能は、マーケティング担当者がキャンペーンのターゲティング、メッセージング、チャネル選択を決定する際に、複数の要素を同時に評価するのに役立ちます。AI が、単なる直感ではなく、包括的なデータ分析に基づいた推奨事項を提供してくれます。</p> \n<p>複数のチームメンバーが AI エージェントと同時に協働できるため、マーケティング組織全体で顧客インサイトへのアクセスが民主化されます。この機能により、マーケティングチームの技術的専門知識の不足によって生じるボトルネックが解消されます。</p> \n<p>エージェントは顧客とのやり取りやキャンペーンのパフォーマンスから継続的に学習するため、チームは素早い反復と最適化を通じてアプローチを改善し、よりよい成果を上げることができます。</p> \n<h3>事例：nobitel 株式会社</h3> \n<p>ヘルス＆スポーツサービスのリーディングカンパニーである nobitel 株式会社は、日本全国でストレッチ専門チェーン「Dr.Stretch」240 店舗以上を展開しています。同社はマーケティング業務において、手作業によるキャンペーン計画とデータのサイロ化により、技術チーム以外のチームが、顧客インサイトにアクセスしてタイムリーなパーソナライズされた推奨事項を提供することができないという課題を持っていました。</p> \n<p>この課題に対処するため、nobitel 社は Amazon Bedrock を含む AWS AI/ML サービスを利用して構築された Treasure Data AI Agent Foundry を導入しました。これにより、同社のマーケティング業務は変革され、技術チーム以外の、高度なデータスキルを持っていないマーケターでも、パーソナライズされたキャンペーンを実行できるようになりました。その結果、キャンペーン計画のスピードは 3 倍、店舗効率は 20% 向上しました。nobitel 社の変革の詳細については<a href=\"https://get.treasuredata.com/rs/714-XIJ-402/images/Nobitel-Case-Study-for-AWS-GenAI.pdf\" target=\"_blank\" rel=\"noopener\">ケーススタディ</a>をご覧ください。（訳注：日本語補足資料として<a href=\"https://www.treasuredata.co.jp/press-releases/20250325-nobitel/\" target=\"_blank\" rel=\"noopener\">こちら</a>もご覧ください）</p> \n<h3>AI を活用したマーケティングの未来</h3> \n<p>AI エージェントは、マーケティングとカスタマーエクスペリエンスのオペレーションを再構築する変革の始まりを象徴しています。将来的には、エージェントがメッセージのバリエーションをテストし、クリエイティブなコンテンツを生成し、マルチチャネルキャンペーンをオーケストレーションし、デバイスや地域を問わずリアルタイムで支出を最適化するようになるでしょう。</p> \n<p>マーケティングと CX の専門家は、キャンペーンを実行する役割から戦略的なオーケストレーターへと進化します。大事なことは、データインフラストラクチャが多数の自律型キャンペーンを正確かつ制御された状態で同時に実行できるかどうかです。</p> \n<p>こうした未来では、堅牢なデータ基盤、高度な AI 機能、そして大規模な信頼とコンプライアンスを確保するガバナンスフレームワークが必要とされます。すでにこのような基盤を構築している組織であれば、自律型マーケティングと CX オペレーションを活用できる態勢を整えていると言えるでしょう。</p> \n<h3>AI とデータによるマーケティングの変革</h3> \n<p>Amazon Bedrock を基盤とする Treasure Data の専用 AI エージェントと AI Agent Foundry は、マーケティング、CX、データの各チームが顧客データから価値を引き出す方法を根本的に変革します。信頼できるデータと高度な基盤モデルを組み合わせることで、チームはデータ分析、セグメント作成、ペルソナ生成、そして戦略的な意思決定を、数ヶ月ではなく数時間で実行できるようになります。</p> \n<p>この変革により、顧客インサイトへのアクセスが民主化され、複雑な分析タスクが自動化されます。マーケティングチームは市場機会への素早い対応と、迅速な反復処理によるよりよい成果の達成が可能になります。このソリューションは、効果的なマーケティングには、インテリジェントエージェントと、それらを真に強力にする堅牢なデータ基盤の両方が必要であることを示しています。</p> \n<p>セキュリティとコンプライアンスは、AWS とお客様の共有責任モデルの上にあります。AWS は Amazon Bedrock を通じて安全でコンプライアンスに準拠した基盤を提供し、お客様はデータとアクセスポリシーを管理できます。このアプローチにより、企業のガバナンス要件を満たしつつ AI を活用したイノベーションを実現できます。</p> \n<h3>まとめ</h3> \n<p>Amazon Bedrock を基盤とする Treasure Data AI Agent Foundry とプリビルドの AI エージェントが、マーケティングキャンペーンの作成プロセスを数か月から数時間、あるいは数日へと変革します。これらの AI ソリューションにより、マーケティング担当者に深い専門知識がなくても、データの迅速な分析、セグメントの作成、ペルソナの生成、そしてデータに基づく意思決定が可能になります。Amazon Bedrock の基盤モデルを活用した顧客インサイトへのアクセスの民主化と、複雑な分析タスクの自動化により、マーケティングチームは市場機会への素早い対応と迅速な反復処理を通じてよりよい成果を達成できるようになります。</p> \n<h3>Treasure Data – AWS パートナースポットライト</h3> \n<p>AWS パートナーである Treasure Data は、エンタープライズ規模に特化したインテリジェントなカスタマーデータプラットフォームです。Yum! Brands、Stellantis、AXA を始めとする 80 社を超える Global 2000 企業から信頼を得ている Treasure Data は、信頼性、パフォーマンス、そして AI ファーストのアーキテクチャを融合し、高度にパーソナライズされた顧客体験による収益向上、マーケティングコストの削減、そしてリスク軽減を実現します。Treasure Data は、すぐにご利用いただけるエージェントと AI Agent Foundry の両方を提供しています。データドリブンなチームやパートナーは、Treasure Data プラットフォーム上およびワークフロー全体で AI エージェントを活用、作成、展開し、信頼できる Treasure Data 環境内でデータを活用することができます。</p> \n<h3>関連情報</h3> \n<p><a href=\"https://aws.amazon.com/marketplace/seller-profile?id=aa906a95-308d-4b8b-b581-95d23bf4e184\" target=\"_blank\" rel=\"noopener\">Treasure Data on AWS Marketplace</a></p> \n<p><a href=\"https://partners.amazonaws.com/jp/partners/001E000000Rp5OSIAZ/Treasure%20Data\" target=\"_blank\" rel=\"noopener\">Treasure Data Partner Profile</a></p> \n<hr> \n<h4>著者について</h4> \n<p><strong>Ronak Shah</strong></p> \n<p>Ronak Shah は、ニューヨークを拠点とする AWS インダストリーバーティカルチームのプリンシパルパートナーソリューションアーキテクトです。小売消費財業界の AWS パートナーと協力し、AWS 上でのイノベーション共創を推進しています。小売業界の新たなトレンドの発見と、デジタルコマース、サプライチェーン、顧客体験、マーケティングテクノロジーの分野における革新的なソリューションの開発に関心を持っています。プライベートでは、ボーイスカウトや地元のディベート大会でボランティア活動を行っています。</p> \n<p><strong>Hiroshi Nakamura</strong></p> \n<p>Hiroshi Nakamura は、ソフトウェアエンジニアリングとシステムアーキテクチャの分野で豊富な経験を持つテクノロジーリーダーです。2014 年 10 月より Treasure Data の CTO 兼エンジニアリング担当 VP を務めており、膨大なデータに対応可能なクラウドベースのデータ管理プラットフォームの設計・開発に尽力してきました。1999 年 4 月からオープンソース開発者としても積極的に活動しており、Ruby と JRuby の大幅な機能強化に貢献しています。早稲田大学理工学修士号を取得しています。</p> \n<p><strong>Pranjal Gururani</strong></p> \n<p>Pranjal Gururani は、シアトルを拠点とする AWS のソリューションアーキテクトです。様々な顧客とともにビジネス課題を解決するクラウドソリューションの構築に取り組んでいます。趣味はハイキング、カヤック、スカイダイビング、​​そして家族との時間です。</p> \n<p>翻訳は Solutions Architect 杉中が担当しました。原文は<a href=\"https://aws.amazon.com/blogs/industries/accelerate-marketing-campaign-planning-by-3x-with-treasure-data-ai-agents-powered-by-amazon-bedrock/\">こちら</a>です。</p>"
  },
  {
    "title": "vercel/next.js – v16.0.0-canary.15",
    "date": "2025-10-19T23:46:13.000Z",
    "source": "GitHub",
    "url": "https://github.com/vercel/next.js/releases/tag/v16.0.0-canary.15",
    "content": "### Core Changes\n\n- Turbopack: Remove unneeded warning for telemetry: #85039\n- [cache components] stabilize cacheLife profiles: #85050\n- [cache components] show when cache components is enabled in the CLI: #85047\n- [cache components]: show cache components enabled in DevTools: #85048\n- [Cache Components] correctly label IO promises in devtools: #84928\n- Plumbing for cache indicator: #84955\n- Upgrade React from `93f85932-20251016` to `1324e1bb-20251016`: #84999\n- enable mcp server by default: #85058\n- Add comment that we expect the function passed to bind to be anonymous: #85070\n- Development: Addres comments on request log PR: #84945\n- Development: Implement request time for Pages Router: #85012\n- [cache components] add cache components indicator to dev start: #85069\n- cli: build partial entries --debug-build-paths arg: #85052\n- Turbopack: Better error for sassOptions.functions as it's unsupported: #85073\n\n### Misc Changes\n\n- add a message about Turbopack tracing: #85044\n- Turbopack: Implement next/font/local declarations option: #85051\n\n### Credits \n\nHuge thanks to @sokra, @ztanner, @timneutkens, @lubieowoce, @eps1lon, @huozhi, and @sebmarkbage for helping!\n"
  },
  {
    "title": "Trocco の運用を Terraform 管理に変えてみた",
    "date": "2025-10-19T23:23:00.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/medley/articles/a68e98452e1adf",
    "content": "\n はじめに\nこんにちは、メドレーでデータエンジニアをしている山邉（@beniyama）です。\n先日、弊社で利用中の Trocco についてこちらの記事を寄稿させていただきましたが、今後の展望として以下を挙げていました。\n\n上述の通り段々と規模が大きくなってきて GUI での管理が大変になってきているため、API や Terraform 経由でのプロビジョニングも生成 AI を絡めて試していきたいです。\n\nhttps://findy-tools.io/products/trocco/17/662\n今回、Trocco の一部運用を Terraform による IaC (Infrastruc..."
  },
  {
    "title": "GitHub Copilot Coding Agent に実装を任せて、作業を並行化する",
    "date": "2025-10-19T22:00:01.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/shintaro/articles/48c0abd59a6088",
    "content": "\n GitHub Copilot Coding Agent とは\nGitHub Copilot Coding Agent は、GitHub が提供する Copilot 関連機能のひとつで、開発者の指示に応じて コードの変更や Pull Request（PR） の作成を自動で実行する自律エージェント です。\nhttps://docs.github.com/ja/copilot/concepts/agents/coding-agent\nCoding Agent は、チャット上や GitHub の UI から自然言語で依頼を受けると、その内容をもとにブランチを作成し、コードを変更し、PR を生..."
  },
  {
    "title": "【結論】TypeScriptの型定義はtypeよりinterfaceを使うべき理由",
    "date": "2025-10-19T15:32:46.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/bmth/articles/interface-props-extends",
    "content": "\n はじめに\nTypeScriptでコンポーネントのPropsやオブジェクトの型を定義するとき、typeとinterfaceのどちらを使うべきか、一度は悩んだことがあるのではないでしょうか。\n巷では「どちらでも良い」「チームで統一されていればOK」といった意見もよく見かけます。\nしかし、私は 明確な理由をもって「基本的にはinterfaceを使うべき」 だと主張します。\nこの記事では私の実体験で遭遇したReactのPropsの深刻なパフォーマンス問題を例に交えながら、なぜinterfaceが優れているのか、そしてtypeはどのような場面で使うべきなのかを解説します。\n\n type ali..."
  },
  {
    "title": "自分のデストップに合うNeovimテーマがなかったので、作ってみた。",
    "date": "2025-10-19T15:13:59.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/ruki_kuri_sun/articles/b31fbca5e3cdd7",
    "content": "\n 第1章：はじめに。\n\n デスクトップテーマから始まった\n落ち着いた緑を基調にした、自作のデスクトップテーマをこんな感じで整えていました。\n\nですが、同じ雰囲気のNeovimテーマがない。\n既存テーマをカスタマイズしても微妙に理想に届かない。\nそこで、自分の手で作るしかないと思い立ちました。\nそして作ったのが yoda.nvim です。\n\n この記事で学べること\nこの記事では、テーマ制作の流れを追いながら以下を学びます。\n\nNeovimテーマの基本構造\n\n最初は「Hello, Theme!」から始めましょう。\n\n\n 第2章：最初のテーマを作る\n\n colorschemeコマンドの裏側\n..."
  },
  {
    "title": "いきなりログイン画面を見せて11%のユーザーを失った",
    "date": "2025-10-19T11:17:15.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/kontaco/articles/16ccc2e51d7a4c",
    "content": "個人開発でアプリをリリースした後、インストールされたものの新規登録せずにログインを試みて離脱するユーザーが一定数いることに気づきました。\n子供向け画像認識学習アプリ「KORENANI」を開発する中で、いきなりログイン画面を表示したことで、約11%のユーザーを初回起動時に失っていました。\nなぜこの設計がユーザーを迷わせたのか、理由を分析して改善を試みた話を共有します。観測数が少ない（n=96）ので、「検証」というほどではないですが、こういうこともあるよ、という感じで読んでもらえればと思います。\n\n TL;DR\n事実：\n\n初回起動後、約11%のユーザーがアカウント作成せずにログインを試みて失..."
  },
  {
    "title": "Rustのsqlxを使ったリポジトリ層の設計パターン",
    "date": "2025-10-19T07:20:05.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/qrtz/articles/sqlx-repo-patterns",
    "content": "sqlxはRustからデータベースを扱うためのライブラリです。Rust製のORMとしてはdieselなどの先発のライブラリがありますが、非同期処理に対応していることや、実装が簡単であるといった特長から、近年人気を集めています。\nsqlxの基礎的な使い方に関する解説記事は、比較的多くある一方で、実際のアプリケーションに導入する際の知見をまとめた記事は、あまり見受けられませんでした。\nそこで、本記事では、sqlxを実際のアプリケーションにおいて、リポジトリ層に導入する場合に、どのようなパターンを組むのが良いのかについて、考察してみたいと思います。\n\n 使用するバージョン\n\nConfig.to..."
  },
  {
    "title": "進捗報告のやり方 - Slava Akhmechet",
    "date": "2025-10-19T03:06:09.000Z",
    "source": "Zennのトレンド",
    "url": "https://zenn.dev/contradiction29/articles/f482262d1ab3c0",
    "content": "\nこの文章は、Slava Akhmechet氏の書いたブログ・エントリHow to send progress updatesを日本語に翻訳した文章です\n本人から翻訳の許可をいただき、翻訳を行いました\n良質な文章を紹介できる機会をもらえたことを、この場で感謝します\n\n\n価値のある仕事をしていると、遅かれ早かれ人々は興味を持ち、進捗状況の報告を求めるようになる。進捗報告のやり方は、四半期ごとの投資家向け報告、上司への週次報告、関係部署へのメールなど、さまざまだ。この場では、進捗報告のための効果的な方法を紹介しよう。\n\n\nまずは自分の役割を理解しよう。そして、一つ一つの報告ごとに、自分がその..."
  },
  {
    "title": "vercel/next.js – v16.0.0-canary.14",
    "date": "2025-10-19T00:09:45.000Z",
    "source": "GitHub",
    "url": "https://github.com/vercel/next.js/releases/tag/v16.0.0-canary.14",
    "content": "### Core Changes\n\n- Add Activity name to route layouts and pages: #85011\n- Update next-lint-to-eslint-cli to support `FlatCompat.config`: #85026\n- [cache components]: move flag out of experimental: #85035\n- [Cache Components] When caches are disabled in dev skip the cache warmup: #85014\n- [Cache Components] Use canary React when only Cache Components is enabled: #85042\n\n### Misc Changes\n\n- Turbopack: make tracing warning not fail build: #85032\n- [ci]: increase number of runners for test jobs: #85049\n\n### Credits \n\nHuge thanks to @acdlite, @devjiwonchoi, @mischnic, @ztanner, and @gnoff for helping!\n"
  },
  {
    "title": "vercel/next.js – v16.0.0-canary.13",
    "date": "2025-10-18T16:48:23.000Z",
    "source": "GitHub",
    "url": "https://github.com/vercel/next.js/releases/tag/v16.0.0-canary.13",
    "content": "### Core Changes\n\n- fix: incorrect canonicalUrl set when using output: export: #85019\n\n### Misc Changes\n\n- Turbopack: shard amount need to grow quadratic to cpu count to keep propability of conflicts constant: #84921\n- Turbopack: fix race condition when adding dependencies: #84946\n\n### Credits \n\nHuge thanks to @sokra and @ztanner for helping!\n"
  }
]